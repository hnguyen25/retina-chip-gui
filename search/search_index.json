{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DC 1 Visualization Introduction Welcome! This website contains documentation for the software GUI for the new Retina Chip being developed as part of the Stanford Artificial Retina Project (ARP). Quick Links For access to the codebase: Github Repository For instructions on how to use the GUI: Intro to the GUI To setup development environment: Setup Contributors: Huy Nguyen (maintainer of wiki, contact me @ nguyen5h@stanford.edu) Maddy Hays (main advisor) John Bailey (Spring & Summer 2022) Emily Bunnapradist (Fall 2022) Sahil Adhawade (Fall 2022)","title":"Introduction"},{"location":"#dc-1-visualization","text":"","title":"DC 1 Visualization"},{"location":"#introduction","text":"Welcome! This website contains documentation for the software GUI for the new Retina Chip being developed as part of the Stanford Artificial Retina Project (ARP).","title":"Introduction"},{"location":"#quick-links","text":"For access to the codebase: Github Repository For instructions on how to use the GUI: Intro to the GUI To setup development environment: Setup","title":"Quick Links"},{"location":"#contributors","text":"Huy Nguyen (maintainer of wiki, contact me @ nguyen5h@stanford.edu) Maddy Hays (main advisor) John Bailey (Spring & Summer 2022) Emily Bunnapradist (Fall 2022) Sahil Adhawade (Fall 2022)","title":"Contributors:"},{"location":"DC1DataContainer/","text":"DC1 Data Container DC1DataContainer Container for holding recording model for the DC1 retina chip. Each container is designed to hold all the relevant information extracted from model collected from a SINGLE recording, of any particular type. To-Dos: TODO figure out time alignment of the model / the actual sampling rate / check for dropped packets TODO figure out time budget for model processing + filtering Source code in app/src/model/DC1DataContainer.py class DC1DataContainer : \"\"\" Container for holding recording model for the DC1 retina chip. Each container is designed to hold all the relevant information extracted from model collected from a SINGLE recording, of any particular type. To-Dos: ---------- TODO figure out time alignment of the model / the actual sampling rate / check for dropped packets TODO figure out time budget for model processing + filtering \"\"\" # +++++ CONSTANTS +++++ # DC1/RC1.5 is a multi-electrode array (MEA) with 32 x 32 channels (1024 total) ARRAY_NUM_ROWS , ARRAY_NUM_COLS = 32 , 32 count_track , time_track = None , None # calculated statistics spike_data = { 'times' : np . zeros (( 32 , 32 )), # np.array with dims 32 x 32 x num_bins 'amplitude' : np . zeros (( 32 , 32 )) } # new model structs to_serialize , to_show = None , None avg_spike_rate_x = [] avg_spike_rate_y = [] def __init__ ( self , app , recording_info = {}, data_processing_settings = {}): self . app = app # reference to MainWindow self . time_track , self . count_track = 0 , 0 self . time_track_processed , self . count_track_processed = 0 , 0 # channel-level information # indexed via row, col of array # value: a dict containing all info for a certain electrode # self.array_indexed_df = pd.Dataframe() # TODO make array-indexed pandas df to replace below df_columns = [ \"row\" , \"col\" , # indexing \"avg_filtered_amp\" , \"avg_unfiltered_amp\" , \"channel_noise_mean\" , \"channel_noise_std\" , # noise \"start_time\" , \"start_count\" , \"buf_recording_len\" , \"N\" , \"packet_idx\" , # timing \"spikes_avg_amp\" , \"spikes_cnt\" , \"spikes_std\" , \"spikes_cum_cnt\" , \"num_bins_per_buffer\" , #spikes \"array_dot_color\" , \"array_dot_size\" # specific plot info ] initial_data = [] for i in range ( 32 ): for j in range ( 32 ): initial_data . append ([ i , j , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]) self . df = pd . DataFrame ( initial_data , columns = df_columns ) self . stats = { \"largest_spike_cnt\" : 0 } self . array_spike_times = { \"spike_bins\" : [[] for i in range ( self . ARRAY_NUM_ROWS * self . ARRAY_NUM_COLS )], \"spike_bins_max_amps\" : [[] for i in range ( self . ARRAY_NUM_ROWS * self . ARRAY_NUM_COLS )] } # ===================== # buffer-level information # indexed via key: buffer number (0 - MAX_NUMBER_OF_BUFFERS) # value: self . buffer_indexed = [] self . to_serialize = queue . Queue () self . to_show = queue . Queue () def append_buf ( self , buf ): packet_idx = buf [ 'packet_idx' ] channel_idxs = [] # for buffer_indexed model struct # calculate times N = buf [ \"packet_data\" ][ 0 ][ \"N\" ] len_packet_time = N * 0.05 # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms next_times = np . linspace ( self . time_track , self . time_track + len_packet_time , N ) self . time_track += len_packet_time self . count_track += N avg_packet_spike_count = 0 packet_data = buf [ 'packet_data' ] for packet in packet_data : # load model # packet keys: 'data_real', 'cnt_real', 'N', # 'channel_idx', 'preprocessed_data', 'filtered_data', # 'stats_cnt', 'stats_noise+mean', 'stats_noise+std' this_channel_idx = packet [ 'channel_idx' ] # for buffer_indexed model struct channel_idxs . append ( this_channel_idx ) # reformatting packet for to_show model struct packet [ \"times\" ] = next_times # for array_indexed model struct r , c = idx2map ( this_channel_idx ) # TODO make this adapt for when multiple packets record from the same channel # use formula Maddy gave df_columns = [ \"row\" , \"col\" , # indexing \"avg_filtered_amp\" , \"avg_unfiltered_amp\" , \"noise_mean\" , \"noise_std\" , # noise \"start_time\" , \"start_count\" , \"buf_recording_len\" , \"N\" , \"packet_idx\" , # timing \"spikes_avg_amp\" , \"spikes_cnt\" , \"spikes_std\" , \"spikes_cum_cnt\" , \"num_bins_per_buffer\" ] # spikes self . df . at [ this_channel_idx , \"N\" ] += packet [ \"stats_cnt\" ] self . df . at [ this_channel_idx , \"avg_unfiltered_amp\" ] = packet [ \"stats_avg+unfiltered+amp\" ] self . df . at [ this_channel_idx , \"noise_mean\" ] = packet [ \"stats_noise+mean\" ] self . df . at [ this_channel_idx , \"noise_std\" ] = packet [ \"stats_noise+std\" ] self . df . at [ this_channel_idx , \"buf_recording_len\" ] = packet [ \"stats_buf+recording+len\" ] self . df . at [ this_channel_idx , \"avg_unfiltered_amp\" ] = packet [ \"stats_avg+unfiltered+amp\" ] self . df . at [ this_channel_idx , \"spikes_cnt\" ] = packet [ \"stats_spikes+cnt\" ] self . df . at [ this_channel_idx , \"spikes_cum_cnt\" ] += packet [ \"stats_spikes+cnt\" ] self . df . at [ this_channel_idx , \"spikes_avg_amp\" ] += packet [ \"stats_spikes+avg+amp\" ] self . df . at [ this_channel_idx , \"spikes_std\" ] += packet [ \"stats_spikes+std\" ] \"\"\" self.array_indexed = { \"stats_num+spike+bins+in+buffer\": np.zeros((self.ARRAY_NUM_ROWS, self.ARRAY_NUM_COLS)), \"spike_bins\": [([] for i in range(self.ARRAY_NUM_ROWS)) for j in range(self.ARRAY_NUM_COLS)], \"spike_bins_max_amps\": [([] for i in range(self.ARRAY_NUM_ROWS)) for j in range(self.ARRAY_NUM_COLS)] } \"\"\" # TODO put spike bins here #print('array spike times -> spike_bins', packet[\"spike_bins\"]) #print('array spike times -> spike_bins_max_amp', packet[\"spike_bins_max_amps\"]) self . array_spike_times [ \"spike_bins\" ][ this_channel_idx ] = packet [ \"spike_bins\" ] self . array_spike_times [ \"spike_bins_max_amps\" ][ this_channel_idx ] = packet [ \"spike_bins_max_amps\" ] avg_packet_spike_count += packet [ \"stats_spikes+cnt\" ] # buffer-level information buffer_indexed_dict = { \"file_dir\" : buf [ \"file_dir\" ], \"filter_type\" : buf [ \"filter_type\" ], \"N\" : N , \"time_elapsed\" : len_packet_time , # TODO check if this is accurate for all recording types \"channel_idxs\" : channel_idxs , \"num_detected_spikes\" : avg_packet_spike_count / len ( packet_data ) # for spike rate plot } self . buffer_indexed . append ( buffer_indexed_dict ) self . calculate_moving_spike_rate_avg () self . to_show . put ( buf ) # return the channels in the buffer return buffer_indexed_dict [ \"channel_idxs\" ] def calculate_moving_spike_rate_avg ( self ): avg_spike_rate = 0 time_elapsed = 0 SPIKE_RATE_WINDOW_SIZE = 4 if len ( self . buffer_indexed ) < SPIKE_RATE_WINDOW_SIZE : for buffer in self . buffer_indexed : avg_spike_rate += buffer [ \"num_detected_spikes\" ] time_elapsed += buffer [ \"time_elapsed\" ] else : for buffer in self . buffer_indexed [ - 1 - SPIKE_RATE_WINDOW_SIZE : - 1 ]: avg_spike_rate += buffer [ \"num_detected_spikes\" ] time_elapsed += buffer [ \"time_elapsed\" ] #print('avg spike rate before division', avg_spike_rate) avg_spike_rate /= time_elapsed x = self . time_track y = avg_spike_rate self . avg_spike_rate_x . append ( x ) self . avg_spike_rate_y . append ( y ) map2idx ( ch_row , ch_col ) Given a channel's row and col, return channel's index Parameters: Name Type Description Default ch_row int row index of channel in array (up to 32) required ch_col int column index of channel in array (up to 32) required Returns: numerical index of array Source code in app/src/model/DC1DataContainer.py def map2idx ( ch_row : int , ch_col : int ): \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx","title":"Data Container"},{"location":"DC1DataContainer/#dc1-data-container","text":"","title":"DC1 Data Container"},{"location":"DC1DataContainer/#app.src.model.DC1DataContainer.DC1DataContainer","text":"Container for holding recording model for the DC1 retina chip. Each container is designed to hold all the relevant information extracted from model collected from a SINGLE recording, of any particular type.","title":"DC1DataContainer"},{"location":"DC1DataContainer/#app.src.model.DC1DataContainer.DC1DataContainer--to-dos","text":"TODO figure out time alignment of the model / the actual sampling rate / check for dropped packets TODO figure out time budget for model processing + filtering Source code in app/src/model/DC1DataContainer.py class DC1DataContainer : \"\"\" Container for holding recording model for the DC1 retina chip. Each container is designed to hold all the relevant information extracted from model collected from a SINGLE recording, of any particular type. To-Dos: ---------- TODO figure out time alignment of the model / the actual sampling rate / check for dropped packets TODO figure out time budget for model processing + filtering \"\"\" # +++++ CONSTANTS +++++ # DC1/RC1.5 is a multi-electrode array (MEA) with 32 x 32 channels (1024 total) ARRAY_NUM_ROWS , ARRAY_NUM_COLS = 32 , 32 count_track , time_track = None , None # calculated statistics spike_data = { 'times' : np . zeros (( 32 , 32 )), # np.array with dims 32 x 32 x num_bins 'amplitude' : np . zeros (( 32 , 32 )) } # new model structs to_serialize , to_show = None , None avg_spike_rate_x = [] avg_spike_rate_y = [] def __init__ ( self , app , recording_info = {}, data_processing_settings = {}): self . app = app # reference to MainWindow self . time_track , self . count_track = 0 , 0 self . time_track_processed , self . count_track_processed = 0 , 0 # channel-level information # indexed via row, col of array # value: a dict containing all info for a certain electrode # self.array_indexed_df = pd.Dataframe() # TODO make array-indexed pandas df to replace below df_columns = [ \"row\" , \"col\" , # indexing \"avg_filtered_amp\" , \"avg_unfiltered_amp\" , \"channel_noise_mean\" , \"channel_noise_std\" , # noise \"start_time\" , \"start_count\" , \"buf_recording_len\" , \"N\" , \"packet_idx\" , # timing \"spikes_avg_amp\" , \"spikes_cnt\" , \"spikes_std\" , \"spikes_cum_cnt\" , \"num_bins_per_buffer\" , #spikes \"array_dot_color\" , \"array_dot_size\" # specific plot info ] initial_data = [] for i in range ( 32 ): for j in range ( 32 ): initial_data . append ([ i , j , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]) self . df = pd . DataFrame ( initial_data , columns = df_columns ) self . stats = { \"largest_spike_cnt\" : 0 } self . array_spike_times = { \"spike_bins\" : [[] for i in range ( self . ARRAY_NUM_ROWS * self . ARRAY_NUM_COLS )], \"spike_bins_max_amps\" : [[] for i in range ( self . ARRAY_NUM_ROWS * self . ARRAY_NUM_COLS )] } # ===================== # buffer-level information # indexed via key: buffer number (0 - MAX_NUMBER_OF_BUFFERS) # value: self . buffer_indexed = [] self . to_serialize = queue . Queue () self . to_show = queue . Queue () def append_buf ( self , buf ): packet_idx = buf [ 'packet_idx' ] channel_idxs = [] # for buffer_indexed model struct # calculate times N = buf [ \"packet_data\" ][ 0 ][ \"N\" ] len_packet_time = N * 0.05 # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms next_times = np . linspace ( self . time_track , self . time_track + len_packet_time , N ) self . time_track += len_packet_time self . count_track += N avg_packet_spike_count = 0 packet_data = buf [ 'packet_data' ] for packet in packet_data : # load model # packet keys: 'data_real', 'cnt_real', 'N', # 'channel_idx', 'preprocessed_data', 'filtered_data', # 'stats_cnt', 'stats_noise+mean', 'stats_noise+std' this_channel_idx = packet [ 'channel_idx' ] # for buffer_indexed model struct channel_idxs . append ( this_channel_idx ) # reformatting packet for to_show model struct packet [ \"times\" ] = next_times # for array_indexed model struct r , c = idx2map ( this_channel_idx ) # TODO make this adapt for when multiple packets record from the same channel # use formula Maddy gave df_columns = [ \"row\" , \"col\" , # indexing \"avg_filtered_amp\" , \"avg_unfiltered_amp\" , \"noise_mean\" , \"noise_std\" , # noise \"start_time\" , \"start_count\" , \"buf_recording_len\" , \"N\" , \"packet_idx\" , # timing \"spikes_avg_amp\" , \"spikes_cnt\" , \"spikes_std\" , \"spikes_cum_cnt\" , \"num_bins_per_buffer\" ] # spikes self . df . at [ this_channel_idx , \"N\" ] += packet [ \"stats_cnt\" ] self . df . at [ this_channel_idx , \"avg_unfiltered_amp\" ] = packet [ \"stats_avg+unfiltered+amp\" ] self . df . at [ this_channel_idx , \"noise_mean\" ] = packet [ \"stats_noise+mean\" ] self . df . at [ this_channel_idx , \"noise_std\" ] = packet [ \"stats_noise+std\" ] self . df . at [ this_channel_idx , \"buf_recording_len\" ] = packet [ \"stats_buf+recording+len\" ] self . df . at [ this_channel_idx , \"avg_unfiltered_amp\" ] = packet [ \"stats_avg+unfiltered+amp\" ] self . df . at [ this_channel_idx , \"spikes_cnt\" ] = packet [ \"stats_spikes+cnt\" ] self . df . at [ this_channel_idx , \"spikes_cum_cnt\" ] += packet [ \"stats_spikes+cnt\" ] self . df . at [ this_channel_idx , \"spikes_avg_amp\" ] += packet [ \"stats_spikes+avg+amp\" ] self . df . at [ this_channel_idx , \"spikes_std\" ] += packet [ \"stats_spikes+std\" ] \"\"\" self.array_indexed = { \"stats_num+spike+bins+in+buffer\": np.zeros((self.ARRAY_NUM_ROWS, self.ARRAY_NUM_COLS)), \"spike_bins\": [([] for i in range(self.ARRAY_NUM_ROWS)) for j in range(self.ARRAY_NUM_COLS)], \"spike_bins_max_amps\": [([] for i in range(self.ARRAY_NUM_ROWS)) for j in range(self.ARRAY_NUM_COLS)] } \"\"\" # TODO put spike bins here #print('array spike times -> spike_bins', packet[\"spike_bins\"]) #print('array spike times -> spike_bins_max_amp', packet[\"spike_bins_max_amps\"]) self . array_spike_times [ \"spike_bins\" ][ this_channel_idx ] = packet [ \"spike_bins\" ] self . array_spike_times [ \"spike_bins_max_amps\" ][ this_channel_idx ] = packet [ \"spike_bins_max_amps\" ] avg_packet_spike_count += packet [ \"stats_spikes+cnt\" ] # buffer-level information buffer_indexed_dict = { \"file_dir\" : buf [ \"file_dir\" ], \"filter_type\" : buf [ \"filter_type\" ], \"N\" : N , \"time_elapsed\" : len_packet_time , # TODO check if this is accurate for all recording types \"channel_idxs\" : channel_idxs , \"num_detected_spikes\" : avg_packet_spike_count / len ( packet_data ) # for spike rate plot } self . buffer_indexed . append ( buffer_indexed_dict ) self . calculate_moving_spike_rate_avg () self . to_show . put ( buf ) # return the channels in the buffer return buffer_indexed_dict [ \"channel_idxs\" ] def calculate_moving_spike_rate_avg ( self ): avg_spike_rate = 0 time_elapsed = 0 SPIKE_RATE_WINDOW_SIZE = 4 if len ( self . buffer_indexed ) < SPIKE_RATE_WINDOW_SIZE : for buffer in self . buffer_indexed : avg_spike_rate += buffer [ \"num_detected_spikes\" ] time_elapsed += buffer [ \"time_elapsed\" ] else : for buffer in self . buffer_indexed [ - 1 - SPIKE_RATE_WINDOW_SIZE : - 1 ]: avg_spike_rate += buffer [ \"num_detected_spikes\" ] time_elapsed += buffer [ \"time_elapsed\" ] #print('avg spike rate before division', avg_spike_rate) avg_spike_rate /= time_elapsed x = self . time_track y = avg_spike_rate self . avg_spike_rate_x . append ( x ) self . avg_spike_rate_y . append ( y )","title":"To-Dos:"},{"location":"DC1DataContainer/#app.src.model.DC1DataContainer.map2idx","text":"Given a channel's row and col, return channel's index Parameters: Name Type Description Default ch_row int row index of channel in array (up to 32) required ch_col int column index of channel in array (up to 32) required Returns: numerical index of array Source code in app/src/model/DC1DataContainer.py def map2idx ( ch_row : int , ch_col : int ): \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx","title":"map2idx()"},{"location":"analysis/","text":"","title":"Analysis"},{"location":"changelog/","text":"5.17.2022 (Huy) Made window assignment backend much more modular. Setting up charts no longer hard-coded. Created frontend for Litke-like minimap visualization Made new noise+spike finding (6x6) GUI layouts in Qt Designer, connected into GUI loading page Added extra documentation about getting started in wiki Properly packaged app with Pyinstaller, still need to fix colormap dependency 5.12.2022 (Huy) Reverted to colored circles for array map, color bar correctly linked with it Hover over array map gives the correct values Created spike rate plot Spike rate based on average incoming spike count in each data chunk Developed four new GUI panes: New session preferences: initial settings to start analyzing datarun streamlined way of choosing to load offline/realtime data set spike threshold value from the beginning of session choose file directory on startup Set up github + github pages Individual Channel Analysis: for looking at plots for individual channels Convenient lookup of channels by number/row/col Electrode List Analysis: for displaying numerical data of electrodes in a sorted list GUI preferences: for persistent settings for the GUI not affected by datarun","title":"Change Log"},{"location":"changelog/#5172022-huy","text":"Made window assignment backend much more modular. Setting up charts no longer hard-coded. Created frontend for Litke-like minimap visualization Made new noise+spike finding (6x6) GUI layouts in Qt Designer, connected into GUI loading page Added extra documentation about getting started in wiki Properly packaged app with Pyinstaller, still need to fix colormap dependency","title":"5.17.2022 (Huy)"},{"location":"changelog/#5122022-huy","text":"Reverted to colored circles for array map, color bar correctly linked with it Hover over array map gives the correct values Created spike rate plot Spike rate based on average incoming spike count in each data chunk Developed four new GUI panes:","title":"5.12.2022 (Huy)"},{"location":"changelog/#new-session-preferences","text":"initial settings to start analyzing datarun streamlined way of choosing to load offline/realtime data set spike threshold value from the beginning of session choose file directory on startup Set up github + github pages","title":"New session preferences:"},{"location":"changelog/#individual-channel-analysis","text":"for looking at plots for individual channels Convenient lookup of channels by number/row/col","title":"Individual Channel Analysis:"},{"location":"changelog/#electrode-list-analysis","text":"for displaying numerical data of electrodes in a sorted list","title":"Electrode List Analysis:"},{"location":"changelog/#gui-preferences","text":"for persistent settings for the GUI not affected by datarun","title":"GUI preferences:"},{"location":"data-loading/","text":"","title":"Data loading"},{"location":"data/","text":"","title":"Data"},{"location":"filters/","text":"Filters applyFilterAuto ( channel_data , dataFilt ) Source code in app/src/model/filters.py def applyFilterAuto ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" samFreq = 20e3 * 1.0 passband = [ 250 , 4000 ] stopband = [ 5 , 6000 ] max_loss_passband = 3 min_loss_stopband = 30 order , normal_cutoff = signal . buttord ( passband , stopband , max_loss_passband , min_loss_stopband , fs = samFreq ) b , a = signal . butter ( order , normal_cutoff , btype = 'bandpass' , fs = samFreq ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt applyFilterAutoTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterAutoTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" samFreq = 20e3 * 1.0 passband = [ 250 , 4000 ] stopband = [ 5 , 6000 ] max_loss_passband = 3 min_loss_stopband = 30 order , normal_cutoff = signal . buttord ( passband , stopband , max_loss_passband , min_loss_stopband , fs = samFreq ) b , a = signal . butter ( order , normal_cutoff , btype = 'bandpass' , fs = samFreq ) print ( 'Order = ' + str ( order )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterFastBandpass ( channel_data , dataFilt ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterFastBandpass ( channel_data , dataFilt ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt applyFilterFastBandpassTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterFastBandpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , analog = False ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterFasterBandpass ( channel_data , dataFilt ) Source code in app/src/model/filters.py def applyFilterFasterBandpass ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq sos1 = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , output = 'sos' ) dataFilt = signal . sosfiltfilt ( sos1 , channel_data ) return dataFilt applyFilterFasterBandpassTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterFasterBandpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq sos1 = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , output = 'sos' ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . sosfiltfilt ( sos1 , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterH0bandpass ( channel_data , dataFilt ) Source code in app/src/model/filters.py def applyFilterH0bandpass ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 5 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt applyFilterH0bandpassTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterH0bandpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 5 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) print ( 'Order = ' + str ( 5 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterHierlemann ( channel_data , dataFilt ) Source code in app/src/model/filters.py def applyFilterHierlemann ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" BP_LOW_CUTOFF = 100.0 NUM_TAPS = 75 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 dataFilt = signal . filtfilt ( TAPS , [ a ], channel_data ) return dataFilt applyFilterHierlemannTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterHierlemannTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" BP_LOW_CUTOFF = 100.0 NUM_TAPS = 75 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( TAPS , [ a ], dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterHighpass ( channel_data , dataFilt ) Source code in app/src/model/filters.py def applyFilterHighpass ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff = 250 / nyq b , a = signal . butter ( 5 , [ cutoff ], btype = \"highpass\" , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt applyFilterHighpassTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterHighpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff = 250 / nyq b , a = signal . butter ( 5 , [ cutoff ], btype = \"highpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterLitke ( channel_data , dataFilt ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterLitke ( channel_data , dataFilt ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 2000 / nyq b , a = signal . butter ( 2 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt applyFilterLitkeTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterLitkeTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 2000 / nyq b , a = signal . butter ( 2 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterModHierlemann ( channel_data , dataFilt ) Parameters: Name Type Description Default channel_data required dataFilt required Source code in app/src/model/filters.py def applyFilterModHierlemann ( channel_data , dataFilt ): \"\"\" Args: channel_data: dataFilt: Returns: \"\"\" BP_LOW_CUTOFF = 250.0 BP_HIGH_CUTOFF = 4000.0 NUM_TAPS = 100 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , BP_HIGH_CUTOFF ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 dataFilt = signal . filtfilt ( TAPS , [ a ], channel_data ) return dataFilt applyFilterModHierlemannTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterModHierlemannTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" BP_LOW_CUTOFF = 250.0 BP_HIGH_CUTOFF = 4000.0 NUM_TAPS = 100 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , BP_HIGH_CUTOFF ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( TAPS , [ a ], dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterToAllData ( dataAll , numChan , chMap , filtType = 'Modified Hierlemann' , debug = False ) Parameters: Name Type Description Default dataAll required numChan required chMap required filtType 'Modified Hierlemann' Source code in app/src/model/filters.py def applyFilterToAllData ( dataAll , numChan , chMap , filtType = 'Modified Hierlemann' , debug = False ): \"\"\" Args: dataAll: numChan: chMap: filtType: Returns: \"\"\" # Future update: only calculate for channels recorded not all dataFilt = np . zeros (( np . shape ( dataAll ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemannTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Modified Hierlemann' : dataFilt = applyFilterModHierlemannTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Highpass' : dataFilt = applyFilterHighpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'H0 Bandpass' : dataFilt = applyFilterH0bandpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Auto' : dataFilt = applyFilterAutoTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Fast Bandpass' : dataFilt = applyFilterFastBandpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Faster Bandpass' : dataFilt = applyFilterFasterBandpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Litke' : dataFilt = applyFilterLitkeTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'None' : dataFilt = np . copy ( dataAll ) else : dataFilt = np . copy ( dataAll ) print ( 'Filter not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) if debug : print ( \"Filter type: \" + str ( filtType )) return dataFilt applyFilterToChannelData ( channel_data , filtType = 'Hierlemann' , debug = False ) Parameters: Name Type Description Default channel_data required filtType 'Hierlemann' Source code in app/src/model/filters.py def applyFilterToChannelData ( channel_data , filtType = 'Hierlemann' , debug = False ): \"\"\" Args: channel_data: filtType: Returns: \"\"\" dataFilt = np . zeros (( np . shape ( channel_data ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemann ( channel_data , dataFilt ) elif filtType == 'Modified Hierlemann' : dataFilt = applyFilterModHierlemann ( channel_data , dataFilt ) elif filtType == 'Highpass' : dataFilt = applyFilterHighpass ( channel_data , dataFilt ) elif filtType == 'H0 Bandpass' : dataFilt = applyFilterH0bandpass ( channel_data , dataFilt ) elif filtType == 'Auto' : dataFilt = applyFilterAuto ( channel_data , dataFilt ) elif filtType == 'Fast Bandpass' : dataFilt = applyFilterFastBandpass ( channel_data , dataFilt ) elif filtType == 'Faster Bandpass' : dataFilt = applyFilterFasterBandpass ( channel_data , dataFilt ) elif filtType == 'Litke' : dataFilt = applyFilterLitke ( channel_data , dataFilt ) elif filtType == 'None' : dataFilt = np . copy ( channel_data ) else : dataFilt = np . copy ( channel_data ) print ( 'Filter type \"' + str ( filtType ) + '\" not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) if debug : print ( \"Filter type: \" + str ( filtType )) return dataFilt","title":"Filters"},{"location":"filters/#filters","text":"","title":"Filters"},{"location":"filters/#app.src.model.filters.applyFilterAuto","text":"Source code in app/src/model/filters.py def applyFilterAuto ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" samFreq = 20e3 * 1.0 passband = [ 250 , 4000 ] stopband = [ 5 , 6000 ] max_loss_passband = 3 min_loss_stopband = 30 order , normal_cutoff = signal . buttord ( passband , stopband , max_loss_passband , min_loss_stopband , fs = samFreq ) b , a = signal . butter ( order , normal_cutoff , btype = 'bandpass' , fs = samFreq ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt","title":"applyFilterAuto()"},{"location":"filters/#app.src.model.filters.applyFilterAutoTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterAutoTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" samFreq = 20e3 * 1.0 passband = [ 250 , 4000 ] stopband = [ 5 , 6000 ] max_loss_passband = 3 min_loss_stopband = 30 order , normal_cutoff = signal . buttord ( passband , stopband , max_loss_passband , min_loss_stopband , fs = samFreq ) b , a = signal . butter ( order , normal_cutoff , btype = 'bandpass' , fs = samFreq ) print ( 'Order = ' + str ( order )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterAutoTimed()"},{"location":"filters/#app.src.model.filters.applyFilterFastBandpass","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterFastBandpass ( channel_data , dataFilt ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt","title":"applyFilterFastBandpass()"},{"location":"filters/#app.src.model.filters.applyFilterFastBandpassTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterFastBandpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , analog = False ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterFastBandpassTimed()"},{"location":"filters/#app.src.model.filters.applyFilterFasterBandpass","text":"Source code in app/src/model/filters.py def applyFilterFasterBandpass ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq sos1 = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , output = 'sos' ) dataFilt = signal . sosfiltfilt ( sos1 , channel_data ) return dataFilt","title":"applyFilterFasterBandpass()"},{"location":"filters/#app.src.model.filters.applyFilterFasterBandpassTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterFasterBandpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq sos1 = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , output = 'sos' ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . sosfiltfilt ( sos1 , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterFasterBandpassTimed()"},{"location":"filters/#app.src.model.filters.applyFilterH0bandpass","text":"Source code in app/src/model/filters.py def applyFilterH0bandpass ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 5 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt","title":"applyFilterH0bandpass()"},{"location":"filters/#app.src.model.filters.applyFilterH0bandpassTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterH0bandpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 5 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) print ( 'Order = ' + str ( 5 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterH0bandpassTimed()"},{"location":"filters/#app.src.model.filters.applyFilterHierlemann","text":"Source code in app/src/model/filters.py def applyFilterHierlemann ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" BP_LOW_CUTOFF = 100.0 NUM_TAPS = 75 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 dataFilt = signal . filtfilt ( TAPS , [ a ], channel_data ) return dataFilt","title":"applyFilterHierlemann()"},{"location":"filters/#app.src.model.filters.applyFilterHierlemannTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterHierlemannTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" BP_LOW_CUTOFF = 100.0 NUM_TAPS = 75 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( TAPS , [ a ], dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterHierlemannTimed()"},{"location":"filters/#app.src.model.filters.applyFilterHighpass","text":"Source code in app/src/model/filters.py def applyFilterHighpass ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff = 250 / nyq b , a = signal . butter ( 5 , [ cutoff ], btype = \"highpass\" , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt","title":"applyFilterHighpass()"},{"location":"filters/#app.src.model.filters.applyFilterHighpassTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterHighpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff = 250 / nyq b , a = signal . butter ( 5 , [ cutoff ], btype = \"highpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterHighpassTimed()"},{"location":"filters/#app.src.model.filters.applyFilterLitke","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterLitke ( channel_data , dataFilt ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 2000 / nyq b , a = signal . butter ( 2 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt","title":"applyFilterLitke()"},{"location":"filters/#app.src.model.filters.applyFilterLitkeTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterLitkeTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 2000 / nyq b , a = signal . butter ( 2 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterLitkeTimed()"},{"location":"filters/#app.src.model.filters.applyFilterModHierlemann","text":"Parameters: Name Type Description Default channel_data required dataFilt required Source code in app/src/model/filters.py def applyFilterModHierlemann ( channel_data , dataFilt ): \"\"\" Args: channel_data: dataFilt: Returns: \"\"\" BP_LOW_CUTOFF = 250.0 BP_HIGH_CUTOFF = 4000.0 NUM_TAPS = 100 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , BP_HIGH_CUTOFF ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 dataFilt = signal . filtfilt ( TAPS , [ a ], channel_data ) return dataFilt","title":"applyFilterModHierlemann()"},{"location":"filters/#app.src.model.filters.applyFilterModHierlemannTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/model/filters.py def applyFilterModHierlemannTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" BP_LOW_CUTOFF = 250.0 BP_HIGH_CUTOFF = 4000.0 NUM_TAPS = 100 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , BP_HIGH_CUTOFF ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( TAPS , [ a ], dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterModHierlemannTimed()"},{"location":"filters/#app.src.model.filters.applyFilterToAllData","text":"Parameters: Name Type Description Default dataAll required numChan required chMap required filtType 'Modified Hierlemann' Source code in app/src/model/filters.py def applyFilterToAllData ( dataAll , numChan , chMap , filtType = 'Modified Hierlemann' , debug = False ): \"\"\" Args: dataAll: numChan: chMap: filtType: Returns: \"\"\" # Future update: only calculate for channels recorded not all dataFilt = np . zeros (( np . shape ( dataAll ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemannTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Modified Hierlemann' : dataFilt = applyFilterModHierlemannTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Highpass' : dataFilt = applyFilterHighpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'H0 Bandpass' : dataFilt = applyFilterH0bandpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Auto' : dataFilt = applyFilterAutoTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Fast Bandpass' : dataFilt = applyFilterFastBandpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Faster Bandpass' : dataFilt = applyFilterFasterBandpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Litke' : dataFilt = applyFilterLitkeTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'None' : dataFilt = np . copy ( dataAll ) else : dataFilt = np . copy ( dataAll ) print ( 'Filter not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) if debug : print ( \"Filter type: \" + str ( filtType )) return dataFilt","title":"applyFilterToAllData()"},{"location":"filters/#app.src.model.filters.applyFilterToChannelData","text":"Parameters: Name Type Description Default channel_data required filtType 'Hierlemann' Source code in app/src/model/filters.py def applyFilterToChannelData ( channel_data , filtType = 'Hierlemann' , debug = False ): \"\"\" Args: channel_data: filtType: Returns: \"\"\" dataFilt = np . zeros (( np . shape ( channel_data ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemann ( channel_data , dataFilt ) elif filtType == 'Modified Hierlemann' : dataFilt = applyFilterModHierlemann ( channel_data , dataFilt ) elif filtType == 'Highpass' : dataFilt = applyFilterHighpass ( channel_data , dataFilt ) elif filtType == 'H0 Bandpass' : dataFilt = applyFilterH0bandpass ( channel_data , dataFilt ) elif filtType == 'Auto' : dataFilt = applyFilterAuto ( channel_data , dataFilt ) elif filtType == 'Fast Bandpass' : dataFilt = applyFilterFastBandpass ( channel_data , dataFilt ) elif filtType == 'Faster Bandpass' : dataFilt = applyFilterFasterBandpass ( channel_data , dataFilt ) elif filtType == 'Litke' : dataFilt = applyFilterLitke ( channel_data , dataFilt ) elif filtType == 'None' : dataFilt = np . copy ( channel_data ) else : dataFilt = np . copy ( channel_data ) print ( 'Filter type \"' + str ( filtType ) + '\" not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) if debug : print ( \"Filter type: \" + str ( filtType )) return dataFilt","title":"applyFilterToChannelData()"},{"location":"getting-started/","text":"Development Getting Started Guide Note: If you would like to know how to run a compiled version of the app, refer to Intro to the GUI 1. Setting up the development environment The retina chip GUI is built completely in Python, the GUI is written with PyQt5 , the plots with PyQtGraph , and the data is manipulated through a combination of numpy , pandas , and scipy . Any IDE which can be used to edit Python code is suitable for development purposes. a. Conda environment Install and setup Anaconda . Within the Github Repository , the file dc1_vis.yml contains a list of all the packages needed to set up the development environment. A new conda environment with all the necessary packages can be installed with the command: conda env create --name rc1-gui --file dc1_vis.yml Note: this package list contains the relevant packages to run on MacOS + Apple Silicon (Huy's current development environment.) If certain packages don't install properly, this is probably because there are platform (i.e. Windows, MacOS Intel) specific packages for them. Just conda install <insert-package-name> the packages that do not install properly. b. Github Repository Clone code from the Github Repository . If you do not have access, contact nguyen5h@stanford.edu. Additional Information: PyQt and PyQtGraph Use PyQt5 (the latest version) and PyQtGraph (specifically the v0.12 builds). For more information about the library, refers to these useful links: PyQt5 Official Documentation : https://doc.qt.io/qtforpython/ PyQt5 Useful Tutorials: : https://www.pythonguis.com/pyqt5/ PyQtGraph Official Documentation : https://pyqtgraph.readthedocs.io/en/latest/developer_guide/index.html 2. Running developer build for the first time This GUI can be run either within the terminal or inside a Python IDE such as PyCharm. a. To run in terminal On new terminal session, conda activate <name-of-env> to load relevant Python libraries Navigate to the location of run.py within the cloned repository Execute command python3 run.py b. To run in PyCharm The top-right bar should contain drop down menu to choose run configuration. Click on Edit configurations... Create a new configuration or edit an existing one Change the Script path to the location of run.py , i.e. /dc1DataVis/app/run.py Setup Python interpreter to be the Conda environment which you setup in part 1 The GUI should load when you press the play button now 3. Notes on important files and where files are located (last updated Nov 2022) Executing dc1DataVis/app/run.py will startup the application. The beginning of the file contains editable parameters that will be passed through to the application ( MainWindow.py ) for the session, which can be modified by the developer. It will also be possible to toggle these parameters within the GUI in the future. Other than run.py , the entire codebase for the GUI is located within the folder dc1DataVis/app/src . src/MainWindow.py The main application for the entire GUI! Every other script links to this file! If unsure what a file does, check where it is loaded in relation to this file. Check this link for additional documentation: TODO src/data folder This file contains functions for loading, manipulating, filtering, and analyzing data collected from the retina chip. It also contains DC1DataContainer.py , which is the main class which holds all of the data visualized by the GUI during runtime. Within this data class, there are two types of data: data that is indexed by the electrode (i.e. noise, time updated, spike rate, etc.) and data that is indexed by the sequential order which data packets are received from the retina chip through the FPGA. src/gui folder The folder contains all the code to plot the different types of visualizations (noise, trace, etc.) src/layouts folder This folder contains all files with endings *.ui. These are layout files which is interpreted by PyQt5 in order to generate the different GUIs. All of these files can be viewed and edited by Qt Designer. Associated .py files with the same filename generate from these .ui files and are convenient to know how to reference different pyqtgraph elements. Official Documentation for Qt Designer : https://doc.qt.io/qt-6/qtdesigner-manual.html src/debug folder Nothing important in this folder (yet!). Will be used to contain unit testing scripts!","title":"Getting Started"},{"location":"getting-started/#development-getting-started-guide","text":"Note: If you would like to know how to run a compiled version of the app, refer to Intro to the GUI","title":"Development Getting Started Guide"},{"location":"getting-started/#1-setting-up-the-development-environment","text":"The retina chip GUI is built completely in Python, the GUI is written with PyQt5 , the plots with PyQtGraph , and the data is manipulated through a combination of numpy , pandas , and scipy . Any IDE which can be used to edit Python code is suitable for development purposes.","title":"1. Setting up the development environment"},{"location":"getting-started/#a-conda-environment","text":"Install and setup Anaconda . Within the Github Repository , the file dc1_vis.yml contains a list of all the packages needed to set up the development environment. A new conda environment with all the necessary packages can be installed with the command: conda env create --name rc1-gui --file dc1_vis.yml Note: this package list contains the relevant packages to run on MacOS + Apple Silicon (Huy's current development environment.) If certain packages don't install properly, this is probably because there are platform (i.e. Windows, MacOS Intel) specific packages for them. Just conda install <insert-package-name> the packages that do not install properly.","title":"a. Conda environment"},{"location":"getting-started/#b-github-repository","text":"Clone code from the Github Repository . If you do not have access, contact nguyen5h@stanford.edu.","title":"b. Github Repository"},{"location":"getting-started/#additional-information-pyqt-and-pyqtgraph","text":"Use PyQt5 (the latest version) and PyQtGraph (specifically the v0.12 builds). For more information about the library, refers to these useful links: PyQt5 Official Documentation : https://doc.qt.io/qtforpython/ PyQt5 Useful Tutorials: : https://www.pythonguis.com/pyqt5/ PyQtGraph Official Documentation : https://pyqtgraph.readthedocs.io/en/latest/developer_guide/index.html","title":"Additional Information: PyQt and PyQtGraph"},{"location":"getting-started/#2-running-developer-build-for-the-first-time","text":"This GUI can be run either within the terminal or inside a Python IDE such as PyCharm.","title":"2. Running developer build for the first time"},{"location":"getting-started/#a-to-run-in-terminal","text":"On new terminal session, conda activate <name-of-env> to load relevant Python libraries Navigate to the location of run.py within the cloned repository Execute command python3 run.py","title":"a. To run in terminal"},{"location":"getting-started/#b-to-run-in-pycharm","text":"The top-right bar should contain drop down menu to choose run configuration. Click on Edit configurations... Create a new configuration or edit an existing one Change the Script path to the location of run.py , i.e. /dc1DataVis/app/run.py Setup Python interpreter to be the Conda environment which you setup in part 1 The GUI should load when you press the play button now","title":"b. To run in PyCharm"},{"location":"getting-started/#3-notes-on-important-files-and-where-files-are-located-last-updated-nov-2022","text":"Executing dc1DataVis/app/run.py will startup the application. The beginning of the file contains editable parameters that will be passed through to the application ( MainWindow.py ) for the session, which can be modified by the developer. It will also be possible to toggle these parameters within the GUI in the future. Other than run.py , the entire codebase for the GUI is located within the folder dc1DataVis/app/src .","title":"3. Notes on important files and where files are located (last updated Nov 2022)"},{"location":"getting-started/#srcmainwindowpy","text":"The main application for the entire GUI! Every other script links to this file! If unsure what a file does, check where it is loaded in relation to this file. Check this link for additional documentation: TODO","title":"src/MainWindow.py"},{"location":"getting-started/#srcdata-folder","text":"This file contains functions for loading, manipulating, filtering, and analyzing data collected from the retina chip. It also contains DC1DataContainer.py , which is the main class which holds all of the data visualized by the GUI during runtime. Within this data class, there are two types of data: data that is indexed by the electrode (i.e. noise, time updated, spike rate, etc.) and data that is indexed by the sequential order which data packets are received from the retina chip through the FPGA.","title":"src/data folder"},{"location":"getting-started/#srcgui-folder","text":"The folder contains all the code to plot the different types of visualizations (noise, trace, etc.)","title":"src/gui folder"},{"location":"getting-started/#srclayouts-folder","text":"This folder contains all files with endings *.ui. These are layout files which is interpreted by PyQt5 in order to generate the different GUIs. All of these files can be viewed and edited by Qt Designer. Associated .py files with the same filename generate from these .ui files and are convenient to know how to reference different pyqtgraph elements. Official Documentation for Qt Designer : https://doc.qt.io/qt-6/qtdesigner-manual.html","title":"src/layouts folder"},{"location":"getting-started/#srcdebug-folder","text":"Nothing important in this folder (yet!). Will be used to contain unit testing scripts!","title":"src/debug folder"},{"location":"gui-interactivity/","text":"","title":"Gui interactivity"},{"location":"gui-layout/","text":"","title":"Gui layout"},{"location":"gui/","text":"","title":"Gui"},{"location":"intro-to-gui/","text":"Introduction to Retina Chip GUI 1. Downloading application The latest version of the rc-gui is available here: 2. Acceptable Data Formats 3. Opening the application 4. Choose session parameters 5. Types of Visualizations a. Spike Finding Plots b. Noise Plots c. Spike Search Plots d. Diagnostic Plot 6. Additional Tools 7. Debugging and Profiling the GUI","title":"Introduction to Retina Chip GUI"},{"location":"intro-to-gui/#introduction-to-retina-chip-gui","text":"","title":"Introduction to Retina Chip GUI"},{"location":"intro-to-gui/#1-downloading-application","text":"The latest version of the rc-gui is available here:","title":"1. Downloading application"},{"location":"intro-to-gui/#2-acceptable-data-formats","text":"","title":"2. Acceptable Data Formats"},{"location":"intro-to-gui/#3-opening-the-application","text":"","title":"3. Opening the application"},{"location":"intro-to-gui/#4-choose-session-parameters","text":"","title":"4. Choose session parameters"},{"location":"intro-to-gui/#5-types-of-visualizations","text":"","title":"5. Types of Visualizations"},{"location":"intro-to-gui/#a-spike-finding-plots","text":"","title":"a. Spike Finding Plots"},{"location":"intro-to-gui/#b-noise-plots","text":"","title":"b. Noise Plots"},{"location":"intro-to-gui/#c-spike-search-plots","text":"","title":"c. Spike Search Plots"},{"location":"intro-to-gui/#d-diagnostic-plot","text":"","title":"d. Diagnostic Plot"},{"location":"intro-to-gui/#6-additional-tools","text":"","title":"6. Additional Tools"},{"location":"intro-to-gui/#7-debugging-and-profiling-the-gui","text":"","title":"7. Debugging and Profiling the GUI"},{"location":"preprocessing/","text":"Data Preprocessing","title":"Preprocessing"},{"location":"preprocessing/#data-preprocessing","text":"","title":"Data Preprocessing"},{"location":"todo/","text":"Wk of May 15-21, 2022 Huy Setup Litke Mini Map Visualizaton Create skeleton GUI for noise, spike finding plot layouts Package everything into a working app using PyInstaller Check for robustness against variable recordings Write more documentation, delete unusued vars/files John setup development environment start on individual channel + list of channels analysis windows","title":"To Dos"},{"location":"todo/#wk-of-may-15-21-2022","text":"","title":"Wk of May 15-21, 2022"},{"location":"todo/#huy","text":"Setup Litke Mini Map Visualizaton Create skeleton GUI for noise, spike finding plot layouts Package everything into a working app using PyInstaller Check for robustness against variable recordings Write more documentation, delete unusued vars/files","title":"Huy"},{"location":"todo/#john","text":"setup development environment start on individual channel + list of channels analysis windows","title":"John"},{"location":"vis_graphs/","text":"","title":"Vis graphs"}]}