{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DC 1 Visualization Introduction Welcome! This website contains documentation for the software GUI for the new Retina Chip being developed as part of the Stanford Artificial Retina Project (ARP). Quick Links For access to the codebase: Github Repository To setup development environment: Setup Main Libraries GUI: PyQt5 (https://doc.qt.io/qtforpython/) GUI Design: QtDesigner (https://doc.qt.io/qt-6/qtdesigner-manual.html) Plotting: PyQtGraph (https://pyqtgraph.readthedocs.io/en/latest/index.html) Data Science: pandas, numpy, scipy Unit Testing: Github Actions, pytest, pytest-qt (https://pytest-qt.readthedocs.io/en/latest/intro.html) Documentation: MkDocs (https://www.mkdocs.org/) Contributors: Huy Nguyen (maintainer of wiki, contact me @ nguyen5h@stanford.edu) Maddy Hays (main advisor) John Bailey (Spring & Summer 2022) Emily Bunnapradist (Fall 2022) Sahil Adhawade (Fall 2022)","title":"Introduction"},{"location":"#dc-1-visualization","text":"","title":"DC 1 Visualization"},{"location":"#introduction","text":"Welcome! This website contains documentation for the software GUI for the new Retina Chip being developed as part of the Stanford Artificial Retina Project (ARP).","title":"Introduction"},{"location":"#quick-links","text":"For access to the codebase: Github Repository To setup development environment: Setup","title":"Quick Links"},{"location":"#main-libraries","text":"GUI: PyQt5 (https://doc.qt.io/qtforpython/) GUI Design: QtDesigner (https://doc.qt.io/qt-6/qtdesigner-manual.html) Plotting: PyQtGraph (https://pyqtgraph.readthedocs.io/en/latest/index.html) Data Science: pandas, numpy, scipy Unit Testing: Github Actions, pytest, pytest-qt (https://pytest-qt.readthedocs.io/en/latest/intro.html) Documentation: MkDocs (https://www.mkdocs.org/)","title":"Main Libraries"},{"location":"#contributors","text":"Huy Nguyen (maintainer of wiki, contact me @ nguyen5h@stanford.edu) Maddy Hays (main advisor) John Bailey (Spring & Summer 2022) Emily Bunnapradist (Fall 2022) Sahil Adhawade (Fall 2022)","title":"Contributors:"},{"location":"controller/modes/init_charts/","text":"This is boilerplate code for the initial setup of the GUI plots, once a specific type of plot has been chosen. Note that chart-specific update logic within each type of plot is specified in its own corresponding file. For instance: For spike rate plots, refer to python file such as view > plot > spike_rate.py Contains one main function setup_layout, and a supporting function for each type of GUI layout, i.e. (1) Spike Finding - a combination of different plots (2) Noise - only electrode noise related plots (3) Spike Search - only channel trace plots (4) Diagnostic (not developed yet) setup_layout ( app , layout , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ) Runs initial setup to load all the charts and their basic information for a given layout (i.e. Spike Finding, Trace Search, Noise, etc.) Parameters: Name Type Description Default app reference to the MainWindow container required layout str name of window type (list specified by SessionStartupGUI.settings[\"visStyle\"]) required CURRENT_THEME str required themes dict required Returns: Type Description (bool) whether set up was successful (int) NUM_CHANNELS_PER_BUFFER Source code in src/controller/modes/init_charts.py def setup_layout ( app , layout : str , CURRENT_THEME : str , themes : dict , NUM_CHANNELS_PER_BUFFER : int ): \"\"\" Runs initial setup to load all the charts and their basic information for a given layout (i.e. Spike Finding, Trace Search, Noise, etc.) Args: app: reference to the MainWindow container layout: name of window type (list specified by SessionStartupGUI.settings[\"visStyle\"]) CURRENT_THEME: themes: Returns: (bool) whether set up was successful (int) NUM_CHANNELS_PER_BUFFER: \"\"\" app . buttons = {} # Load layout based on QtDesigner .ui file if layout == \"Spike Finding\" : from src.controller.modes.mode_spikefinding import setup_spike_finding setup_spike_finding ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ) elif layout == \"Trace Search\" : from src.controller.modes.mode_tracesearch import setup_trace_search setup_trace_search ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ) elif layout == \"Noise\" : from src.controller.modes.mode_noise import setup_noise_plots setup_noise_plots ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ) else : return False update_theme ( app , CURRENT_THEME ) return True","title":"initialize charts"},{"location":"controller/modes/init_charts/#src.controller.modes.init_charts.setup_layout","text":"Runs initial setup to load all the charts and their basic information for a given layout (i.e. Spike Finding, Trace Search, Noise, etc.) Parameters: Name Type Description Default app reference to the MainWindow container required layout str name of window type (list specified by SessionStartupGUI.settings[\"visStyle\"]) required CURRENT_THEME str required themes dict required Returns: Type Description (bool) whether set up was successful (int) NUM_CHANNELS_PER_BUFFER Source code in src/controller/modes/init_charts.py def setup_layout ( app , layout : str , CURRENT_THEME : str , themes : dict , NUM_CHANNELS_PER_BUFFER : int ): \"\"\" Runs initial setup to load all the charts and their basic information for a given layout (i.e. Spike Finding, Trace Search, Noise, etc.) Args: app: reference to the MainWindow container layout: name of window type (list specified by SessionStartupGUI.settings[\"visStyle\"]) CURRENT_THEME: themes: Returns: (bool) whether set up was successful (int) NUM_CHANNELS_PER_BUFFER: \"\"\" app . buttons = {} # Load layout based on QtDesigner .ui file if layout == \"Spike Finding\" : from src.controller.modes.mode_spikefinding import setup_spike_finding setup_spike_finding ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ) elif layout == \"Trace Search\" : from src.controller.modes.mode_tracesearch import setup_trace_search setup_trace_search ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ) elif layout == \"Noise\" : from src.controller.modes.mode_noise import setup_noise_plots setup_noise_plots ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ) else : return False update_theme ( app , CURRENT_THEME ) return True","title":"setup_layout()"},{"location":"controller/modes/mode_compression/","text":"This is the code to start the visualization of the compression mode, which will be used to view compressed spike traces.","title":"compression"},{"location":"controller/modes/mode_diagnostic/","text":"This is the code to start the visualization of the diagnostic mode, which will be used to check if the retina chip is functioning properly.","title":"diagnostic"},{"location":"controller/modes/mode_noise/","text":"This is the code to start the visualization of the noise mode, which will be used to view noise statistics of the retina chip. setup_noise_plots ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ) Parameters: Name Type Description Default app required CURRENT_THEME required themes required NUM_CHANNELS_PER_BUFFER required Source code in src/controller/modes/mode_noise.py def setup_noise_plots ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ): \"\"\" Args: app: CURRENT_THEME: themes: NUM_CHANNELS_PER_BUFFER: Returns: \"\"\" # (1) load the Qt Designer template uic . loadUi ( \"./src/view/layouts/NoiseWindow.ui\" , app ) # (2) set the functions to continually update charts in the GUI app . charts = { \"channelTracesVerticalLayout\" : app . channelTraceLayout , \"channelTraces\" : [ app . channelTrace1 , app . channelTrace2 , app . channelTrace3 , app . channelTrace4 ], \"noiseHistogram\" : app . noiseHistogramPlot , \"noiseHeatMap\" : app . noiseHeatMap } app . chart_update_function_mapping = { \"channelTraces\" : update_channel_trace_plot , \"noiseHistogram\" : update_noise_histogram_plot , \"noiseHeatMap\" : update_noise_heat_map } app . chart_update_extra_params = { \"channelTraces\" : app . charts [ \"channelTraces\" ], \"noiseHistogram\" : None , \"noiseHeatMap\" : None } app . CHART_MIN_TIME_TO_REFRESH = { \"channelTraces\" : 1 , \"noiseHistogram\" : 2 , \"noiseHeatMap\" : 4 } app . charts [ \"noiseHeatMap\" ] . setTitle ( \"Noise Heat Map\" , size = \"12pt\" ) setupSpikeTrace ( app . charts [ \"channelTraces\" ], CURRENT_THEME , themes ) setupNoiseHistogramPlot ( app . charts [ \"noiseHistogram\" ], CURRENT_THEME , themes ) # (3) Set up additional functionality pass","title":"noise"},{"location":"controller/modes/mode_noise/#src.controller.modes.mode_noise.setup_noise_plots","text":"Parameters: Name Type Description Default app required CURRENT_THEME required themes required NUM_CHANNELS_PER_BUFFER required Source code in src/controller/modes/mode_noise.py def setup_noise_plots ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ): \"\"\" Args: app: CURRENT_THEME: themes: NUM_CHANNELS_PER_BUFFER: Returns: \"\"\" # (1) load the Qt Designer template uic . loadUi ( \"./src/view/layouts/NoiseWindow.ui\" , app ) # (2) set the functions to continually update charts in the GUI app . charts = { \"channelTracesVerticalLayout\" : app . channelTraceLayout , \"channelTraces\" : [ app . channelTrace1 , app . channelTrace2 , app . channelTrace3 , app . channelTrace4 ], \"noiseHistogram\" : app . noiseHistogramPlot , \"noiseHeatMap\" : app . noiseHeatMap } app . chart_update_function_mapping = { \"channelTraces\" : update_channel_trace_plot , \"noiseHistogram\" : update_noise_histogram_plot , \"noiseHeatMap\" : update_noise_heat_map } app . chart_update_extra_params = { \"channelTraces\" : app . charts [ \"channelTraces\" ], \"noiseHistogram\" : None , \"noiseHeatMap\" : None } app . CHART_MIN_TIME_TO_REFRESH = { \"channelTraces\" : 1 , \"noiseHistogram\" : 2 , \"noiseHeatMap\" : 4 } app . charts [ \"noiseHeatMap\" ] . setTitle ( \"Noise Heat Map\" , size = \"12pt\" ) setupSpikeTrace ( app . charts [ \"channelTraces\" ], CURRENT_THEME , themes ) setupNoiseHistogramPlot ( app . charts [ \"noiseHistogram\" ], CURRENT_THEME , themes ) # (3) Set up additional functionality pass","title":"setup_noise_plots()"},{"location":"controller/modes/mode_spikefinding/","text":"This is the code to start the visualization of the spike finding mode, which will be used experimentally to find existence of spikes in live data. OnFastForward ( app ) Parameters: Name Type Description Default app required Source code in src/controller/modes/mode_spikefinding.py def OnFastForward ( app ): \"\"\" Args: app: Returns: \"\"\" print ( '>>' ) pass OnPlay ( app ) Parameters: Name Type Description Default app required Source code in src/controller/modes/mode_spikefinding.py def OnPlay ( app ): \"\"\" Args: app: Returns: \"\"\" print ( 'play' ) app . is_paused = not app . is_paused if app . is_paused is True : app . statusBar () . showMessage ( \"Paused!\" ) else : app . statusBar () . showMessage ( \"Un-paused!\" ) pass OnRewind ( app ) Parameters: Name Type Description Default app required Source code in src/controller/modes/mode_spikefinding.py def OnRewind ( app ): \"\"\" Args: app: Returns: \"\"\" print ( '<<' ) pass setup_spike_finding ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ) Parameters: Name Type Description Default app required CURRENT_THEME required themes required NUM_CHANNELS_PER_BUFFER required Source code in src/controller/modes/mode_spikefinding.py def setup_spike_finding ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ): \"\"\" Args: app: CURRENT_THEME: themes: NUM_CHANNELS_PER_BUFFER: Returns: \"\"\" # (1) load the Qt Designer template uic . loadUi ( \"./src/view/layouts/SpikeFinding.ui\" , app ) # (2) set the functions to continually update charts in the GUI # We need to define each trace plot individually. # Notes: channelTracesGrid is a QGridLayout, top-left of grid layout is (0,0) if NUM_CHANNELS_PER_BUFFER < 8 : channel_traces = [ pg . PlotWidget () for _ in range ( NUM_CHANNELS_PER_BUFFER )] for i in range ( NUM_CHANNELS_PER_BUFFER ): app . channelTracesGrid . addWidget ( channel_traces [ i ], i , 0 ) else : channel_traces = [ pg . PlotWidget () for _ in range ( 8 )] for i in range ( 4 ): app . channelTracesGrid . addWidget ( channel_traces [ i ], i , 0 ) app . channelTracesGrid . addWidget ( channel_traces [ i + 4 ], i , 1 ) \"\"\" # add a signal function for mouse click for i in range(NUM_CHANNELS_PER_BUFFER): # https://stackoverflow.com/questions/58526980/how-to-connect-mouse-clicked-signal-to-pyqtgraph-plot-widget from app.src.controller.input_mouse import pause_trace_updating print('updating signal function', i) # TODO Bug -> all the buttons when clicked only trigger the last trace plot channel_traces[i].scene().sigMouseClicked.connect(lambda: pause_trace_updating(channel_traces[i], i)) \"\"\" app . charts = { \"arrayMap\" : app . arrayMap , \"miniMap\" : app . miniMap , \"spikeRatePlot\" : app . spikeRatePlot , \"noiseHistogram\" : app . noiseHistogram , \"channelTraces\" : channel_traces , \"channelTracesLayout\" : app . channelTracesGrid } app . chart_update_function_mapping = { \"miniMap\" : update_mini_map_plot , \"spikeRatePlot\" : update_spike_rate_plot , \"noiseHistogram\" : update_noise_histogram_plot , \"channelTraces\" : update_channel_trace_plot , \"arrayMap\" : update_array_map_plot } app . chart_update_extra_params = { \"miniMap\" : None , \"spikeRatePlot\" : None , \"noiseHistogram\" : None , \"channelTraces\" : channel_traces , # should be trace plots \"arrayMap\" : None , \"noiseHeatMap\" : None , } app . CHART_MIN_TIME_TO_REFRESH = { \"miniMap\" : 2 , \"spikeRatePlot\" : 0.5 , \"noiseHistogram\" : 2 , \"channelTraces\" : 1 , \"arrayMap\" : 4 , # 4 \"noiseHeatMap\" : 0.5 , \"spikeSearch\" : 0.5 } setupArrayMap ( app , app . charts [ \"arrayMap\" ], CURRENT_THEME , themes ) setupMiniMapPlot ( app , app . charts [ \"miniMap\" ], CURRENT_THEME , themes ) setupSpikeRatePlot ( app . charts [ \"spikeRatePlot\" ], CURRENT_THEME , themes ) setupNoiseHistogramPlot ( app . charts [ \"noiseHistogram\" ], CURRENT_THEME , themes ) setupSpikeTrace ( app . charts [ \"channelTraces\" ], CURRENT_THEME , themes ) # (3) Set up additional functionality app . charts [ \"arrayMapHover\" ] = HoverRegion ( app . charts [ \"arrayMap\" ], app . showArrayLocOnStatusBar , app . onArrayMapClick ) app . RewindButton = QPushButton ( \"\u23ea\" ) app . RewindButton . setToolTip ( 'REWIND plotting to the very first recording' ) app . RewindButton . setStyleSheet ( \"background-color: \" + themes [ CURRENT_THEME ][ 'background_borders' ]) app . TogglePlayButton = QPushButton ( \"\u23f8\ufe0e\" ) app . TogglePlayButton . setToolTip ( 'PAUSE plotting on the current packet' ) app . TogglePlayButton . setStyleSheet ( \"background-color: \" + themes [ CURRENT_THEME ][ 'background_borders' ]) app . FastForwardButton = QPushButton ( \"\u23e9\" ) app . FastForwardButton . setToolTip ( 'FAST FORWARD plotting to the latest processed packet' ) app . FastForwardButton . setStyleSheet ( \"background-color: \" + themes [ CURRENT_THEME ][ 'background_borders' ]) app . statusBar () . addPermanentWidget ( app . RewindButton ) app . statusBar () . addPermanentWidget ( app . TogglePlayButton ) app . statusBar () . addPermanentWidget ( app . FastForwardButton ) from src.controller.modes.mode_spikefinding import OnRewind , OnPlay , OnFastForward app . RewindButton . clicked . connect ( OnRewind ) app . TogglePlayButton . clicked . connect ( OnPlay ) app . FastForwardButton . clicked . connect ( OnFastForward ) app . actionUpdateSession . triggered . connect ( app . OnNewSession )","title":"spike finding (main)"},{"location":"controller/modes/mode_spikefinding/#src.controller.modes.mode_spikefinding.OnFastForward","text":"Parameters: Name Type Description Default app required Source code in src/controller/modes/mode_spikefinding.py def OnFastForward ( app ): \"\"\" Args: app: Returns: \"\"\" print ( '>>' ) pass","title":"OnFastForward()"},{"location":"controller/modes/mode_spikefinding/#src.controller.modes.mode_spikefinding.OnPlay","text":"Parameters: Name Type Description Default app required Source code in src/controller/modes/mode_spikefinding.py def OnPlay ( app ): \"\"\" Args: app: Returns: \"\"\" print ( 'play' ) app . is_paused = not app . is_paused if app . is_paused is True : app . statusBar () . showMessage ( \"Paused!\" ) else : app . statusBar () . showMessage ( \"Un-paused!\" ) pass","title":"OnPlay()"},{"location":"controller/modes/mode_spikefinding/#src.controller.modes.mode_spikefinding.OnRewind","text":"Parameters: Name Type Description Default app required Source code in src/controller/modes/mode_spikefinding.py def OnRewind ( app ): \"\"\" Args: app: Returns: \"\"\" print ( '<<' ) pass","title":"OnRewind()"},{"location":"controller/modes/mode_spikefinding/#src.controller.modes.mode_spikefinding.setup_spike_finding","text":"Parameters: Name Type Description Default app required CURRENT_THEME required themes required NUM_CHANNELS_PER_BUFFER required Source code in src/controller/modes/mode_spikefinding.py def setup_spike_finding ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ): \"\"\" Args: app: CURRENT_THEME: themes: NUM_CHANNELS_PER_BUFFER: Returns: \"\"\" # (1) load the Qt Designer template uic . loadUi ( \"./src/view/layouts/SpikeFinding.ui\" , app ) # (2) set the functions to continually update charts in the GUI # We need to define each trace plot individually. # Notes: channelTracesGrid is a QGridLayout, top-left of grid layout is (0,0) if NUM_CHANNELS_PER_BUFFER < 8 : channel_traces = [ pg . PlotWidget () for _ in range ( NUM_CHANNELS_PER_BUFFER )] for i in range ( NUM_CHANNELS_PER_BUFFER ): app . channelTracesGrid . addWidget ( channel_traces [ i ], i , 0 ) else : channel_traces = [ pg . PlotWidget () for _ in range ( 8 )] for i in range ( 4 ): app . channelTracesGrid . addWidget ( channel_traces [ i ], i , 0 ) app . channelTracesGrid . addWidget ( channel_traces [ i + 4 ], i , 1 ) \"\"\" # add a signal function for mouse click for i in range(NUM_CHANNELS_PER_BUFFER): # https://stackoverflow.com/questions/58526980/how-to-connect-mouse-clicked-signal-to-pyqtgraph-plot-widget from app.src.controller.input_mouse import pause_trace_updating print('updating signal function', i) # TODO Bug -> all the buttons when clicked only trigger the last trace plot channel_traces[i].scene().sigMouseClicked.connect(lambda: pause_trace_updating(channel_traces[i], i)) \"\"\" app . charts = { \"arrayMap\" : app . arrayMap , \"miniMap\" : app . miniMap , \"spikeRatePlot\" : app . spikeRatePlot , \"noiseHistogram\" : app . noiseHistogram , \"channelTraces\" : channel_traces , \"channelTracesLayout\" : app . channelTracesGrid } app . chart_update_function_mapping = { \"miniMap\" : update_mini_map_plot , \"spikeRatePlot\" : update_spike_rate_plot , \"noiseHistogram\" : update_noise_histogram_plot , \"channelTraces\" : update_channel_trace_plot , \"arrayMap\" : update_array_map_plot } app . chart_update_extra_params = { \"miniMap\" : None , \"spikeRatePlot\" : None , \"noiseHistogram\" : None , \"channelTraces\" : channel_traces , # should be trace plots \"arrayMap\" : None , \"noiseHeatMap\" : None , } app . CHART_MIN_TIME_TO_REFRESH = { \"miniMap\" : 2 , \"spikeRatePlot\" : 0.5 , \"noiseHistogram\" : 2 , \"channelTraces\" : 1 , \"arrayMap\" : 4 , # 4 \"noiseHeatMap\" : 0.5 , \"spikeSearch\" : 0.5 } setupArrayMap ( app , app . charts [ \"arrayMap\" ], CURRENT_THEME , themes ) setupMiniMapPlot ( app , app . charts [ \"miniMap\" ], CURRENT_THEME , themes ) setupSpikeRatePlot ( app . charts [ \"spikeRatePlot\" ], CURRENT_THEME , themes ) setupNoiseHistogramPlot ( app . charts [ \"noiseHistogram\" ], CURRENT_THEME , themes ) setupSpikeTrace ( app . charts [ \"channelTraces\" ], CURRENT_THEME , themes ) # (3) Set up additional functionality app . charts [ \"arrayMapHover\" ] = HoverRegion ( app . charts [ \"arrayMap\" ], app . showArrayLocOnStatusBar , app . onArrayMapClick ) app . RewindButton = QPushButton ( \"\u23ea\" ) app . RewindButton . setToolTip ( 'REWIND plotting to the very first recording' ) app . RewindButton . setStyleSheet ( \"background-color: \" + themes [ CURRENT_THEME ][ 'background_borders' ]) app . TogglePlayButton = QPushButton ( \"\u23f8\ufe0e\" ) app . TogglePlayButton . setToolTip ( 'PAUSE plotting on the current packet' ) app . TogglePlayButton . setStyleSheet ( \"background-color: \" + themes [ CURRENT_THEME ][ 'background_borders' ]) app . FastForwardButton = QPushButton ( \"\u23e9\" ) app . FastForwardButton . setToolTip ( 'FAST FORWARD plotting to the latest processed packet' ) app . FastForwardButton . setStyleSheet ( \"background-color: \" + themes [ CURRENT_THEME ][ 'background_borders' ]) app . statusBar () . addPermanentWidget ( app . RewindButton ) app . statusBar () . addPermanentWidget ( app . TogglePlayButton ) app . statusBar () . addPermanentWidget ( app . FastForwardButton ) from src.controller.modes.mode_spikefinding import OnRewind , OnPlay , OnFastForward app . RewindButton . clicked . connect ( OnRewind ) app . TogglePlayButton . clicked . connect ( OnPlay ) app . FastForwardButton . clicked . connect ( OnFastForward ) app . actionUpdateSession . triggered . connect ( app . OnNewSession )","title":"setup_spike_finding()"},{"location":"controller/modes/mode_tracesearch/","text":"This is the code to start the visualization of the trace search mode, which will be used to view large amounts of trace data to search for spikes in non-live data. backPage ( app ) Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def backPage ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" if app . pageNum > 0 : app . pageNum -= 1 app . FigureLabel . setText ( \"Page: \" + str ( app . pageNum )) app . timeStep = 0 app . update_spike_search_plots () clearTraceSearchPlots ( app ) Parameters: Name Type Description Default app MainWindow required Source code in src/controller/modes/mode_tracesearch.py def clearTraceSearchPlots ( app ): \"\"\" Args: app: MainWindow Returns: \"\"\" for chart in app . charts : app . charts [ chart ] . clear () electrodeToPlotGrid ( app , electrodeNum ) Parameters: Name Type Description Default app MainWindow required electrodeNum required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def electrodeToPlotGrid ( app , electrodeNum ): \"\"\" Args: app: MainWindow electrodeNum: Returns: None \"\"\" \"\"\" Args: electrodeNum: electrode number on RC array (0-1023) Returns: row, col (each between 0 and 5) for the 6x6 plot grid \"\"\" electrodeNum = electrodeNum - 36 * app . pageNum row = int ( electrodeNum / 6 ) col = int ( electrodeNum - row * 6 ) return row , col getTracesToPlot ( app ) Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def getTracesToPlot ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" \"\"\" Function to determine which electrodes to plot given what page of spike search GUI user is on Returns: 36 electrodes #s in a list \"\"\" app . tracesToPlot . clear () for i in range ( 36 ): app . tracesToPlot . append ( app . pageNum * 36 + i ) app . FigureLabel . setText ( \"Figure \" + str ( app . pageNum ) + \": Ch \" + str ( app . tracesToPlot [ 0 ]) + \" to Ch \" + str ( app . tracesToPlot [ - 1 ])) return app . tracesToPlot nextPage ( app ) Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def nextPage ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" if app . pageNum < 28 : app . pageNum += 1 app . FigureLabel . setText ( \"Page: \" + str ( app . pageNum )) app . timeStep = 0 app . update_spike_search_plots () resetSpikeSearchPlotParams ( app ) Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def resetSpikeSearchPlotParams ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" app . yMax . setValue ( 20 ) app . yMin . setValue ( 30 ) app . timeZoom = True app . timeStep = 0 app . update_spike_search_plots () setupOneSpikeTrace ( plot_widget , label , CURRENT_THEME , themes ) function to set up trace plots in the spike search gui Parameters: Name Type Description Default plot_widget reference to pyqtgraph widget required label int required CURRENT_THEME str current GUI theme required themes dict dictionary of theme colors required Source code in src/controller/modes/mode_tracesearch.py def setupOneSpikeTrace ( plot_widget , label : int , CURRENT_THEME : str , themes : dict ): \"\"\"function to set up trace plots in the spike search gui Args: plot_widget: reference to pyqtgraph widget label: CURRENT_THEME: current GUI theme themes: dictionary of theme colors Returns: \"\"\" color = themes [ CURRENT_THEME ][ \"font_color\" ] if label > 1023 : label = \"####\" plot_widget . setTitle ( 'Ch # ' + str ( label ), color = color , size = '10pt' ) plot_widget . setLabel ( 'bottom' , 'time' ) setup_trace_search ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ) Parameters: Name Type Description Default app MainWindow required CURRENT_THEME required themes required NUM_CHANNELS_PER_BUFFER required Source code in src/controller/modes/mode_tracesearch.py def setup_trace_search ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ): \"\"\" Args: app: MainWindow CURRENT_THEME: themes: NUM_CHANNELS_PER_BUFFER: Returns: \"\"\" # (1) load the Qt Designer template uic . loadUi ( \"./src/view/layouts/TraceSearch.ui\" , app ) # (2) set the functions to continually update charts in the GUI for i in range ( 0 , 6 ): for j in range ( 0 , 6 ): chart_name = \"r\" + str ( i ) + \"c\" + str ( j ) app . charts [ chart_name ] = eval ( \"app.\" + chart_name ) app . chart_update_function_mapping = { \"traceSearch\" : update_trace_search_plots , #\"channelTraces\": update_channel_trace_plot } app . chart_update_extra_params = { \"traceSearch\" : None } app . CHART_MIN_TIME_TO_REFRESH = { \"traceSearch\" : 2 } # (3) Set up additional functionality # app.buttons[\"ResetButton\"] = app.resetButton # app.buttons[\"nextFigButton\"] = app.nextFigButton # app.buttons[\"yScaleButton\"] = app.yScaleButton # app.buttons[\"backButton\"] = app.backButton # app.buttons[\"nextButton\"] = app.nextButton # app.buttons[\"atTimeWindowButton\"] = app.atTimeWindowButton app . FigureLabel . setText ( \"Figure: \" + str ( app . pageNum )) app . actionIndividualChannelInfo . triggered . connect ( app . viewNewIndividualChannelInformation ) app . actionListElectrodesInfo . triggered . connect ( app . viewChannelListInformation ) app . actionAnalysisParameters . triggered . connect ( app . viewGUIPreferences ) app . actionGUIProfiler . triggered . connect ( app . viewGUIProfiler ) from src.controller.modes.mode_tracesearch import resetSpikeSearchPlotParams , nextPage , backPage , switchTimeZoom , \\ timeStepUp , timeStepDown \"\"\"todo reconnect these app.resetButton.clicked.connect(app.resetSpikeSearchPlotParams) app.nextButton.clicked.connect(app.nextPage) app.backButton.clicked.connect(app.backPage) app.timeZoomToggle.clicked.connect(app.switchTimeZoom) app.nextTimeStep.clicked.connect(app.timeStepUp) app.lastTimeStep.clicked.connect(app.timeStepDown) app.yMin.valueChanged.connect(app.update_spike_search_plots) app.yMax.valueChanged.connect(app.update_spike_search_plots) app.yMax.setValue(20) app.yMin.setValue(30) # note: pyqt spin boxes don't support negative values (for some reason) # so yMin is the distance below the mean we display \"\"\" font_color = themes [ CURRENT_THEME ][ \"font_color\" ] button_color = themes [ CURRENT_THEME ][ \"button\" ] button_style = \"color:\" + font_color + \";\" + \\ \"background-color:\" + button_color + \";\" app . resetButton . setStyleSheet ( button_style ) app . nextButton . setStyleSheet ( button_style ) app . backButton . setStyleSheet ( button_style ) app . timeZoomToggle . setStyleSheet ( button_style ) app . nextTimeStep . setStyleSheet ( button_style ) app . lastTimeStep . setStyleSheet ( button_style ) switchTimeZoom ( app ) Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def switchTimeZoom ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" app . timeZoom = not app . timeZoom app . timeStep = 0 app . update_spike_search_plots () timeStepDown ( app ) Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def timeStepDown ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" if app . timeStep > 0 : app . timeStep -= 1 app . update_spike_search_plots () timeStepUp ( app ) Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def timeStepUp ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" if app . timeStep < app . numberOfTimeSteps - 1 : app . timeStep += 1 app . update_spike_search_plots () update_trace_search_plots ( app , next_packet , CURRENT_THEME , themes , extra_params ) Parameters: Name Type Description Default app MainWindow required next_packet data contained in next buffer required CURRENT_THEME str current GUI theme required themes dict dictionary of theme colors required extra_params required Source code in src/controller/modes/mode_tracesearch.py def update_trace_search_plots ( app , next_packet , CURRENT_THEME : str , themes : dict , extra_params ): \"\"\" Args: app: MainWindow next_packet: data contained in next buffer CURRENT_THEME: current GUI theme themes: dictionary of theme colors extra_params: Returns: \"\"\" # First, clear the plots clearTraceSearchPlots ( app ) # Second, set up the plot figures for every electrode on the page # TODO make this code work for elec in getTracesToPlot ( app ): row , col = electrodeToPlotGrid ( app , elec ) setupOneSpikeTrace ( app . charts [ \"r\" + str ( row ) + \"c\" + str ( col )], elec , CURRENT_THEME , themes ) pen = pg . mkPen ( color = themes [ CURRENT_THEME ][ 'tracePlotting' ]) from src.controller.windows.window_individualchannel import IndividualChannelInformation individualChannel = IndividualChannelInformation () individualChannel . setSessionParent ( app ) # Third, fill in plots with what model you have for elec in getTracesToPlot ( app ): individualChannel . current_elec = elec individualChannel . updateElectrodeData () # The Y range we display is [mean-app.yMin, mean+app.yMax] mean = np . nanmean ( individualChannel . electrode_data ) if math . isnan ( mean ): mean = 0 lowerYBound = mean - int ( app . yMin . value ()) upperYBound = mean + int ( app . yMax . value ()) # If timeZoom, we want to zoom in on specific time windows of each trace if app . timeZoom : # The X range we display is based on which time step the user is on totalTime = len ( individualChannel . electrode_times ) if totalTime == 0 : xRange = [ 0 , 0 ] else : windowLength = int ( totalTime / app . numberOfTimeSteps ) startIdx = app . timeStep * windowLength xRange = [ individualChannel . electrode_times [ startIdx ], individualChannel . electrode_times [ startIdx + windowLength - 1 ]] row , col = app . electrodeToPlotGrid ( elec ) gridToPlot = \"r\" + str ( row ) + \"c\" + str ( col ) app . charts [ gridToPlot ] . plot ( individualChannel . electrode_times , individualChannel . electrode_data , pen = pen ) app . charts [ gridToPlot ] . setYRange ( lowerYBound , upperYBound , padding = 0 ) app . charts [ gridToPlot ] . setXRange ( xRange [ 0 ], xRange [ 1 ], padding = 0 ) # If timeZoom is false, we just want to display the whole trace, not zoomed in portions else : row , col = app . electrodeToPlotGrid ( elec ) gridToPlot = \"r\" + str ( row ) + \"c\" + str ( col ) app . charts [ gridToPlot ] . plot ( individualChannel . electrode_times , individualChannel . electrode_data , pen = pen ) app . charts [ gridToPlot ] . setYRange ( lowerYBound , upperYBound , padding = 0 ) app . charts [ gridToPlot ] . enableAutoRange ( axis = 'x' , enable = True ) # Spike highlighting if len ( individualChannel . electrode_times ) > 25 : for spike in individualChannel . electrode_spike_times : lr = pg . LinearRegionItem ([ spike - 2 , spike + 2 ]) lr . setBrush ( pg . mkBrush ( themes [ CURRENT_THEME ][ \"spikeHighlighting\" ])) lr . setZValue ( - 5 ) app . charts [ gridToPlot ] . addItem ( lr )","title":"trace search"},{"location":"controller/modes/mode_tracesearch/#src.controller.modes.mode_tracesearch.backPage","text":"Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def backPage ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" if app . pageNum > 0 : app . pageNum -= 1 app . FigureLabel . setText ( \"Page: \" + str ( app . pageNum )) app . timeStep = 0 app . update_spike_search_plots ()","title":"backPage()"},{"location":"controller/modes/mode_tracesearch/#src.controller.modes.mode_tracesearch.clearTraceSearchPlots","text":"Parameters: Name Type Description Default app MainWindow required Source code in src/controller/modes/mode_tracesearch.py def clearTraceSearchPlots ( app ): \"\"\" Args: app: MainWindow Returns: \"\"\" for chart in app . charts : app . charts [ chart ] . clear ()","title":"clearTraceSearchPlots()"},{"location":"controller/modes/mode_tracesearch/#src.controller.modes.mode_tracesearch.electrodeToPlotGrid","text":"Parameters: Name Type Description Default app MainWindow required electrodeNum required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def electrodeToPlotGrid ( app , electrodeNum ): \"\"\" Args: app: MainWindow electrodeNum: Returns: None \"\"\" \"\"\" Args: electrodeNum: electrode number on RC array (0-1023) Returns: row, col (each between 0 and 5) for the 6x6 plot grid \"\"\" electrodeNum = electrodeNum - 36 * app . pageNum row = int ( electrodeNum / 6 ) col = int ( electrodeNum - row * 6 ) return row , col","title":"electrodeToPlotGrid()"},{"location":"controller/modes/mode_tracesearch/#src.controller.modes.mode_tracesearch.getTracesToPlot","text":"Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def getTracesToPlot ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" \"\"\" Function to determine which electrodes to plot given what page of spike search GUI user is on Returns: 36 electrodes #s in a list \"\"\" app . tracesToPlot . clear () for i in range ( 36 ): app . tracesToPlot . append ( app . pageNum * 36 + i ) app . FigureLabel . setText ( \"Figure \" + str ( app . pageNum ) + \": Ch \" + str ( app . tracesToPlot [ 0 ]) + \" to Ch \" + str ( app . tracesToPlot [ - 1 ])) return app . tracesToPlot","title":"getTracesToPlot()"},{"location":"controller/modes/mode_tracesearch/#src.controller.modes.mode_tracesearch.nextPage","text":"Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def nextPage ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" if app . pageNum < 28 : app . pageNum += 1 app . FigureLabel . setText ( \"Page: \" + str ( app . pageNum )) app . timeStep = 0 app . update_spike_search_plots ()","title":"nextPage()"},{"location":"controller/modes/mode_tracesearch/#src.controller.modes.mode_tracesearch.resetSpikeSearchPlotParams","text":"Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def resetSpikeSearchPlotParams ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" app . yMax . setValue ( 20 ) app . yMin . setValue ( 30 ) app . timeZoom = True app . timeStep = 0 app . update_spike_search_plots ()","title":"resetSpikeSearchPlotParams()"},{"location":"controller/modes/mode_tracesearch/#src.controller.modes.mode_tracesearch.setupOneSpikeTrace","text":"function to set up trace plots in the spike search gui Parameters: Name Type Description Default plot_widget reference to pyqtgraph widget required label int required CURRENT_THEME str current GUI theme required themes dict dictionary of theme colors required Source code in src/controller/modes/mode_tracesearch.py def setupOneSpikeTrace ( plot_widget , label : int , CURRENT_THEME : str , themes : dict ): \"\"\"function to set up trace plots in the spike search gui Args: plot_widget: reference to pyqtgraph widget label: CURRENT_THEME: current GUI theme themes: dictionary of theme colors Returns: \"\"\" color = themes [ CURRENT_THEME ][ \"font_color\" ] if label > 1023 : label = \"####\" plot_widget . setTitle ( 'Ch # ' + str ( label ), color = color , size = '10pt' ) plot_widget . setLabel ( 'bottom' , 'time' )","title":"setupOneSpikeTrace()"},{"location":"controller/modes/mode_tracesearch/#src.controller.modes.mode_tracesearch.setup_trace_search","text":"Parameters: Name Type Description Default app MainWindow required CURRENT_THEME required themes required NUM_CHANNELS_PER_BUFFER required Source code in src/controller/modes/mode_tracesearch.py def setup_trace_search ( app , CURRENT_THEME , themes , NUM_CHANNELS_PER_BUFFER ): \"\"\" Args: app: MainWindow CURRENT_THEME: themes: NUM_CHANNELS_PER_BUFFER: Returns: \"\"\" # (1) load the Qt Designer template uic . loadUi ( \"./src/view/layouts/TraceSearch.ui\" , app ) # (2) set the functions to continually update charts in the GUI for i in range ( 0 , 6 ): for j in range ( 0 , 6 ): chart_name = \"r\" + str ( i ) + \"c\" + str ( j ) app . charts [ chart_name ] = eval ( \"app.\" + chart_name ) app . chart_update_function_mapping = { \"traceSearch\" : update_trace_search_plots , #\"channelTraces\": update_channel_trace_plot } app . chart_update_extra_params = { \"traceSearch\" : None } app . CHART_MIN_TIME_TO_REFRESH = { \"traceSearch\" : 2 } # (3) Set up additional functionality # app.buttons[\"ResetButton\"] = app.resetButton # app.buttons[\"nextFigButton\"] = app.nextFigButton # app.buttons[\"yScaleButton\"] = app.yScaleButton # app.buttons[\"backButton\"] = app.backButton # app.buttons[\"nextButton\"] = app.nextButton # app.buttons[\"atTimeWindowButton\"] = app.atTimeWindowButton app . FigureLabel . setText ( \"Figure: \" + str ( app . pageNum )) app . actionIndividualChannelInfo . triggered . connect ( app . viewNewIndividualChannelInformation ) app . actionListElectrodesInfo . triggered . connect ( app . viewChannelListInformation ) app . actionAnalysisParameters . triggered . connect ( app . viewGUIPreferences ) app . actionGUIProfiler . triggered . connect ( app . viewGUIProfiler ) from src.controller.modes.mode_tracesearch import resetSpikeSearchPlotParams , nextPage , backPage , switchTimeZoom , \\ timeStepUp , timeStepDown \"\"\"todo reconnect these app.resetButton.clicked.connect(app.resetSpikeSearchPlotParams) app.nextButton.clicked.connect(app.nextPage) app.backButton.clicked.connect(app.backPage) app.timeZoomToggle.clicked.connect(app.switchTimeZoom) app.nextTimeStep.clicked.connect(app.timeStepUp) app.lastTimeStep.clicked.connect(app.timeStepDown) app.yMin.valueChanged.connect(app.update_spike_search_plots) app.yMax.valueChanged.connect(app.update_spike_search_plots) app.yMax.setValue(20) app.yMin.setValue(30) # note: pyqt spin boxes don't support negative values (for some reason) # so yMin is the distance below the mean we display \"\"\" font_color = themes [ CURRENT_THEME ][ \"font_color\" ] button_color = themes [ CURRENT_THEME ][ \"button\" ] button_style = \"color:\" + font_color + \";\" + \\ \"background-color:\" + button_color + \";\" app . resetButton . setStyleSheet ( button_style ) app . nextButton . setStyleSheet ( button_style ) app . backButton . setStyleSheet ( button_style ) app . timeZoomToggle . setStyleSheet ( button_style ) app . nextTimeStep . setStyleSheet ( button_style ) app . lastTimeStep . setStyleSheet ( button_style )","title":"setup_trace_search()"},{"location":"controller/modes/mode_tracesearch/#src.controller.modes.mode_tracesearch.switchTimeZoom","text":"Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def switchTimeZoom ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" app . timeZoom = not app . timeZoom app . timeStep = 0 app . update_spike_search_plots ()","title":"switchTimeZoom()"},{"location":"controller/modes/mode_tracesearch/#src.controller.modes.mode_tracesearch.timeStepDown","text":"Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def timeStepDown ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" if app . timeStep > 0 : app . timeStep -= 1 app . update_spike_search_plots ()","title":"timeStepDown()"},{"location":"controller/modes/mode_tracesearch/#src.controller.modes.mode_tracesearch.timeStepUp","text":"Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/modes/mode_tracesearch.py def timeStepUp ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" if app . timeStep < app . numberOfTimeSteps - 1 : app . timeStep += 1 app . update_spike_search_plots ()","title":"timeStepUp()"},{"location":"controller/modes/mode_tracesearch/#src.controller.modes.mode_tracesearch.update_trace_search_plots","text":"Parameters: Name Type Description Default app MainWindow required next_packet data contained in next buffer required CURRENT_THEME str current GUI theme required themes dict dictionary of theme colors required extra_params required Source code in src/controller/modes/mode_tracesearch.py def update_trace_search_plots ( app , next_packet , CURRENT_THEME : str , themes : dict , extra_params ): \"\"\" Args: app: MainWindow next_packet: data contained in next buffer CURRENT_THEME: current GUI theme themes: dictionary of theme colors extra_params: Returns: \"\"\" # First, clear the plots clearTraceSearchPlots ( app ) # Second, set up the plot figures for every electrode on the page # TODO make this code work for elec in getTracesToPlot ( app ): row , col = electrodeToPlotGrid ( app , elec ) setupOneSpikeTrace ( app . charts [ \"r\" + str ( row ) + \"c\" + str ( col )], elec , CURRENT_THEME , themes ) pen = pg . mkPen ( color = themes [ CURRENT_THEME ][ 'tracePlotting' ]) from src.controller.windows.window_individualchannel import IndividualChannelInformation individualChannel = IndividualChannelInformation () individualChannel . setSessionParent ( app ) # Third, fill in plots with what model you have for elec in getTracesToPlot ( app ): individualChannel . current_elec = elec individualChannel . updateElectrodeData () # The Y range we display is [mean-app.yMin, mean+app.yMax] mean = np . nanmean ( individualChannel . electrode_data ) if math . isnan ( mean ): mean = 0 lowerYBound = mean - int ( app . yMin . value ()) upperYBound = mean + int ( app . yMax . value ()) # If timeZoom, we want to zoom in on specific time windows of each trace if app . timeZoom : # The X range we display is based on which time step the user is on totalTime = len ( individualChannel . electrode_times ) if totalTime == 0 : xRange = [ 0 , 0 ] else : windowLength = int ( totalTime / app . numberOfTimeSteps ) startIdx = app . timeStep * windowLength xRange = [ individualChannel . electrode_times [ startIdx ], individualChannel . electrode_times [ startIdx + windowLength - 1 ]] row , col = app . electrodeToPlotGrid ( elec ) gridToPlot = \"r\" + str ( row ) + \"c\" + str ( col ) app . charts [ gridToPlot ] . plot ( individualChannel . electrode_times , individualChannel . electrode_data , pen = pen ) app . charts [ gridToPlot ] . setYRange ( lowerYBound , upperYBound , padding = 0 ) app . charts [ gridToPlot ] . setXRange ( xRange [ 0 ], xRange [ 1 ], padding = 0 ) # If timeZoom is false, we just want to display the whole trace, not zoomed in portions else : row , col = app . electrodeToPlotGrid ( elec ) gridToPlot = \"r\" + str ( row ) + \"c\" + str ( col ) app . charts [ gridToPlot ] . plot ( individualChannel . electrode_times , individualChannel . electrode_data , pen = pen ) app . charts [ gridToPlot ] . setYRange ( lowerYBound , upperYBound , padding = 0 ) app . charts [ gridToPlot ] . enableAutoRange ( axis = 'x' , enable = True ) # Spike highlighting if len ( individualChannel . electrode_times ) > 25 : for spike in individualChannel . electrode_spike_times : lr = pg . LinearRegionItem ([ spike - 2 , spike + 2 ]) lr . setBrush ( pg . mkBrush ( themes [ CURRENT_THEME ][ \"spikeHighlighting\" ])) lr . setZValue ( - 5 ) app . charts [ gridToPlot ] . addItem ( lr )","title":"update_trace_search_plots()"},{"location":"controller/plots/array_map/","text":"HoverRegion Source code in src/controller/plots/array_map.py class HoverRegion (): window = None region = None vLine , hLine = None , None vb = None proxy = None proxy2 = None HoverFunc , ClickFunc = None , None last_mouse_x , last_mouse_y = None , None def __init__ ( self , window_ref , HoverFunc , ClickFunc ): self . window = window_ref #self.region = pg.LinearRegionItem() self . HoverFunc = HoverFunc self . ClickFunc = ClickFunc #self.window.addItem(self.region, ignoreBounds=True) #self.window.sigRangeChanged.connect(self.updateRegion) #self.region.setZValue(10) #self.region.setRegion([-10, 50]) #self.region.sigRegionChanged.connect(self.update) self . vb = self . window . plotItem . vb self . proxy = pg . SignalProxy ( self . window . scene () . sigMouseMoved , rateLimit = 10 , slot = self . mouseMoved ) #self.proxy2 = pg.SignalProxy(self.window.scene().sigMouseClicked, # rateLimit=60, # slot=self.mouseClicked) self . window . scene () . sigMouseClicked . connect ( self . mouseClicked ) #def update(self): # self.region.setZValue(10) # self.window.setXRange(-10, 40, padding=0) #def updateRegion(self, window, viewRange): # rgn = viewRange[0] # self.region.setRegion(rgn) def mouseMoved ( self , evt ): \"\"\"Updated when the mouse is moved by the user Args: evt: event encoded by PyQt Returns: None \"\"\" pos = evt [ 0 ] # using signal proxy turns original arguments into a tuple if self . window . sceneBoundingRect () . contains ( pos ): mousePoint = self . vb . mapSceneToView ( pos ) self . last_mouse_x = mousePoint . x () self . last_mouse_y = mousePoint . y () self . HoverFunc ( mousePoint . x (), mousePoint . y ()) def mouseClicked ( self , evt ): \"\"\"Update when the mouse is clicked by the user Args: evt: event encoded by PyQt Returns: \"\"\" pos = ( self . last_mouse_x , self . last_mouse_y ) #if self.window.sceneBoundingRect().contains(pos): # mousePoint = self.vb.mapSceneToView(pos) # print('entering click func') self . ClickFunc ( self . last_mouse_x , self . last_mouse_y ) mouseClicked ( self , evt ) Update when the mouse is clicked by the user Parameters: Name Type Description Default evt event encoded by PyQt required Source code in src/controller/plots/array_map.py def mouseClicked ( self , evt ): \"\"\"Update when the mouse is clicked by the user Args: evt: event encoded by PyQt Returns: \"\"\" pos = ( self . last_mouse_x , self . last_mouse_y ) #if self.window.sceneBoundingRect().contains(pos): # mousePoint = self.vb.mapSceneToView(pos) # print('entering click func') self . ClickFunc ( self . last_mouse_x , self . last_mouse_y ) mouseMoved ( self , evt ) Updated when the mouse is moved by the user Parameters: Name Type Description Default evt event encoded by PyQt required Returns: Type Description None Source code in src/controller/plots/array_map.py def mouseMoved ( self , evt ): \"\"\"Updated when the mouse is moved by the user Args: evt: event encoded by PyQt Returns: None \"\"\" pos = evt [ 0 ] # using signal proxy turns original arguments into a tuple if self . window . sceneBoundingRect () . contains ( pos ): mousePoint = self . vb . mapSceneToView ( pos ) self . last_mouse_x = mousePoint . x () self . last_mouse_y = mousePoint . y () self . HoverFunc ( mousePoint . x (), mousePoint . y ()) calculate_one_elec_color_and_size ( app , idx ) Parameters: Name Type Description Default app MainWindow required idx int the index of the electrode (0-1023) to be calculated required Returns: Type Description None Source code in src/controller/plots/array_map.py def calculate_one_elec_color_and_size ( app , idx : int ): \"\"\" Args: app: MainWindow idx: the index of the electrode (0-1023) to be calculated Returns: None \"\"\" # calculate the dot color from electrode's average spike amplitude spike_avg_amp = app . data . df . at [ idx , \"spikes_avg_amp\" ] levels = app . array_map_color_bar . levels () spike_avg_amp = np . clip ( spike_avg_amp , levels [ 0 ], levels [ 1 ]) spike_avg_amp = ( spike_avg_amp - levels [ 0 ]) / ( levels [ 1 ] - levels [ 0 ]) color = spike_avg_amp app . data . df . at [ idx , \"array_dot_color\" ] = color # calculate the dot size from electrode's average spike count spikes_cnt = app . data . df . at [ idx , \"spikes_cnt\" ] size = ( spikes_cnt / app . data . stats [ \"largest_spike_cnt\" ]) * app . settings [ \"max_dot_size\" ] size = np . clip ( size , app . settings [ \"min_dot_size\" ], app . settings [ \"max_dot_size\" ]) app . data . df . at [ idx , \"array_dot_size\" ] = size return color , size on_color_bar_levels_changed ( app ) called when the color bar is interacted with by the user in the viewing mode, changes the colors of the dots on the array map Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/plots/array_map.py def on_color_bar_levels_changed ( app ): \"\"\" called when the color bar is interacted with by the user in the viewing mode, changes the colors of the dots on the array map Args: app: MainWindow Returns: None \"\"\" recalculate_all_colors ( app ) elecs_points = [] color_map = app . array_map_color_bar . colorMap () for row in range ( NUM_TOTAL_ROWS ): for col in range ( NUM_TOTAL_COLS ): from src.model.data_loading_mat import map2idx idx = map2idx ( row , col ) color = color_map . map ( app . data . df . at [ idx , \"array_dot_color\" ]) default_elec_dict = { 'pos' : ( col , row ), 'size' : app . data . df . at [ idx , \"array_dot_size\" ], 'pen' : color , 'brush' : color , 'symbol' : 'o' } elecs_points . append ( default_elec_dict ) elecs_plot = pg . ScatterPlotItem ( pxMode = False ) elecs_plot . addPoints ( elecs_points ) app . update_subplot_element ( \"arrayMap\" , 'default_elecs_plot' , elecs_plot ) recalculate_all_colors ( app ) Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/plots/array_map.py def recalculate_all_colors ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" spikes_avg_amp = np . array ( app . data . df [ \"spikes_avg_amp\" ]) levels = app . array_map_color_bar . levels () spikes_avg_amp = np . clip ( np . abs ( spikes_avg_amp ), levels [ 0 ], levels [ 1 ]) spikes_avg_amp = ( spikes_avg_amp - levels [ 0 ]) / ( levels [ 1 ] - levels [ 0 ]) app . data . df [ \"array_dot_color\" ] = spikes_avg_amp recalculate_all_sizes ( app ) Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/plots/array_map.py def recalculate_all_sizes ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" spikes_cnt = np . array ( app . data . df [ \"spikes_cnt\" ]) sizes = ( spikes_cnt / app . data . stats [ \"largest_spike_cnt\" ]) * app . settings [ \"max_dot_size\" ] sizes = np . clip ( sizes , app . settings [ \"min_dot_size\" ], app . settings [ \"max_dot_size\" ]) app . data . df [ \"array_dot_size\" ] = sizes if app . arrayMapHoverCoords is not None : x , y = app . arrayMapHoverCoords if 0 <= x <= 31 and 0 <= y <= 31 : from src.model.DC1DataContainer import map2idx idx = map2idx ( x , y ) spike_cnt = app . data . df . at [ idx , \"spikes_cnt\" ] spike_amp = app . data . df . at [ idx , \"spikes_avg_amp\" ] # spike_cnt = app.model.array_indexed['stats_spikes+cnt'][y][x + 1] # spike_amp = app.model.array_indexed['stats_spikes+avg+amp'][y][x + 1] from src.model.data_loading_mat import map2idx channel_idx = map2idx ( y , x ) tooltip_text = \"<html>\" + \"Electrode Channel #\" + str ( channel_idx ) + \"<br>\" + \\ \"Row \" + str ( y ) + \", Column \" + str ( x ) + \"<br>\" + \\ \"Spike Count: \" + str ( round ( spike_cnt )) + \"<br>\" + \\ \"Spike Amplitude: \" + str ( round ( spike_amp , 3 )) + \"<\\html>\" app . charts [ \"arrayMap\" ] . setToolTip ( str ( tooltip_text )) setupArrayMap ( app , plot_widget , CURRENT_THEME , themes ) Parameters: Name Type Description Default app MainWindow required plot_widget reference to pyqtgraph widget required CURRENT_THEME str current GUI theme required themes dict dictionary of theme colors required Returns: Type Description None Source code in src/controller/plots/array_map.py def setupArrayMap ( app , plot_widget , CURRENT_THEME : str , themes : dict ): \"\"\" Args: app: MainWindow plot_widget: reference to pyqtgraph widget CURRENT_THEME: current GUI theme themes: dictionary of theme colors Returns: None \"\"\" plot_widget . showGrid ( x = False , y = False , alpha = 0 ) plot_widget . setAspectLocked () plot_widget . setLimits ( xMin =- 7 , xMax = 39 , yMin =- 7 , yMax = 39 , minXRange = 5 , maxXRange = 100 , minYRange = 5 , maxYRange = 100 ) plot_widget . getPlotItem () . hideAxis ( 'top' ) plot_widget . getPlotItem () . hideAxis ( 'bottom' ) plot_widget . getPlotItem () . hideAxis ( 'left' ) plot_widget . getPlotItem () . hideAxis ( 'right' ) cm = pg . colormap . get ( 'plasma' , source = 'matplotlib' ) colors = np . array ( app . data . df [ \"spikes_avg_amp\" ]) . reshape (( 32 , 32 )) # the pyqtgraph color bar REQUIRES it to be set to an image # however, we don't want to use an image, we want it to be linked with our scatter plot # so we make it, and set it off the screen tr = QtGui . QTransform () # prepare ImageItem transformation: tr . translate ( 200 , 200 ) # scoot image out of view image = pg . ImageItem ( colors . T ) # for old pixel-based model image . setTransform ( tr ) # bound the LinearRegionItem to the plotted model app . charts [ \"arrayMap\" ] . addItem ( image ) # TODO check if average spike amplitude makes sense w/ colors app . array_map_color_bar = app . charts [ \"arrayMap\" ] . addColorBar ( image , colorMap = cm , label = \"Spike Amplitude\" , values = ( - 10 , 20 )) # values=(0, np.max(model))) app . array_map_color_bar . sigLevelsChanged . connect ( lambda : on_color_bar_levels_changed ( app )) #app.charts[\"arrayMapHover\"].region.setClipItem(image) update_minimap_indicator ( app , CURRENT_THEME , themes ) elecs_points = [] for row in range ( NUM_TOTAL_ROWS ): for col in range ( NUM_TOTAL_COLS ): default_elec_dict = { 'pos' : ( row , col ), 'size' : 0.1 , 'pen' : { 'color' : 'w' }, 'brush' : QColor ( 0 , 0 , 0 , 0 ), 'symbol' : 'o' } elecs_points . append ( default_elec_dict ) elecs_plot = pg . ScatterPlotItem ( pxMode = False ) elecs_plot . addPoints ( elecs_points ) app . update_subplot_element ( \"arrayMap\" , 'default_elecs_plot' , elecs_plot ) update_array_map_plot ( app , next_packet , CURRENT_THEME , themes , extra_params ) Parameters: Name Type Description Default app MainWindow required next_packet data from the chip on the next buffer to be displayed required CURRENT_THEME str current GUI theme required themes dict dictionary of theme colors required extra_params required Returns: Type Description None Source code in src/controller/plots/array_map.py def update_array_map_plot ( app , next_packet , CURRENT_THEME : str , themes : dict , extra_params ): \"\"\" Args: app: MainWindow next_packet: data from the chip on the next buffer to be displayed CURRENT_THEME: current GUI theme themes: dictionary of theme colors extra_params: Returns: None \"\"\" # CURRENT ELECTRODE BOX INDICATOR curr_rec_elecs_box = [] dot_scaling_changed = False for i in range ( len ( next_packet [ 'packet_data' ])): # get packet info chan_idx = next_packet [ 'packet_data' ][ i ][ 'channel_idx' ] from src.model.data_loading_mat import idx2map row , col = idx2map ( chan_idx ) # add squares around electrodes currently being recorded from + visualized in spike trace spot_dict = { 'pos' : ( col , row ), 'size' : 1 , 'pen' : { 'color' : pg . mkColor ( themes [ CURRENT_THEME ][ 'light1' ]), 'width' : 2 }, 'brush' : QColor ( 255 , 0 , 255 , 0 ), 'symbol' : 's' } curr_rec_elecs_box . append ( spot_dict ) # check if scaling needs to be changed if app . data . stats [ 'largest_spike_cnt' ] < app . settings [ 'spike_cnt_for_dot_size_saturation' ]: if app . data . df . at [ chan_idx , \"spikes_cnt\" ] > app . data . stats [ \"largest_spike_cnt\" ]: if app . data . df . at [ chan_idx , \"spikes_cnt\" ] > app . settings [ 'spike_cnt_for_dot_size_saturation' ]: app . data . stats [ 'largest_spikes_cnt' ] = app . settings [ 'spike_cnt_for_dot_size_saturation' ] else : app . data . stats [ \"largest_spike_cnt\" ] = app . data . df . at [ chan_idx , \"spikes_cnt\" ] dot_scaling_changed = True current_recording_elecs_indicator = pg . ScatterPlotItem ( pxMode = False ) current_recording_elecs_indicator . addPoints ( curr_rec_elecs_box ) app . update_subplot_element ( \"arrayMap\" , \"current_recording_elecs_indicator\" , current_recording_elecs_indicator ) # update the dot information (color and size) idxs_to_change = [] if dot_scaling_changed : # all recalculate colors and sizes recalculate_all_sizes ( app ) else : # calculate only for specific elecs in current buffer for i in range ( len ( next_packet [ 'packet_data' ])): chan_idx = next_packet [ 'packet_data' ][ i ][ 'channel_idx' ] idxs_to_change . append ( chan_idx ) calculate_one_elec_color_and_size ( app , chan_idx ) # render all the points elecs_points = [] color_map = app . array_map_color_bar . colorMap () for row in range ( NUM_TOTAL_ROWS ): for col in range ( NUM_TOTAL_COLS ): from src.model.data_loading_mat import map2idx idx = map2idx ( row , col ) array_dot_color_idx = app . data . df . at [ idx , \"array_dot_color\" ] #if array_dot_color_idx > 0: # print('ar dot color idx:', 'r', row, 'c', col, '/', array_dot_color_idx) color = color_map . map ( array_dot_color_idx ) default_elec_dict = { 'pos' : ( col , row ), 'size' : app . data . df . at [ idx , \"array_dot_size\" ], 'pen' : color , 'brush' : color , 'symbol' : 'o' } elecs_points . append ( default_elec_dict ) elecs_plot = pg . ScatterPlotItem ( pxMode = False ) elecs_plot . addPoints ( elecs_points ) app . update_subplot_element ( \"arrayMap\" , 'default_elecs_plot' , elecs_plot ) update_minimap_indicator ( app , CURRENT_THEME , themes ) add a square around electrodes displayed in the minimap Parameters: Name Type Description Default app MainWindow required CURRENT_THEME str current GUI theme required themes dict dictionary of theme colors required Returns: Type Description None Source code in src/controller/plots/array_map.py def update_minimap_indicator ( app , CURRENT_THEME : str , themes : dict ): # this is called on cursor click + on setup \"\"\"add a square around electrodes displayed in the minimap Args: app: MainWindow CURRENT_THEME: current GUI theme themes: dictionary of theme colors Returns: None \"\"\" minimap_square_indicator = pg . QtGui . QGraphicsRectItem ( app . settings [ 'cursor_row' ] - 4.5 , app . settings [ 'cursor_col' ] - 2.5 , 8 , 4 ) minimap_square_indicator . setPen ( pg . mkPen ( themes [ CURRENT_THEME ][ 'blue3' ])) minimap_square_indicator . setBrush ( QColor ( 255 , 0 , 255 , 0 )) app . update_subplot_element ( \"arrayMap\" , 'minimap_square_indicator' , minimap_square_indicator )","title":"array map"},{"location":"controller/plots/array_map/#src.controller.plots.array_map.HoverRegion","text":"Source code in src/controller/plots/array_map.py class HoverRegion (): window = None region = None vLine , hLine = None , None vb = None proxy = None proxy2 = None HoverFunc , ClickFunc = None , None last_mouse_x , last_mouse_y = None , None def __init__ ( self , window_ref , HoverFunc , ClickFunc ): self . window = window_ref #self.region = pg.LinearRegionItem() self . HoverFunc = HoverFunc self . ClickFunc = ClickFunc #self.window.addItem(self.region, ignoreBounds=True) #self.window.sigRangeChanged.connect(self.updateRegion) #self.region.setZValue(10) #self.region.setRegion([-10, 50]) #self.region.sigRegionChanged.connect(self.update) self . vb = self . window . plotItem . vb self . proxy = pg . SignalProxy ( self . window . scene () . sigMouseMoved , rateLimit = 10 , slot = self . mouseMoved ) #self.proxy2 = pg.SignalProxy(self.window.scene().sigMouseClicked, # rateLimit=60, # slot=self.mouseClicked) self . window . scene () . sigMouseClicked . connect ( self . mouseClicked ) #def update(self): # self.region.setZValue(10) # self.window.setXRange(-10, 40, padding=0) #def updateRegion(self, window, viewRange): # rgn = viewRange[0] # self.region.setRegion(rgn) def mouseMoved ( self , evt ): \"\"\"Updated when the mouse is moved by the user Args: evt: event encoded by PyQt Returns: None \"\"\" pos = evt [ 0 ] # using signal proxy turns original arguments into a tuple if self . window . sceneBoundingRect () . contains ( pos ): mousePoint = self . vb . mapSceneToView ( pos ) self . last_mouse_x = mousePoint . x () self . last_mouse_y = mousePoint . y () self . HoverFunc ( mousePoint . x (), mousePoint . y ()) def mouseClicked ( self , evt ): \"\"\"Update when the mouse is clicked by the user Args: evt: event encoded by PyQt Returns: \"\"\" pos = ( self . last_mouse_x , self . last_mouse_y ) #if self.window.sceneBoundingRect().contains(pos): # mousePoint = self.vb.mapSceneToView(pos) # print('entering click func') self . ClickFunc ( self . last_mouse_x , self . last_mouse_y )","title":"HoverRegion"},{"location":"controller/plots/array_map/#src.controller.plots.array_map.HoverRegion.mouseClicked","text":"Update when the mouse is clicked by the user Parameters: Name Type Description Default evt event encoded by PyQt required Source code in src/controller/plots/array_map.py def mouseClicked ( self , evt ): \"\"\"Update when the mouse is clicked by the user Args: evt: event encoded by PyQt Returns: \"\"\" pos = ( self . last_mouse_x , self . last_mouse_y ) #if self.window.sceneBoundingRect().contains(pos): # mousePoint = self.vb.mapSceneToView(pos) # print('entering click func') self . ClickFunc ( self . last_mouse_x , self . last_mouse_y )","title":"mouseClicked()"},{"location":"controller/plots/array_map/#src.controller.plots.array_map.HoverRegion.mouseMoved","text":"Updated when the mouse is moved by the user Parameters: Name Type Description Default evt event encoded by PyQt required Returns: Type Description None Source code in src/controller/plots/array_map.py def mouseMoved ( self , evt ): \"\"\"Updated when the mouse is moved by the user Args: evt: event encoded by PyQt Returns: None \"\"\" pos = evt [ 0 ] # using signal proxy turns original arguments into a tuple if self . window . sceneBoundingRect () . contains ( pos ): mousePoint = self . vb . mapSceneToView ( pos ) self . last_mouse_x = mousePoint . x () self . last_mouse_y = mousePoint . y () self . HoverFunc ( mousePoint . x (), mousePoint . y ())","title":"mouseMoved()"},{"location":"controller/plots/array_map/#src.controller.plots.array_map.calculate_one_elec_color_and_size","text":"Parameters: Name Type Description Default app MainWindow required idx int the index of the electrode (0-1023) to be calculated required Returns: Type Description None Source code in src/controller/plots/array_map.py def calculate_one_elec_color_and_size ( app , idx : int ): \"\"\" Args: app: MainWindow idx: the index of the electrode (0-1023) to be calculated Returns: None \"\"\" # calculate the dot color from electrode's average spike amplitude spike_avg_amp = app . data . df . at [ idx , \"spikes_avg_amp\" ] levels = app . array_map_color_bar . levels () spike_avg_amp = np . clip ( spike_avg_amp , levels [ 0 ], levels [ 1 ]) spike_avg_amp = ( spike_avg_amp - levels [ 0 ]) / ( levels [ 1 ] - levels [ 0 ]) color = spike_avg_amp app . data . df . at [ idx , \"array_dot_color\" ] = color # calculate the dot size from electrode's average spike count spikes_cnt = app . data . df . at [ idx , \"spikes_cnt\" ] size = ( spikes_cnt / app . data . stats [ \"largest_spike_cnt\" ]) * app . settings [ \"max_dot_size\" ] size = np . clip ( size , app . settings [ \"min_dot_size\" ], app . settings [ \"max_dot_size\" ]) app . data . df . at [ idx , \"array_dot_size\" ] = size return color , size","title":"calculate_one_elec_color_and_size()"},{"location":"controller/plots/array_map/#src.controller.plots.array_map.on_color_bar_levels_changed","text":"called when the color bar is interacted with by the user in the viewing mode, changes the colors of the dots on the array map Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/plots/array_map.py def on_color_bar_levels_changed ( app ): \"\"\" called when the color bar is interacted with by the user in the viewing mode, changes the colors of the dots on the array map Args: app: MainWindow Returns: None \"\"\" recalculate_all_colors ( app ) elecs_points = [] color_map = app . array_map_color_bar . colorMap () for row in range ( NUM_TOTAL_ROWS ): for col in range ( NUM_TOTAL_COLS ): from src.model.data_loading_mat import map2idx idx = map2idx ( row , col ) color = color_map . map ( app . data . df . at [ idx , \"array_dot_color\" ]) default_elec_dict = { 'pos' : ( col , row ), 'size' : app . data . df . at [ idx , \"array_dot_size\" ], 'pen' : color , 'brush' : color , 'symbol' : 'o' } elecs_points . append ( default_elec_dict ) elecs_plot = pg . ScatterPlotItem ( pxMode = False ) elecs_plot . addPoints ( elecs_points ) app . update_subplot_element ( \"arrayMap\" , 'default_elecs_plot' , elecs_plot )","title":"on_color_bar_levels_changed()"},{"location":"controller/plots/array_map/#src.controller.plots.array_map.recalculate_all_colors","text":"Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/plots/array_map.py def recalculate_all_colors ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" spikes_avg_amp = np . array ( app . data . df [ \"spikes_avg_amp\" ]) levels = app . array_map_color_bar . levels () spikes_avg_amp = np . clip ( np . abs ( spikes_avg_amp ), levels [ 0 ], levels [ 1 ]) spikes_avg_amp = ( spikes_avg_amp - levels [ 0 ]) / ( levels [ 1 ] - levels [ 0 ]) app . data . df [ \"array_dot_color\" ] = spikes_avg_amp","title":"recalculate_all_colors()"},{"location":"controller/plots/array_map/#src.controller.plots.array_map.recalculate_all_sizes","text":"Parameters: Name Type Description Default app MainWindow required Returns: Type Description None Source code in src/controller/plots/array_map.py def recalculate_all_sizes ( app ): \"\"\" Args: app: MainWindow Returns: None \"\"\" spikes_cnt = np . array ( app . data . df [ \"spikes_cnt\" ]) sizes = ( spikes_cnt / app . data . stats [ \"largest_spike_cnt\" ]) * app . settings [ \"max_dot_size\" ] sizes = np . clip ( sizes , app . settings [ \"min_dot_size\" ], app . settings [ \"max_dot_size\" ]) app . data . df [ \"array_dot_size\" ] = sizes if app . arrayMapHoverCoords is not None : x , y = app . arrayMapHoverCoords if 0 <= x <= 31 and 0 <= y <= 31 : from src.model.DC1DataContainer import map2idx idx = map2idx ( x , y ) spike_cnt = app . data . df . at [ idx , \"spikes_cnt\" ] spike_amp = app . data . df . at [ idx , \"spikes_avg_amp\" ] # spike_cnt = app.model.array_indexed['stats_spikes+cnt'][y][x + 1] # spike_amp = app.model.array_indexed['stats_spikes+avg+amp'][y][x + 1] from src.model.data_loading_mat import map2idx channel_idx = map2idx ( y , x ) tooltip_text = \"<html>\" + \"Electrode Channel #\" + str ( channel_idx ) + \"<br>\" + \\ \"Row \" + str ( y ) + \", Column \" + str ( x ) + \"<br>\" + \\ \"Spike Count: \" + str ( round ( spike_cnt )) + \"<br>\" + \\ \"Spike Amplitude: \" + str ( round ( spike_amp , 3 )) + \"<\\html>\" app . charts [ \"arrayMap\" ] . setToolTip ( str ( tooltip_text ))","title":"recalculate_all_sizes()"},{"location":"controller/plots/array_map/#src.controller.plots.array_map.setupArrayMap","text":"Parameters: Name Type Description Default app MainWindow required plot_widget reference to pyqtgraph widget required CURRENT_THEME str current GUI theme required themes dict dictionary of theme colors required Returns: Type Description None Source code in src/controller/plots/array_map.py def setupArrayMap ( app , plot_widget , CURRENT_THEME : str , themes : dict ): \"\"\" Args: app: MainWindow plot_widget: reference to pyqtgraph widget CURRENT_THEME: current GUI theme themes: dictionary of theme colors Returns: None \"\"\" plot_widget . showGrid ( x = False , y = False , alpha = 0 ) plot_widget . setAspectLocked () plot_widget . setLimits ( xMin =- 7 , xMax = 39 , yMin =- 7 , yMax = 39 , minXRange = 5 , maxXRange = 100 , minYRange = 5 , maxYRange = 100 ) plot_widget . getPlotItem () . hideAxis ( 'top' ) plot_widget . getPlotItem () . hideAxis ( 'bottom' ) plot_widget . getPlotItem () . hideAxis ( 'left' ) plot_widget . getPlotItem () . hideAxis ( 'right' ) cm = pg . colormap . get ( 'plasma' , source = 'matplotlib' ) colors = np . array ( app . data . df [ \"spikes_avg_amp\" ]) . reshape (( 32 , 32 )) # the pyqtgraph color bar REQUIRES it to be set to an image # however, we don't want to use an image, we want it to be linked with our scatter plot # so we make it, and set it off the screen tr = QtGui . QTransform () # prepare ImageItem transformation: tr . translate ( 200 , 200 ) # scoot image out of view image = pg . ImageItem ( colors . T ) # for old pixel-based model image . setTransform ( tr ) # bound the LinearRegionItem to the plotted model app . charts [ \"arrayMap\" ] . addItem ( image ) # TODO check if average spike amplitude makes sense w/ colors app . array_map_color_bar = app . charts [ \"arrayMap\" ] . addColorBar ( image , colorMap = cm , label = \"Spike Amplitude\" , values = ( - 10 , 20 )) # values=(0, np.max(model))) app . array_map_color_bar . sigLevelsChanged . connect ( lambda : on_color_bar_levels_changed ( app )) #app.charts[\"arrayMapHover\"].region.setClipItem(image) update_minimap_indicator ( app , CURRENT_THEME , themes ) elecs_points = [] for row in range ( NUM_TOTAL_ROWS ): for col in range ( NUM_TOTAL_COLS ): default_elec_dict = { 'pos' : ( row , col ), 'size' : 0.1 , 'pen' : { 'color' : 'w' }, 'brush' : QColor ( 0 , 0 , 0 , 0 ), 'symbol' : 'o' } elecs_points . append ( default_elec_dict ) elecs_plot = pg . ScatterPlotItem ( pxMode = False ) elecs_plot . addPoints ( elecs_points ) app . update_subplot_element ( \"arrayMap\" , 'default_elecs_plot' , elecs_plot )","title":"setupArrayMap()"},{"location":"controller/plots/array_map/#src.controller.plots.array_map.update_array_map_plot","text":"Parameters: Name Type Description Default app MainWindow required next_packet data from the chip on the next buffer to be displayed required CURRENT_THEME str current GUI theme required themes dict dictionary of theme colors required extra_params required Returns: Type Description None Source code in src/controller/plots/array_map.py def update_array_map_plot ( app , next_packet , CURRENT_THEME : str , themes : dict , extra_params ): \"\"\" Args: app: MainWindow next_packet: data from the chip on the next buffer to be displayed CURRENT_THEME: current GUI theme themes: dictionary of theme colors extra_params: Returns: None \"\"\" # CURRENT ELECTRODE BOX INDICATOR curr_rec_elecs_box = [] dot_scaling_changed = False for i in range ( len ( next_packet [ 'packet_data' ])): # get packet info chan_idx = next_packet [ 'packet_data' ][ i ][ 'channel_idx' ] from src.model.data_loading_mat import idx2map row , col = idx2map ( chan_idx ) # add squares around electrodes currently being recorded from + visualized in spike trace spot_dict = { 'pos' : ( col , row ), 'size' : 1 , 'pen' : { 'color' : pg . mkColor ( themes [ CURRENT_THEME ][ 'light1' ]), 'width' : 2 }, 'brush' : QColor ( 255 , 0 , 255 , 0 ), 'symbol' : 's' } curr_rec_elecs_box . append ( spot_dict ) # check if scaling needs to be changed if app . data . stats [ 'largest_spike_cnt' ] < app . settings [ 'spike_cnt_for_dot_size_saturation' ]: if app . data . df . at [ chan_idx , \"spikes_cnt\" ] > app . data . stats [ \"largest_spike_cnt\" ]: if app . data . df . at [ chan_idx , \"spikes_cnt\" ] > app . settings [ 'spike_cnt_for_dot_size_saturation' ]: app . data . stats [ 'largest_spikes_cnt' ] = app . settings [ 'spike_cnt_for_dot_size_saturation' ] else : app . data . stats [ \"largest_spike_cnt\" ] = app . data . df . at [ chan_idx , \"spikes_cnt\" ] dot_scaling_changed = True current_recording_elecs_indicator = pg . ScatterPlotItem ( pxMode = False ) current_recording_elecs_indicator . addPoints ( curr_rec_elecs_box ) app . update_subplot_element ( \"arrayMap\" , \"current_recording_elecs_indicator\" , current_recording_elecs_indicator ) # update the dot information (color and size) idxs_to_change = [] if dot_scaling_changed : # all recalculate colors and sizes recalculate_all_sizes ( app ) else : # calculate only for specific elecs in current buffer for i in range ( len ( next_packet [ 'packet_data' ])): chan_idx = next_packet [ 'packet_data' ][ i ][ 'channel_idx' ] idxs_to_change . append ( chan_idx ) calculate_one_elec_color_and_size ( app , chan_idx ) # render all the points elecs_points = [] color_map = app . array_map_color_bar . colorMap () for row in range ( NUM_TOTAL_ROWS ): for col in range ( NUM_TOTAL_COLS ): from src.model.data_loading_mat import map2idx idx = map2idx ( row , col ) array_dot_color_idx = app . data . df . at [ idx , \"array_dot_color\" ] #if array_dot_color_idx > 0: # print('ar dot color idx:', 'r', row, 'c', col, '/', array_dot_color_idx) color = color_map . map ( array_dot_color_idx ) default_elec_dict = { 'pos' : ( col , row ), 'size' : app . data . df . at [ idx , \"array_dot_size\" ], 'pen' : color , 'brush' : color , 'symbol' : 'o' } elecs_points . append ( default_elec_dict ) elecs_plot = pg . ScatterPlotItem ( pxMode = False ) elecs_plot . addPoints ( elecs_points ) app . update_subplot_element ( \"arrayMap\" , 'default_elecs_plot' , elecs_plot )","title":"update_array_map_plot()"},{"location":"controller/plots/array_map/#src.controller.plots.array_map.update_minimap_indicator","text":"add a square around electrodes displayed in the minimap Parameters: Name Type Description Default app MainWindow required CURRENT_THEME str current GUI theme required themes dict dictionary of theme colors required Returns: Type Description None Source code in src/controller/plots/array_map.py def update_minimap_indicator ( app , CURRENT_THEME : str , themes : dict ): # this is called on cursor click + on setup \"\"\"add a square around electrodes displayed in the minimap Args: app: MainWindow CURRENT_THEME: current GUI theme themes: dictionary of theme colors Returns: None \"\"\" minimap_square_indicator = pg . QtGui . QGraphicsRectItem ( app . settings [ 'cursor_row' ] - 4.5 , app . settings [ 'cursor_col' ] - 2.5 , 8 , 4 ) minimap_square_indicator . setPen ( pg . mkPen ( themes [ CURRENT_THEME ][ 'blue3' ])) minimap_square_indicator . setBrush ( QColor ( 255 , 0 , 255 , 0 )) app . update_subplot_element ( \"arrayMap\" , 'minimap_square_indicator' , minimap_square_indicator )","title":"update_minimap_indicator()"},{"location":"controller/plots/channel_trace/","text":"setupSpikeTrace ( list_of_plots , CURRENT_THEME , themes ) Parameters: Name Type Description Default list_of_plots required CURRENT_THEME required themes required Source code in src/controller/plots/channel_trace.py def setupSpikeTrace ( list_of_plots , CURRENT_THEME , themes ): \"\"\" Args: list_of_plots: CURRENT_THEME: themes: Returns: \"\"\" for plot in list_of_plots : plot . getAxis ( \"left\" ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ]) plot . getAxis ( \"bottom\" ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ]) plot . getAxis ( 'top' ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ]) plot . setLabel ( 'left' , '# ???' ) plot . setLabel ( 'bottom' , 'Time (ms)' ) update_channel_trace_plot ( app , next_packet , CURRENT_THEME , themes , extra_params ) This function updates the model for the trace plots when a new packet arrives. The plots are updated even faster through 'continuouslyUpdateTracePlotData()', which scans through the packet slowly to visualize model as realtime. Parameters: Name Type Description Default trace_plots required Source code in src/controller/plots/channel_trace.py def update_channel_trace_plot ( app , next_packet , CURRENT_THEME , themes , extra_params ): \"\"\" This function updates the model for the trace plots when a new packet arrives. The plots are updated even faster through 'continuouslyUpdateTracePlotData()', which scans through the packet slowly to visualize model as realtime. Args: trace_plots: Returns: \"\"\" trace_plots = extra_params # Generate subplots for m , plt in enumerate ( trace_plots ): plt . clear () times = next_packet [ \"packet_data\" ][ m ][ \"times\" ] data = next_packet [ \"packet_data\" ][ m ][ \"filtered_data\" ] chan_idx = next_packet [ \"packet_data\" ][ m ][ \"channel_idx\" ] from src.model.data_loading_mat import idx2map row , col = idx2map ( chan_idx ) # crop to area where model != 0 nonzero_data = np . where ( data != 0. )[ 0 ] first_nonzero_index = nonzero_data [ 0 ] last_nonzero_index = nonzero_data [ - 1 ] # TODO [later] check why the dims of times and model don't match # crop to range data = data [ first_nonzero_index : last_nonzero_index ] times = times [ first_nonzero_index : last_nonzero_index ] begin_time = times [ 0 ] end_time = times [ - 1 ] # TODO [later] more principled way of doing x and y range WIDTH_OF_TIME_TO_DISPLAY = 250 center_time = ( end_time - begin_time ) / 2 #plt.setXRange(begin_time + center_time - WIDTH_OF_TIME_TO_DISPLAY/2, # begin_time + center_time + WIDTH_OF_TIME_TO_DISPLAY/2, # padding=0) channel_noise_mean = app . data . df . at [ chan_idx , \"noise_mean\" ] channel_noise_std = app . data . df . at [ chan_idx , \"noise_std\" ] # channel_noise_mean = app.model.array_indexed[\"stats_noise+mean\"][row][col] # channel_noise_std = app.model.array_indexed[\"stats_noise+std\"][row][col] plt . setYRange ( channel_noise_mean - 10 * channel_noise_std , channel_noise_mean + 10 * channel_noise_std , padding = 0 ) tooltip_text = '<html>Trace signal of electrode #' + str ( chan_idx ) + \\ '<br>Row ' + str ( row ) + ', Column ' + str ( col ) + \\ '<br>From time ' + str ( round ( begin_time , 2 )) + 's to ' + str ( round ( end_time , 2 )) + \\ 's after this recording started.' + \\ '<\\html>' plt . setToolTip ( tooltip_text ) # TODO add channel name as the background plt . getAxis ( \"left\" ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ], size = '20pt' ) plt . setLabel ( 'left' , 'Ch ' + str ( next_packet [ 'packet_data' ][ m ][ 'channel_idx' ])) plt . plot ( times , data )","title":"channel trace"},{"location":"controller/plots/channel_trace/#src.controller.plots.channel_trace.setupSpikeTrace","text":"Parameters: Name Type Description Default list_of_plots required CURRENT_THEME required themes required Source code in src/controller/plots/channel_trace.py def setupSpikeTrace ( list_of_plots , CURRENT_THEME , themes ): \"\"\" Args: list_of_plots: CURRENT_THEME: themes: Returns: \"\"\" for plot in list_of_plots : plot . getAxis ( \"left\" ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ]) plot . getAxis ( \"bottom\" ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ]) plot . getAxis ( 'top' ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ]) plot . setLabel ( 'left' , '# ???' ) plot . setLabel ( 'bottom' , 'Time (ms)' )","title":"setupSpikeTrace()"},{"location":"controller/plots/channel_trace/#src.controller.plots.channel_trace.update_channel_trace_plot","text":"This function updates the model for the trace plots when a new packet arrives. The plots are updated even faster through 'continuouslyUpdateTracePlotData()', which scans through the packet slowly to visualize model as realtime. Parameters: Name Type Description Default trace_plots required Source code in src/controller/plots/channel_trace.py def update_channel_trace_plot ( app , next_packet , CURRENT_THEME , themes , extra_params ): \"\"\" This function updates the model for the trace plots when a new packet arrives. The plots are updated even faster through 'continuouslyUpdateTracePlotData()', which scans through the packet slowly to visualize model as realtime. Args: trace_plots: Returns: \"\"\" trace_plots = extra_params # Generate subplots for m , plt in enumerate ( trace_plots ): plt . clear () times = next_packet [ \"packet_data\" ][ m ][ \"times\" ] data = next_packet [ \"packet_data\" ][ m ][ \"filtered_data\" ] chan_idx = next_packet [ \"packet_data\" ][ m ][ \"channel_idx\" ] from src.model.data_loading_mat import idx2map row , col = idx2map ( chan_idx ) # crop to area where model != 0 nonzero_data = np . where ( data != 0. )[ 0 ] first_nonzero_index = nonzero_data [ 0 ] last_nonzero_index = nonzero_data [ - 1 ] # TODO [later] check why the dims of times and model don't match # crop to range data = data [ first_nonzero_index : last_nonzero_index ] times = times [ first_nonzero_index : last_nonzero_index ] begin_time = times [ 0 ] end_time = times [ - 1 ] # TODO [later] more principled way of doing x and y range WIDTH_OF_TIME_TO_DISPLAY = 250 center_time = ( end_time - begin_time ) / 2 #plt.setXRange(begin_time + center_time - WIDTH_OF_TIME_TO_DISPLAY/2, # begin_time + center_time + WIDTH_OF_TIME_TO_DISPLAY/2, # padding=0) channel_noise_mean = app . data . df . at [ chan_idx , \"noise_mean\" ] channel_noise_std = app . data . df . at [ chan_idx , \"noise_std\" ] # channel_noise_mean = app.model.array_indexed[\"stats_noise+mean\"][row][col] # channel_noise_std = app.model.array_indexed[\"stats_noise+std\"][row][col] plt . setYRange ( channel_noise_mean - 10 * channel_noise_std , channel_noise_mean + 10 * channel_noise_std , padding = 0 ) tooltip_text = '<html>Trace signal of electrode #' + str ( chan_idx ) + \\ '<br>Row ' + str ( row ) + ', Column ' + str ( col ) + \\ '<br>From time ' + str ( round ( begin_time , 2 )) + 's to ' + str ( round ( end_time , 2 )) + \\ 's after this recording started.' + \\ '<\\html>' plt . setToolTip ( tooltip_text ) # TODO add channel name as the background plt . getAxis ( \"left\" ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ], size = '20pt' ) plt . setLabel ( 'left' , 'Ch ' + str ( next_packet [ 'packet_data' ][ m ][ 'channel_idx' ])) plt . plot ( times , data )","title":"update_channel_trace_plot()"},{"location":"controller/plots/mini_map/","text":"minimap_gui_update_fn ( x , y , data ) Parameters: Name Type Description Default x required y required data required Source code in src/controller/plots/mini_map.py def minimap_gui_update_fn ( x , y , data ): \"\"\" Args: x: y: data: Returns: \"\"\" spike_times , spike_amps , elec_idx = data [ \"spike_times_normed\" ], data [ \"spike_amps_normed\" ], data [ \"idx\" ] # draw a horizontal bar at the bottom with the index of the electrode bar_ref = pg . QtGui . QGraphicsRectItem ( x , y , 4 , 0.5 ) # width, height bar_ref . setPen ( pg . mkPen ( data [ \"themes\" ][ data [ \"CURRENT_THEME\" ]][ 'bar_color' ])) bar_ref . setBrush ( pg . mkPen ( data [ \"themes\" ][ data [ \"CURRENT_THEME\" ]][ 'bar_color' ])) # draw a number next to the bar elec_idx = data [ \"idx\" ] bar_text_ref = pg . TextItem ( elec_idx , data [ \"themes\" ][ data [ \"CURRENT_THEME\" ]][ 'font_color' ], anchor = ( 0 , 0 )) bar_text_ref . setPos ( x , y ) bar_text_ref . setParentItem ( bar_ref ) # and then draw the spikes BAR_LENGTH = 2 list_of_spike_refs = [] for ( spike_time , spike_amp ) in zip ( spike_times , spike_amps ): spike_ref = pg . QtGui . QGraphicsRectItem ( x + spike_time * BAR_LENGTH , y , 0.5 , spike_amp ) spike_ref . setPen ( pg . mkPen ( spike_color )) spike_ref . setBrush ( pg . mkBrush ( spike_color )) list_of_spike_refs . append ( spike_ref ) shape_refs = { 'bar' : bar_ref , 'bar_text' : bar_text_ref , 'spikes' : list_of_spike_refs } return shape_refs setupMiniMapPlot ( app , plot_widget , CURRENT_THEME , themes , center_row = 16 , center_col = 16 ) Parameters: Name Type Description Default app required plot_widget required CURRENT_THEME required themes required center_row 16 center_col 16 Source code in src/controller/plots/mini_map.py def setupMiniMapPlot ( app , plot_widget , CURRENT_THEME , themes , center_row = 16 , center_col = 16 ): \"\"\" Args: app: plot_widget: CURRENT_THEME: themes: center_row: center_col: Returns: \"\"\" plot_widget . showGrid ( x = True , y = True , alpha = 0 ) plot_widget . getPlotItem () . hideAxis ( 'bottom' ) plot_widget . getPlotItem () . hideAxis ( 'left' ) plot_widget . enableAutoRange ( axis = 'x' , enable = True ) plot_widget . enableAutoRange ( axis = 'y' , enable = True ) plot_widget . setAspectLocked () update_mini_map_plot ( app , next_packet , CURRENT_THEME , themes , extra_params ) Parameters: Name Type Description Default app required next_packet required CURRENT_THEME required themes required extra_params required Source code in src/controller/plots/mini_map.py def update_mini_map_plot ( app , next_packet , CURRENT_THEME , themes , extra_params ): \"\"\" Args: app: next_packet: CURRENT_THEME: themes: extra_params: Returns: \"\"\" app . charts [ \"miniMap\" ] . clear () BAR_LENGTH = 4 # same as self.settings['binSize'] but for the minimap. # so that the view doesn't freeze # TODO MIN_BIN_LENGTH = 4 MAX_SPIKES = 16 # can't draw every spike or view will crash -> group spikes together curr_idxs = [] for packet in next_packet [ 'packet_data' ]: curr_idxs . append ( packet [ 'channel_idx' ]) # make a legend legend_loc_x = app . settings [ 'cursor_row' ] - 4 - 1.5 legend_loc_y = app . settings [ 'cursor_col' ] - 2 spike_indicator_base = pg . QtGui . QGraphicsRectItem ( legend_loc_x * 5 , legend_loc_y * 5 , BAR_LENGTH , 0.2 ) spike_indicator_base . setPen ( pg . mkPen ( themes [ CURRENT_THEME ][ 'blue1' ])) spike_indicator_base . setBrush ( pg . mkBrush ( themes [ CURRENT_THEME ][ 'blue1' ])) legend_text = str ( round ( app . data . buffer_indexed [ 0 ][ \"time_elapsed\" ], 0 )) + \" ms\" spike_indicator_text = pg . TextItem ( legend_text , themes [ CURRENT_THEME ][ 'font_color' ], anchor = ( 0 , 0 )) spike_indicator_text . setPos ( legend_loc_x * 5 , legend_loc_y * 5 ) spike_indicator_text . setParentItem ( spike_indicator_base ) app . charts [ \"miniMap\" ] . addItem ( spike_indicator_base ) app . charts [ \"miniMap\" ] . addItem ( spike_indicator_text ) # now visualize the selected electrodes in the window of the minimap for row in range ( app . settings [ 'cursor_row' ] - 4 , app . settings [ 'cursor_row' ] + 4 ): for col in range ( app . settings [ 'cursor_col' ] - 2 , app . settings [ 'cursor_col' ] + 2 ): if ( row > - 2 ) and ( col > - 2 ): from src.model.data_loading_mat import map2idx elec_idx = str ( map2idx ( col , row )) spike_indicator_base = pg . QtGui . QGraphicsRectItem ( row * 5 , col * 5 , BAR_LENGTH , 0.2 ) if elec_idx not in curr_idxs : spike_indicator_base . setPen ( pg . mkPen ( themes [ CURRENT_THEME ][ 'blue1' ])) spike_indicator_base . setBrush ( pg . mkBrush ( themes [ CURRENT_THEME ][ 'blue1' ])) else : spike_indicator_base . setPen ( pg . mkPen ( themes [ CURRENT_THEME ][ 'orange' ])) spike_indicator_base . setBrush ( pg . mkBrush ( themes [ CURRENT_THEME ][ 'orange' ])) spike_indicator_text = pg . TextItem ( elec_idx , themes [ CURRENT_THEME ][ 'font_color' ], anchor = ( 0 , 0 )) spike_indicator_text . setPos ( row * 5 , col * 5 ) spike_indicator_text . setParentItem ( spike_indicator_base ) app . charts [ \"miniMap\" ] . addItem ( spike_indicator_base ) app . charts [ \"miniMap\" ] . addItem ( spike_indicator_text ) spike_bins = app . data . array_spike_times [ \"spike_bins\" ][ int ( elec_idx )] spike_bins_max_amps = app . data . array_spike_times [ \"spike_bins_max_amps\" ][ int ( elec_idx )] spikeLocs = np . argwhere ( spike_bins == True ) num_bins = len ( spike_bins ) for i in spikeLocs : spike_loc_on_vis_bar = ( i / num_bins ) * BAR_LENGTH spike_height_on_vis_bar = np . abs ( spike_bins_max_amps [ i ] / 20 ) spike_indicator = pg . QtGui . QGraphicsRectItem ( row * 5 + spike_loc_on_vis_bar , col * 5 , 0.03 , spike_height_on_vis_bar ) spike_indicator . setPen ( pg . mkPen ( themes [ CURRENT_THEME ][ 'blue1' ])) spike_indicator . setBrush ( pg . mkBrush ( themes [ CURRENT_THEME ][ 'blue1' ])) spike_indicator . setParentItem ( spike_indicator_base ) app . charts [ \"miniMap\" ] . addItem ( spike_indicator )","title":"mini map"},{"location":"controller/plots/mini_map/#src.controller.plots.mini_map.minimap_gui_update_fn","text":"Parameters: Name Type Description Default x required y required data required Source code in src/controller/plots/mini_map.py def minimap_gui_update_fn ( x , y , data ): \"\"\" Args: x: y: data: Returns: \"\"\" spike_times , spike_amps , elec_idx = data [ \"spike_times_normed\" ], data [ \"spike_amps_normed\" ], data [ \"idx\" ] # draw a horizontal bar at the bottom with the index of the electrode bar_ref = pg . QtGui . QGraphicsRectItem ( x , y , 4 , 0.5 ) # width, height bar_ref . setPen ( pg . mkPen ( data [ \"themes\" ][ data [ \"CURRENT_THEME\" ]][ 'bar_color' ])) bar_ref . setBrush ( pg . mkPen ( data [ \"themes\" ][ data [ \"CURRENT_THEME\" ]][ 'bar_color' ])) # draw a number next to the bar elec_idx = data [ \"idx\" ] bar_text_ref = pg . TextItem ( elec_idx , data [ \"themes\" ][ data [ \"CURRENT_THEME\" ]][ 'font_color' ], anchor = ( 0 , 0 )) bar_text_ref . setPos ( x , y ) bar_text_ref . setParentItem ( bar_ref ) # and then draw the spikes BAR_LENGTH = 2 list_of_spike_refs = [] for ( spike_time , spike_amp ) in zip ( spike_times , spike_amps ): spike_ref = pg . QtGui . QGraphicsRectItem ( x + spike_time * BAR_LENGTH , y , 0.5 , spike_amp ) spike_ref . setPen ( pg . mkPen ( spike_color )) spike_ref . setBrush ( pg . mkBrush ( spike_color )) list_of_spike_refs . append ( spike_ref ) shape_refs = { 'bar' : bar_ref , 'bar_text' : bar_text_ref , 'spikes' : list_of_spike_refs } return shape_refs","title":"minimap_gui_update_fn()"},{"location":"controller/plots/mini_map/#src.controller.plots.mini_map.setupMiniMapPlot","text":"Parameters: Name Type Description Default app required plot_widget required CURRENT_THEME required themes required center_row 16 center_col 16 Source code in src/controller/plots/mini_map.py def setupMiniMapPlot ( app , plot_widget , CURRENT_THEME , themes , center_row = 16 , center_col = 16 ): \"\"\" Args: app: plot_widget: CURRENT_THEME: themes: center_row: center_col: Returns: \"\"\" plot_widget . showGrid ( x = True , y = True , alpha = 0 ) plot_widget . getPlotItem () . hideAxis ( 'bottom' ) plot_widget . getPlotItem () . hideAxis ( 'left' ) plot_widget . enableAutoRange ( axis = 'x' , enable = True ) plot_widget . enableAutoRange ( axis = 'y' , enable = True ) plot_widget . setAspectLocked ()","title":"setupMiniMapPlot()"},{"location":"controller/plots/mini_map/#src.controller.plots.mini_map.update_mini_map_plot","text":"Parameters: Name Type Description Default app required next_packet required CURRENT_THEME required themes required extra_params required Source code in src/controller/plots/mini_map.py def update_mini_map_plot ( app , next_packet , CURRENT_THEME , themes , extra_params ): \"\"\" Args: app: next_packet: CURRENT_THEME: themes: extra_params: Returns: \"\"\" app . charts [ \"miniMap\" ] . clear () BAR_LENGTH = 4 # same as self.settings['binSize'] but for the minimap. # so that the view doesn't freeze # TODO MIN_BIN_LENGTH = 4 MAX_SPIKES = 16 # can't draw every spike or view will crash -> group spikes together curr_idxs = [] for packet in next_packet [ 'packet_data' ]: curr_idxs . append ( packet [ 'channel_idx' ]) # make a legend legend_loc_x = app . settings [ 'cursor_row' ] - 4 - 1.5 legend_loc_y = app . settings [ 'cursor_col' ] - 2 spike_indicator_base = pg . QtGui . QGraphicsRectItem ( legend_loc_x * 5 , legend_loc_y * 5 , BAR_LENGTH , 0.2 ) spike_indicator_base . setPen ( pg . mkPen ( themes [ CURRENT_THEME ][ 'blue1' ])) spike_indicator_base . setBrush ( pg . mkBrush ( themes [ CURRENT_THEME ][ 'blue1' ])) legend_text = str ( round ( app . data . buffer_indexed [ 0 ][ \"time_elapsed\" ], 0 )) + \" ms\" spike_indicator_text = pg . TextItem ( legend_text , themes [ CURRENT_THEME ][ 'font_color' ], anchor = ( 0 , 0 )) spike_indicator_text . setPos ( legend_loc_x * 5 , legend_loc_y * 5 ) spike_indicator_text . setParentItem ( spike_indicator_base ) app . charts [ \"miniMap\" ] . addItem ( spike_indicator_base ) app . charts [ \"miniMap\" ] . addItem ( spike_indicator_text ) # now visualize the selected electrodes in the window of the minimap for row in range ( app . settings [ 'cursor_row' ] - 4 , app . settings [ 'cursor_row' ] + 4 ): for col in range ( app . settings [ 'cursor_col' ] - 2 , app . settings [ 'cursor_col' ] + 2 ): if ( row > - 2 ) and ( col > - 2 ): from src.model.data_loading_mat import map2idx elec_idx = str ( map2idx ( col , row )) spike_indicator_base = pg . QtGui . QGraphicsRectItem ( row * 5 , col * 5 , BAR_LENGTH , 0.2 ) if elec_idx not in curr_idxs : spike_indicator_base . setPen ( pg . mkPen ( themes [ CURRENT_THEME ][ 'blue1' ])) spike_indicator_base . setBrush ( pg . mkBrush ( themes [ CURRENT_THEME ][ 'blue1' ])) else : spike_indicator_base . setPen ( pg . mkPen ( themes [ CURRENT_THEME ][ 'orange' ])) spike_indicator_base . setBrush ( pg . mkBrush ( themes [ CURRENT_THEME ][ 'orange' ])) spike_indicator_text = pg . TextItem ( elec_idx , themes [ CURRENT_THEME ][ 'font_color' ], anchor = ( 0 , 0 )) spike_indicator_text . setPos ( row * 5 , col * 5 ) spike_indicator_text . setParentItem ( spike_indicator_base ) app . charts [ \"miniMap\" ] . addItem ( spike_indicator_base ) app . charts [ \"miniMap\" ] . addItem ( spike_indicator_text ) spike_bins = app . data . array_spike_times [ \"spike_bins\" ][ int ( elec_idx )] spike_bins_max_amps = app . data . array_spike_times [ \"spike_bins_max_amps\" ][ int ( elec_idx )] spikeLocs = np . argwhere ( spike_bins == True ) num_bins = len ( spike_bins ) for i in spikeLocs : spike_loc_on_vis_bar = ( i / num_bins ) * BAR_LENGTH spike_height_on_vis_bar = np . abs ( spike_bins_max_amps [ i ] / 20 ) spike_indicator = pg . QtGui . QGraphicsRectItem ( row * 5 + spike_loc_on_vis_bar , col * 5 , 0.03 , spike_height_on_vis_bar ) spike_indicator . setPen ( pg . mkPen ( themes [ CURRENT_THEME ][ 'blue1' ])) spike_indicator . setBrush ( pg . mkBrush ( themes [ CURRENT_THEME ][ 'blue1' ])) spike_indicator . setParentItem ( spike_indicator_base ) app . charts [ \"miniMap\" ] . addItem ( spike_indicator )","title":"update_mini_map_plot()"},{"location":"controller/plots/noise_heatmap/","text":"update_noise_heat_map ( app , next_packet , CURRENT_THEME , themes , extra_params , debug = False ) Parameters: Name Type Description Default app required next_packet required CURRENT_THEME required themes required extra_params required debug False Source code in src/controller/plots/noise_heatmap.py def update_noise_heat_map ( app , next_packet , CURRENT_THEME , themes , extra_params , debug = False ): \"\"\" Args: app: next_packet: CURRENT_THEME: themes: extra_params: debug: Returns: \"\"\" plot = app . charts [ \"noiseHeatMap\" ] plot . clear () font = pg . QtGui . QFont () font . setPixelSize ( 20 ) plot . getAxis ( \"bottom\" ) . tickFont = font plot . getAxis ( \"bottom\" ) . setStyle ( tickTextOffset = 1 ) if app . first_time_plotting is False : data = app . data . df [ \"noise_std\" ] #model = app.model.array_indexed[\"stats_noise+std\"] data = data . T else : data = None img = pg . ImageItem ( data ) cm = pg . colormap . get ( 'plasma' , source = 'matplotlib' ) plot . addItem ( img ) if app . noise_heat_map_color_bar is None : app . noise_heat_map_color_bar = app . charts [ \"noiseHeatMap\" ] . addColorBar ( img , colorMap = cm , label = \"Noise SD\" , values = ( 0 , 5 )) else : app . noise_heat_map_color_bar . setImageItem ( img ) app . first_time_plotting = False if debug : print ( \"Data\" + str ( data ))","title":"noise heatmap"},{"location":"controller/plots/noise_heatmap/#src.controller.plots.noise_heatmap.update_noise_heat_map","text":"Parameters: Name Type Description Default app required next_packet required CURRENT_THEME required themes required extra_params required debug False Source code in src/controller/plots/noise_heatmap.py def update_noise_heat_map ( app , next_packet , CURRENT_THEME , themes , extra_params , debug = False ): \"\"\" Args: app: next_packet: CURRENT_THEME: themes: extra_params: debug: Returns: \"\"\" plot = app . charts [ \"noiseHeatMap\" ] plot . clear () font = pg . QtGui . QFont () font . setPixelSize ( 20 ) plot . getAxis ( \"bottom\" ) . tickFont = font plot . getAxis ( \"bottom\" ) . setStyle ( tickTextOffset = 1 ) if app . first_time_plotting is False : data = app . data . df [ \"noise_std\" ] #model = app.model.array_indexed[\"stats_noise+std\"] data = data . T else : data = None img = pg . ImageItem ( data ) cm = pg . colormap . get ( 'plasma' , source = 'matplotlib' ) plot . addItem ( img ) if app . noise_heat_map_color_bar is None : app . noise_heat_map_color_bar = app . charts [ \"noiseHeatMap\" ] . addColorBar ( img , colorMap = cm , label = \"Noise SD\" , values = ( 0 , 5 )) else : app . noise_heat_map_color_bar . setImageItem ( img ) app . first_time_plotting = False if debug : print ( \"Data\" + str ( data ))","title":"update_noise_heat_map()"},{"location":"controller/plots/spike_rate/","text":"setupSpikeRatePlot ( plot_widget , CURRENT_THEME , themes ) Parameters: Name Type Description Default plot_widget required CURRENT_THEME required themes required Source code in src/controller/plots/spike_rate.py def setupSpikeRatePlot ( plot_widget , CURRENT_THEME , themes ): \"\"\" Args: plot_widget: CURRENT_THEME: themes: Returns: \"\"\" plot_widget . getAxis ( \"left\" ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ]) plot_widget . getAxis ( \"bottom\" ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ]) plot_widget . getAxis ( 'top' ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ]) plot_widget . showGrid ( x = True , y = True , alpha = 0 ) plot_widget . enableAutoRange ( axis = 'x' , enable = True ) plot_widget . enableAutoRange ( axis = 'y' , enable = True ) plot_widget . setLimits ( xMin = 0 , yMin = 0 ) plot_widget . getPlotItem () . hideAxis ( 'top' ) plot_widget . setLabel ( 'left' , \"Spike Rate\" , size = '12pt' , color = themes [ CURRENT_THEME ][ 'font_color' ]) plot_widget . setLabel ( 'bottom' , \"Time (ms)\" , size = '12pt' , color = themes [ CURRENT_THEME ][ 'font_color' ]) plot_widget . setTitle ( \"Array Spike Rate\" , size = '14pt' , color = themes [ CURRENT_THEME ][ 'font_color' ]) plot_widget . setLimits ( xMin = 0 , yMin = 0 , minXRange = 5 ) plot_widget . setLimits ( xMin = 0 , yMin =- 5 , minXRange = 5 ) plot_widget . enableAutoRange ( axis = 'x' ) update_spike_rate_plot ( app , next_packet , CURRENT_THEME , themes , extra_params , debug = False ) Parameters: Name Type Description Default app required next_packet required CURRENT_THEME required themes required extra_params required debug False Source code in src/controller/plots/spike_rate.py def update_spike_rate_plot ( app , next_packet , CURRENT_THEME , themes , extra_params , debug = False ): \"\"\" Args: app: next_packet: CURRENT_THEME: themes: extra_params: debug: Returns: \"\"\" app . charts [ \"spikeRatePlot\" ] . clear () #print(\"avgspikerate x/y\", app.model.avg_spike_rate_x, app.model.avg_spike_rate_y) app . charts [ \"spikeRatePlot\" ] . plot ( app . data . avg_spike_rate_x , app . data . avg_spike_rate_y , pen = pg . mkPen ( themes [ CURRENT_THEME ][ 'font_color' ], width = 5 ))","title":"spike rate"},{"location":"controller/plots/spike_rate/#src.controller.plots.spike_rate.setupSpikeRatePlot","text":"Parameters: Name Type Description Default plot_widget required CURRENT_THEME required themes required Source code in src/controller/plots/spike_rate.py def setupSpikeRatePlot ( plot_widget , CURRENT_THEME , themes ): \"\"\" Args: plot_widget: CURRENT_THEME: themes: Returns: \"\"\" plot_widget . getAxis ( \"left\" ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ]) plot_widget . getAxis ( \"bottom\" ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ]) plot_widget . getAxis ( 'top' ) . setTextPen ( themes [ CURRENT_THEME ][ 'font_color' ]) plot_widget . showGrid ( x = True , y = True , alpha = 0 ) plot_widget . enableAutoRange ( axis = 'x' , enable = True ) plot_widget . enableAutoRange ( axis = 'y' , enable = True ) plot_widget . setLimits ( xMin = 0 , yMin = 0 ) plot_widget . getPlotItem () . hideAxis ( 'top' ) plot_widget . setLabel ( 'left' , \"Spike Rate\" , size = '12pt' , color = themes [ CURRENT_THEME ][ 'font_color' ]) plot_widget . setLabel ( 'bottom' , \"Time (ms)\" , size = '12pt' , color = themes [ CURRENT_THEME ][ 'font_color' ]) plot_widget . setTitle ( \"Array Spike Rate\" , size = '14pt' , color = themes [ CURRENT_THEME ][ 'font_color' ]) plot_widget . setLimits ( xMin = 0 , yMin = 0 , minXRange = 5 ) plot_widget . setLimits ( xMin = 0 , yMin =- 5 , minXRange = 5 ) plot_widget . enableAutoRange ( axis = 'x' )","title":"setupSpikeRatePlot()"},{"location":"controller/plots/spike_rate/#src.controller.plots.spike_rate.update_spike_rate_plot","text":"Parameters: Name Type Description Default app required next_packet required CURRENT_THEME required themes required extra_params required debug False Source code in src/controller/plots/spike_rate.py def update_spike_rate_plot ( app , next_packet , CURRENT_THEME , themes , extra_params , debug = False ): \"\"\" Args: app: next_packet: CURRENT_THEME: themes: extra_params: debug: Returns: \"\"\" app . charts [ \"spikeRatePlot\" ] . clear () #print(\"avgspikerate x/y\", app.model.avg_spike_rate_x, app.model.avg_spike_rate_y) app . charts [ \"spikeRatePlot\" ] . plot ( app . data . avg_spike_rate_x , app . data . avg_spike_rate_y , pen = pg . mkPen ( themes [ CURRENT_THEME ][ 'font_color' ], width = 5 ))","title":"update_spike_rate_plot()"},{"location":"controller/windows/window_electrodelist/","text":"DataFrameModel ( QAbstractTableModel ) Source code in src/controller/windows/window_electrodelist.py class DataFrameModel ( QtCore . QAbstractTableModel ): DtypeRole = QtCore . Qt . UserRole + 1000 ValueRole = QtCore . Qt . UserRole + 1001 def __init__ ( self , df = pd . DataFrame (), parent = None ): super ( DataFrameModel , self ) . __init__ ( parent ) self . _dataframe = df def setDataFrame ( self , dataframe ): self . beginResetModel () self . _dataframe = dataframe . copy () self . endResetModel () def dataFrame ( self ): return self . _dataframe dataFrame = QtCore . pyqtProperty ( pd . DataFrame , fget = dataFrame , fset = setDataFrame ) @QtCore . pyqtSlot ( int , QtCore . Qt . Orientation , result = str ) def headerData ( self , section : int , orientation : QtCore . Qt . Orientation , role : int = QtCore . Qt . DisplayRole ): if role == QtCore . Qt . DisplayRole : if orientation == QtCore . Qt . Horizontal : return self . _dataframe . columns [ section ] else : return str ( self . _dataframe . index [ section ]) return QtCore . QVariant () def rowCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return len ( self . _dataframe . index ) def columnCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return self . _dataframe . columns . size def data ( self , index , role = QtCore . Qt . DisplayRole ): if not index . isValid () or not ( 0 <= index . row () < self . rowCount () \\ and 0 <= index . column () < self . columnCount ()): return QtCore . QVariant () row = self . _dataframe . index [ index . row ()] col = self . _dataframe . columns [ index . column ()] dt = self . _dataframe [ col ] . dtype val = self . _dataframe . iloc [ row ][ col ] if role == QtCore . Qt . DisplayRole : return str ( val ) elif role == DataFrameModel . ValueRole : return val if role == DataFrameModel . DtypeRole : return dt return QtCore . QVariant () def roleNames ( self ): roles = { QtCore . Qt . DisplayRole : b 'display' , DataFrameModel . DtypeRole : b 'dtype' , DataFrameModel . ValueRole : b 'value' } return roles # see MainWindow.update_theme() for how this is called def update_theme ( self , current_theme , themes ): pass columnCount ( self , parent =< PyQt5 . QtCore . QModelIndex object at 0x7f90224edb50 > ) columnCount(self, parent: QModelIndex = QModelIndex()) -> int Source code in src/controller/windows/window_electrodelist.py def columnCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return self . _dataframe . columns . size data ( self , index , role = 0 ) data(self, QModelIndex, role: int = Qt.ItemDataRole.DisplayRole) -> Any Source code in src/controller/windows/window_electrodelist.py def data ( self , index , role = QtCore . Qt . DisplayRole ): if not index . isValid () or not ( 0 <= index . row () < self . rowCount () \\ and 0 <= index . column () < self . columnCount ()): return QtCore . QVariant () row = self . _dataframe . index [ index . row ()] col = self . _dataframe . columns [ index . column ()] dt = self . _dataframe [ col ] . dtype val = self . _dataframe . iloc [ row ][ col ] if role == QtCore . Qt . DisplayRole : return str ( val ) elif role == DataFrameModel . ValueRole : return val if role == DataFrameModel . DtypeRole : return dt return QtCore . QVariant () headerData ( self , section , orientation , role = 0 ) headerData(self, int, Qt.Orientation, role: int = Qt.ItemDataRole.DisplayRole) -> Any Source code in src/controller/windows/window_electrodelist.py @QtCore . pyqtSlot ( int , QtCore . Qt . Orientation , result = str ) def headerData ( self , section : int , orientation : QtCore . Qt . Orientation , role : int = QtCore . Qt . DisplayRole ): if role == QtCore . Qt . DisplayRole : if orientation == QtCore . Qt . Horizontal : return self . _dataframe . columns [ section ] else : return str ( self . _dataframe . index [ section ]) return QtCore . QVariant () roleNames ( self ) roleNames(self) -> Dict[int, QByteArray] Source code in src/controller/windows/window_electrodelist.py def roleNames ( self ): roles = { QtCore . Qt . DisplayRole : b 'display' , DataFrameModel . DtypeRole : b 'dtype' , DataFrameModel . ValueRole : b 'value' } return roles rowCount ( self , parent =< PyQt5 . QtCore . QModelIndex object at 0x7f90224edad0 > ) rowCount(self, parent: QModelIndex = QModelIndex()) -> int Source code in src/controller/windows/window_electrodelist.py def rowCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return len ( self . _dataframe . index ) ElectrodeListInformation ( QWidget ) Source code in src/controller/windows/window_electrodelist.py class ElectrodeListInformation ( QWidget ): app = None current_elec = 0 current_row = 0 current_col = 0 model = None sortOption = None def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) uic . loadUi ( \"./src/view/layouts/AllChannelsList.ui\" , self ) self . sort_by = \"row\" self . chooseSortOption . activated . connect ( self . setSortOption ) def setSessionParent ( self , session_parent ): \"\"\" Args: session_parent: Returns: \"\"\" self . app = session_parent self . model = DataFrameModel ( self . app . data . df ) self . electrodeTable . setModel ( self . model ) self . setTheme () def update ( self ): \"\"\" Returns: \"\"\" self . model = DataFrameModel ( self . app . data . df ) self . model . sort ( 1 ) self . electrodeTable . setModel ( self . model ) def setSortOption ( self ): \"\"\" Returns: \"\"\" self . sortOption = self . chooseSortOption . currentText () print ( \"SORT OPTION: \" + self . sortOption ) self . update () def setTheme ( self ): #background_color = self.settings[\"\"] #self.electrodeTable.setBackground(background_color) # TODO set theme of electrode list pass setSessionParent ( self , session_parent ) Parameters: Name Type Description Default session_parent required Source code in src/controller/windows/window_electrodelist.py def setSessionParent ( self , session_parent ): \"\"\" Args: session_parent: Returns: \"\"\" self . app = session_parent self . model = DataFrameModel ( self . app . data . df ) self . electrodeTable . setModel ( self . model ) self . setTheme () setSortOption ( self ) Source code in src/controller/windows/window_electrodelist.py def setSortOption ( self ): \"\"\" Returns: \"\"\" self . sortOption = self . chooseSortOption . currentText () print ( \"SORT OPTION: \" + self . sortOption ) self . update () update ( self ) Source code in src/controller/windows/window_electrodelist.py def update ( self ): \"\"\" Returns: \"\"\" self . model = DataFrameModel ( self . app . data . df ) self . model . sort ( 1 ) self . electrodeTable . setModel ( self . model )","title":"electrode list"},{"location":"controller/windows/window_electrodelist/#src.controller.windows.window_electrodelist.DataFrameModel","text":"Source code in src/controller/windows/window_electrodelist.py class DataFrameModel ( QtCore . QAbstractTableModel ): DtypeRole = QtCore . Qt . UserRole + 1000 ValueRole = QtCore . Qt . UserRole + 1001 def __init__ ( self , df = pd . DataFrame (), parent = None ): super ( DataFrameModel , self ) . __init__ ( parent ) self . _dataframe = df def setDataFrame ( self , dataframe ): self . beginResetModel () self . _dataframe = dataframe . copy () self . endResetModel () def dataFrame ( self ): return self . _dataframe dataFrame = QtCore . pyqtProperty ( pd . DataFrame , fget = dataFrame , fset = setDataFrame ) @QtCore . pyqtSlot ( int , QtCore . Qt . Orientation , result = str ) def headerData ( self , section : int , orientation : QtCore . Qt . Orientation , role : int = QtCore . Qt . DisplayRole ): if role == QtCore . Qt . DisplayRole : if orientation == QtCore . Qt . Horizontal : return self . _dataframe . columns [ section ] else : return str ( self . _dataframe . index [ section ]) return QtCore . QVariant () def rowCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return len ( self . _dataframe . index ) def columnCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return self . _dataframe . columns . size def data ( self , index , role = QtCore . Qt . DisplayRole ): if not index . isValid () or not ( 0 <= index . row () < self . rowCount () \\ and 0 <= index . column () < self . columnCount ()): return QtCore . QVariant () row = self . _dataframe . index [ index . row ()] col = self . _dataframe . columns [ index . column ()] dt = self . _dataframe [ col ] . dtype val = self . _dataframe . iloc [ row ][ col ] if role == QtCore . Qt . DisplayRole : return str ( val ) elif role == DataFrameModel . ValueRole : return val if role == DataFrameModel . DtypeRole : return dt return QtCore . QVariant () def roleNames ( self ): roles = { QtCore . Qt . DisplayRole : b 'display' , DataFrameModel . DtypeRole : b 'dtype' , DataFrameModel . ValueRole : b 'value' } return roles # see MainWindow.update_theme() for how this is called def update_theme ( self , current_theme , themes ): pass","title":"DataFrameModel"},{"location":"controller/windows/window_electrodelist/#src.controller.windows.window_electrodelist.DataFrameModel.columnCount","text":"columnCount(self, parent: QModelIndex = QModelIndex()) -> int Source code in src/controller/windows/window_electrodelist.py def columnCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return self . _dataframe . columns . size","title":"columnCount()"},{"location":"controller/windows/window_electrodelist/#src.controller.windows.window_electrodelist.DataFrameModel.data","text":"data(self, QModelIndex, role: int = Qt.ItemDataRole.DisplayRole) -> Any Source code in src/controller/windows/window_electrodelist.py def data ( self , index , role = QtCore . Qt . DisplayRole ): if not index . isValid () or not ( 0 <= index . row () < self . rowCount () \\ and 0 <= index . column () < self . columnCount ()): return QtCore . QVariant () row = self . _dataframe . index [ index . row ()] col = self . _dataframe . columns [ index . column ()] dt = self . _dataframe [ col ] . dtype val = self . _dataframe . iloc [ row ][ col ] if role == QtCore . Qt . DisplayRole : return str ( val ) elif role == DataFrameModel . ValueRole : return val if role == DataFrameModel . DtypeRole : return dt return QtCore . QVariant ()","title":"data()"},{"location":"controller/windows/window_electrodelist/#src.controller.windows.window_electrodelist.DataFrameModel.headerData","text":"headerData(self, int, Qt.Orientation, role: int = Qt.ItemDataRole.DisplayRole) -> Any Source code in src/controller/windows/window_electrodelist.py @QtCore . pyqtSlot ( int , QtCore . Qt . Orientation , result = str ) def headerData ( self , section : int , orientation : QtCore . Qt . Orientation , role : int = QtCore . Qt . DisplayRole ): if role == QtCore . Qt . DisplayRole : if orientation == QtCore . Qt . Horizontal : return self . _dataframe . columns [ section ] else : return str ( self . _dataframe . index [ section ]) return QtCore . QVariant ()","title":"headerData()"},{"location":"controller/windows/window_electrodelist/#src.controller.windows.window_electrodelist.DataFrameModel.roleNames","text":"roleNames(self) -> Dict[int, QByteArray] Source code in src/controller/windows/window_electrodelist.py def roleNames ( self ): roles = { QtCore . Qt . DisplayRole : b 'display' , DataFrameModel . DtypeRole : b 'dtype' , DataFrameModel . ValueRole : b 'value' } return roles","title":"roleNames()"},{"location":"controller/windows/window_electrodelist/#src.controller.windows.window_electrodelist.DataFrameModel.rowCount","text":"rowCount(self, parent: QModelIndex = QModelIndex()) -> int Source code in src/controller/windows/window_electrodelist.py def rowCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return len ( self . _dataframe . index )","title":"rowCount()"},{"location":"controller/windows/window_electrodelist/#src.controller.windows.window_electrodelist.ElectrodeListInformation","text":"Source code in src/controller/windows/window_electrodelist.py class ElectrodeListInformation ( QWidget ): app = None current_elec = 0 current_row = 0 current_col = 0 model = None sortOption = None def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) uic . loadUi ( \"./src/view/layouts/AllChannelsList.ui\" , self ) self . sort_by = \"row\" self . chooseSortOption . activated . connect ( self . setSortOption ) def setSessionParent ( self , session_parent ): \"\"\" Args: session_parent: Returns: \"\"\" self . app = session_parent self . model = DataFrameModel ( self . app . data . df ) self . electrodeTable . setModel ( self . model ) self . setTheme () def update ( self ): \"\"\" Returns: \"\"\" self . model = DataFrameModel ( self . app . data . df ) self . model . sort ( 1 ) self . electrodeTable . setModel ( self . model ) def setSortOption ( self ): \"\"\" Returns: \"\"\" self . sortOption = self . chooseSortOption . currentText () print ( \"SORT OPTION: \" + self . sortOption ) self . update () def setTheme ( self ): #background_color = self.settings[\"\"] #self.electrodeTable.setBackground(background_color) # TODO set theme of electrode list pass","title":"ElectrodeListInformation"},{"location":"controller/windows/window_electrodelist/#src.controller.windows.window_electrodelist.ElectrodeListInformation.setSessionParent","text":"Parameters: Name Type Description Default session_parent required Source code in src/controller/windows/window_electrodelist.py def setSessionParent ( self , session_parent ): \"\"\" Args: session_parent: Returns: \"\"\" self . app = session_parent self . model = DataFrameModel ( self . app . data . df ) self . electrodeTable . setModel ( self . model ) self . setTheme ()","title":"setSessionParent()"},{"location":"controller/windows/window_electrodelist/#src.controller.windows.window_electrodelist.ElectrodeListInformation.setSortOption","text":"Source code in src/controller/windows/window_electrodelist.py def setSortOption ( self ): \"\"\" Returns: \"\"\" self . sortOption = self . chooseSortOption . currentText () print ( \"SORT OPTION: \" + self . sortOption ) self . update ()","title":"setSortOption()"},{"location":"controller/windows/window_electrodelist/#src.controller.windows.window_electrodelist.ElectrodeListInformation.update","text":"Source code in src/controller/windows/window_electrodelist.py def update ( self ): \"\"\" Returns: \"\"\" self . model = DataFrameModel ( self . app . data . df ) self . model . sort ( 1 ) self . electrodeTable . setModel ( self . model )","title":"update()"},{"location":"controller/windows/window_individualchannel/","text":"IndividualChannelInformation ( QWidget ) Source code in src/controller/windows/window_individualchannel.py class IndividualChannelInformation ( QWidget ): session_parent = None current_elec = 0 current_row = 0 current_col = 0 recordedTime = None has_data = None # List of dictionaries containing model packets with electrode info (model, times, spikes, etc). # Each packet is for the same electrode, but may have model from different times within recording session electrode_packets = [] # Lists containing values stored in the associated key in electrode_packets dictionaries electrode_times = [] electrode_data = [] electrode_spikes = [] electrode_spike_times = [] individualchannel_charts = {} # dictionary for all different individual channel charts individualchannel_charts_update_mapping = {} # dictionary for mapping charts to their update functions def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) uic . loadUi ( \"./src/view/layouts/IndividualChannelWindow.ui\" , self ) self . updateElectrodeNum . clicked . connect ( self . setElecNum ) self . updateRC . clicked . connect ( self . setRC ) self . individualchannel_charts = { 'ChannelTracePlot' : self . ChannelTracePlot , 'AmplitudeHistPlot' : self . AmplitudeHistPlot , 'SpikeRatePlot' : self . SpikeRatePlot } self . individualchannel_charts_update_mapping = { 'ChannelTracePlot' : self . updateChannelTrace , 'AmplitudeHistPlot' : self . updateAmplitudeHist , 'SpikeRatePlot' : self . updateSpikeRate } def setSessionParent ( self , session_parent ): self . session_parent = session_parent # self.setupCharts() TODO figure why this was here # Note: do NOT change name from \"update\" def update ( self , debug = False ): start = time . time () print ( \"Update individual channels: \" + str ( self . current_elec )) self . updateElectrodeData () # update the charts for chart in self . individualchannel_charts_update_mapping . keys (): self . individualchannel_charts_update_mapping [ chart ]() idx = map2idx ( self . current_row , self . current_col ) if debug : print ( 'std from array stats: ' + str ( self . session_parent . LoadedData . df . at [ idx , \"noise_std\" ])) print ( \"noise mean from array stats: \" + str ( self . session_parent . LoadedData . df . at [ idx , \"noise_mean\" ])) print ( 'std from direct calculation: ' + str ( np . std ( self . electrode_packets [ 0 ][ \"model\" ]))) self . totalSamples . setText ( \"Total number of samples: \" + str ( len ( self . electrode_data ))) self . timeRecorded . setText ( \"Total time recording electrode: \" + str ( self . recordedTime ) + \"ms\" ) self . numSpikes . setText ( \"Number of spikes: \" + str ( sum ( self . electrode_spikes ))) if debug : print ( 'number of spikes from array stats: ' + str ( self . session_parent . LoadedData . array_indexed [ 'spike_cnt' ][ self . current_row ][ self . current_col ])) end = time . time () if self . session_parent . gui_state [ 'is_mode_profiling' ]: print ( \"Individual Channel update time: \" + str ( np . round ( end - start , 2 ))) def updateElectrodeData ( self , debug = False ): self . electrode_packets . clear () self . electrode_spikes . clear () self . electrode_spike_times . clear () self . electrode_data . clear () self . electrode_times . clear () match = False X , Y = self . session_parent . data . get_last_trace_with_electrode_idx ( self . current_elec ) # TODO hook this data with rest of GUI \"\"\" # Create a list of dictionaries of model packets for the selected electrode for i in range(len_filtered_data): if self.session_parent.LoadedData.filtered_data[i]['channel_idx'] == self.current_elec: self.electrode_packets.append(self.session_parent.LoadedData.filtered_data[i]) match = True if debug: if not match: print(\"No model from this electrode yet\") filtered = True if self.session_parent.settings[\"filter\"] == \"None\": filtered = False # Get lists of times and model from each packet for the selected electrode for i in range(len(self.electrode_packets)): self.session_parent.LoadedData.\\ calculate_realtime_spike_info_for_channel_in_buffer(self.electrode_packets[i], filtered) self.electrode_spikes.extend(self.electrode_packets[i][\"spikeBins\"]) self.electrode_spike_times.extend(self.electrode_packets[i][\"incom_spike_times\"]) self.electrode_times.extend(self.electrode_packets[i]['times']) self.electrode_data.extend(self.electrode_packets[i]['model']) self.recordedTime = round((len(self.electrode_data)) * 0.05, 2) \"\"\" def updateAmplitudeHist ( self ): vals = self . electrode_data std = np . std ( vals ) vals = abs ( vals / std ) self . AmplitudeHistPlot . clear () y , x = np . histogram ( vals , bins = np . linspace ( 0 , 20 , 40 )) curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . AmplitudeHistPlot . addItem ( curve ) def updateSpikeRate ( self , movingAverage = True , windowSize = 15 , numberOfUpdates = 10 , debug = False ): \"\"\" movingAverage: If false, divide up the range into numberOfUpdates bins and average to find spike rate windowSize: Size of moving average window in milliseconds numberOfUpdates: How many times you want to update the spike rate if not doing moving average. Function divides the range of model into numberOfUpdates bins to time average spikes. debug: Print helpful model. \"\"\" self . SpikeRatePlot . clear () if debug : print ( \"self.electrode_times: \" + str ( self . electrode_times )) print ( \"self.electrode_spikes: \" + str ( self . electrode_spikes )) print ( \"Length of electrode times: \" + str ( len ( self . electrode_times ))) print ( \"Length of electrode spikes list: \" + str ( len ( self . electrode_spikes ))) spikeList = self . electrode_spikes indexes = np . linspace ( 0 , len ( spikeList ), numberOfUpdates + 1 ) indexes = [ int ( i ) for i in indexes ] t = [] spike_rate = [] # Only run if electrode has been recorded if self . recordedTime != 0 : # Perform moving average on spike list if movingAverage : moving_averages = [] i = 0 while i < len ( spikeList ) - windowSize + 1 : window_average = round ( np . sum ( spikeList [ i : i + windowSize ]) / windowSize , 2 ) moving_averages . append ( 1000 * window_average ) # multiply by 1000 to go to spikes/sec i += 1 t = np . linspace ( self . electrode_times [ 0 ], self . electrode_times [ - 1 ], len ( spikeList ) - windowSize + 1 ) spike_rate = moving_averages # Window modes else : num_spikes = [] for i in range ( numberOfUpdates ): window = spikeList [ indexes [ i ]: indexes [ i + 1 ]] num_spikes . append ( sum ( window )) spike_rate = [ 1000 * num_spike / ( self . recordedTime / numberOfUpdates ) for num_spike in num_spikes ] t = np . linspace ( self . electrode_times [ 0 ], self . electrode_times [ - 1 ], numberOfUpdates ) t = [ int ( i ) for i in t ] else : spike_rate = [ 0 for i in range ( numberOfUpdates )] t = [ 0 for i in range ( numberOfUpdates )] self . SpikeRatePlot . plot ( t , spike_rate , pen = pg . mkPen ( themes [ CURRENT_THEME ][ 'blue1' ], width = 5 )) idx = map2idx ( self . current_row , self . current_col ) if debug : print ( \"length of recording: \" + str ( len ( self . electrode_times )) + \" model points\" ) print ( \"electrode times: \" + str ( self . electrode_times [ 0 ]) + \"-\" + str ( self . electrode_times [ - 1 ])) print ( \"spikes: \" + str ( self . electrode_spikes )) #print(\"double binned spikes: \" + str(num_spikes)) print ( \"number of spike bins: \" + str ( len ( self . electrode_spikes ))) print ( \"incoming spike times: \" + str ( self . electrode_spike_times )) print ( \"noise mean: \" + str ( self . session_parent . LoadedData . df . at [ idx , 'noise_mean' ])) print ( \"noise std: \" + str ( self . session_parent . LoadedData . df . at [ idx , 'noise_std' ])) def updateChannelTrace ( self ): self . ChannelTracePlot . clear () self . ChannelTracePlot . plot ( self . electrode_times , self . electrode_data , pen = 'b' ) self . ChannelTracePlot . enableAutoRange ( axis = 'y' ) self . ChannelTracePlot . setAutoVisible ( y = True ) self . ChannelTracePlot . setLabel ( 'top' , '#' + str ( self . current_elec )) def setRC ( self ): \"\"\" Set the row and column entries and text boxes given an electrode number. Connected to \"Update Row and Column\" button \"\"\" input = self . InputElectrodeNumber . toPlainText () if input . isnumeric (): if 0 <= int ( input ) < 1024 and int ( input ) != self . current_elec : self . current_elec = int ( input ) self . current_row , self . current_col = self . idx2map ( self . current_elec ) self . InputElectrodeRow . setText ( str ( self . current_row )) self . InputElectrodeCol . setText ( str ( self . current_col )) self . update () else : pass self . InputElectrodeNumber . setText ( str ( self . current_elec )) else : pass self . InputElectrodeNumber . setText ( str ( self . current_elec )) def setElecNum ( self ): \"\"\" Given a row and column value, set the electrode number textbox and display plots Connected to the \"\"\" row = self . InputElectrodeRow . toPlainText () col = self . InputElectrodeCol . toPlainText () if row == \"\" : self . current_row = 0 self . InputElectrodeRow . setText ( \"0\" ) if col == \"\" : self . current_col = 0 self . InputElectrodeCol . setText ( \"0\" ) if row . isnumeric () and col . isnumeric (): row = int ( row ) col = int ( col ) if 0 <= row < 32 and row != self . current_row : self . current_row = row else : pass self . InputElectrodeRow . setText ( str ( self . current_row )) if 0 <= col < 32 and col != self . current_col : self . current_col = col else : pass self . InputElectrodeCol . setText ( str ( self . current_col )) self . current_elec = self . map2idx ( self . current_row , self . current_col ) self . update () self . InputElectrodeNumber . setText ( str ( self . current_elec )) def map2idx ( self , ch_row : int , ch_col : int ) -> object : \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx def idx2map ( self , ch_idx : int ): \"\"\" Given a channel index, return the channel's row and col Args: ch_idx: single numerical index for array (up to 1024) Returns: channel row and channel index \"\"\" if ch_idx > 1023 or ch_idx < 0 : print ( 'Chan num out of range' ) return - 1 else : ch_row = int ( ch_idx / 32 ) ch_col = int ( ch_idx - ch_row * 32 ) return ch_row , ch_col # see MainWindow.update_theme() for how this is called def update_theme ( self , current_theme , themes ): background_color = themes [ current_theme ][ \"background_color\" ] background_border = themes [ current_theme ][ \"background_borders\" ] button_color = themes [ current_theme ][ \"button\" ] font_color = themes [ current_theme ][ \"font_color\" ] self . setStyleSheet ( \"background-color: \" + background_border ) self . updateElectrodeNum . setStyleSheet ( \"background-color: \" + button_color ) self . updateRC . setStyleSheet ( \"background-color: \" + button_color ) self . label_elecnum . setStyleSheet ( \"color: \" + font_color ) self . label_2 . setStyleSheet ( \"color: \" + font_color ) self . label_3 . setStyleSheet ( \"color: \" + font_color ) self . numSpikes . setStyleSheet ( \"color: \" + font_color ) self . totalSamples . setStyleSheet ( \"color: \" + font_color ) self . timeRecorded . setStyleSheet ( \"color: \" + font_color ) self . InputElectrodeRow . setStyleSheet ( \"background-color: \" + button_color ) self . InputElectrodeCol . setStyleSheet ( \"background-color: \" + button_color ) self . InputElectrodeNumber . setStyleSheet ( \"background-color: \" + button_color ) for chart in self . individualchannel_charts . keys (): self . individualchannel_charts [ chart ] . setBackground ( background_color ) idx2map ( self , ch_idx ) Given a channel index, return the channel's row and col Parameters: Name Type Description Default ch_idx int single numerical index for array (up to 1024) required Returns: Type Description channel row and channel index Source code in src/controller/windows/window_individualchannel.py def idx2map ( self , ch_idx : int ): \"\"\" Given a channel index, return the channel's row and col Args: ch_idx: single numerical index for array (up to 1024) Returns: channel row and channel index \"\"\" if ch_idx > 1023 or ch_idx < 0 : print ( 'Chan num out of range' ) return - 1 else : ch_row = int ( ch_idx / 32 ) ch_col = int ( ch_idx - ch_row * 32 ) return ch_row , ch_col map2idx ( self , ch_row , ch_col ) Given a channel's row and col, return channel's index Parameters: Name Type Description Default ch_row int row index of channel in array (up to 32) required ch_col int column index of channel in array (up to 32) required Returns: numerical index of array Source code in src/controller/windows/window_individualchannel.py def map2idx ( self , ch_row : int , ch_col : int ) -> object : \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx setElecNum ( self ) Given a row and column value, set the electrode number textbox and display plots Connected to the Source code in src/controller/windows/window_individualchannel.py def setElecNum ( self ): \"\"\" Given a row and column value, set the electrode number textbox and display plots Connected to the \"\"\" row = self . InputElectrodeRow . toPlainText () col = self . InputElectrodeCol . toPlainText () if row == \"\" : self . current_row = 0 self . InputElectrodeRow . setText ( \"0\" ) if col == \"\" : self . current_col = 0 self . InputElectrodeCol . setText ( \"0\" ) if row . isnumeric () and col . isnumeric (): row = int ( row ) col = int ( col ) if 0 <= row < 32 and row != self . current_row : self . current_row = row else : pass self . InputElectrodeRow . setText ( str ( self . current_row )) if 0 <= col < 32 and col != self . current_col : self . current_col = col else : pass self . InputElectrodeCol . setText ( str ( self . current_col )) self . current_elec = self . map2idx ( self . current_row , self . current_col ) self . update () self . InputElectrodeNumber . setText ( str ( self . current_elec )) setRC ( self ) Set the row and column entries and text boxes given an electrode number. Connected to \"Update Row and Column\" button Source code in src/controller/windows/window_individualchannel.py def setRC ( self ): \"\"\" Set the row and column entries and text boxes given an electrode number. Connected to \"Update Row and Column\" button \"\"\" input = self . InputElectrodeNumber . toPlainText () if input . isnumeric (): if 0 <= int ( input ) < 1024 and int ( input ) != self . current_elec : self . current_elec = int ( input ) self . current_row , self . current_col = self . idx2map ( self . current_elec ) self . InputElectrodeRow . setText ( str ( self . current_row )) self . InputElectrodeCol . setText ( str ( self . current_col )) self . update () else : pass self . InputElectrodeNumber . setText ( str ( self . current_elec )) else : pass self . InputElectrodeNumber . setText ( str ( self . current_elec )) update ( self , debug = False ) update(self) update(self, QRect) update(self, QRegion) update(self, int, int, int, int) Source code in src/controller/windows/window_individualchannel.py def update ( self , debug = False ): start = time . time () print ( \"Update individual channels: \" + str ( self . current_elec )) self . updateElectrodeData () # update the charts for chart in self . individualchannel_charts_update_mapping . keys (): self . individualchannel_charts_update_mapping [ chart ]() idx = map2idx ( self . current_row , self . current_col ) if debug : print ( 'std from array stats: ' + str ( self . session_parent . LoadedData . df . at [ idx , \"noise_std\" ])) print ( \"noise mean from array stats: \" + str ( self . session_parent . LoadedData . df . at [ idx , \"noise_mean\" ])) print ( 'std from direct calculation: ' + str ( np . std ( self . electrode_packets [ 0 ][ \"model\" ]))) self . totalSamples . setText ( \"Total number of samples: \" + str ( len ( self . electrode_data ))) self . timeRecorded . setText ( \"Total time recording electrode: \" + str ( self . recordedTime ) + \"ms\" ) self . numSpikes . setText ( \"Number of spikes: \" + str ( sum ( self . electrode_spikes ))) if debug : print ( 'number of spikes from array stats: ' + str ( self . session_parent . LoadedData . array_indexed [ 'spike_cnt' ][ self . current_row ][ self . current_col ])) end = time . time () if self . session_parent . gui_state [ 'is_mode_profiling' ]: print ( \"Individual Channel update time: \" + str ( np . round ( end - start , 2 ))) updateSpikeRate ( self , movingAverage = True , windowSize = 15 , numberOfUpdates = 10 , debug = False ) movingAverage: If false, divide up the range into numberOfUpdates bins and average to find spike rate windowSize: Size of moving average window in milliseconds numberOfUpdates: How many times you want to update the spike rate if not doing moving average. Function divides the range of model into numberOfUpdates bins to time average spikes. debug: Print helpful model. Source code in src/controller/windows/window_individualchannel.py def updateSpikeRate ( self , movingAverage = True , windowSize = 15 , numberOfUpdates = 10 , debug = False ): \"\"\" movingAverage: If false, divide up the range into numberOfUpdates bins and average to find spike rate windowSize: Size of moving average window in milliseconds numberOfUpdates: How many times you want to update the spike rate if not doing moving average. Function divides the range of model into numberOfUpdates bins to time average spikes. debug: Print helpful model. \"\"\" self . SpikeRatePlot . clear () if debug : print ( \"self.electrode_times: \" + str ( self . electrode_times )) print ( \"self.electrode_spikes: \" + str ( self . electrode_spikes )) print ( \"Length of electrode times: \" + str ( len ( self . electrode_times ))) print ( \"Length of electrode spikes list: \" + str ( len ( self . electrode_spikes ))) spikeList = self . electrode_spikes indexes = np . linspace ( 0 , len ( spikeList ), numberOfUpdates + 1 ) indexes = [ int ( i ) for i in indexes ] t = [] spike_rate = [] # Only run if electrode has been recorded if self . recordedTime != 0 : # Perform moving average on spike list if movingAverage : moving_averages = [] i = 0 while i < len ( spikeList ) - windowSize + 1 : window_average = round ( np . sum ( spikeList [ i : i + windowSize ]) / windowSize , 2 ) moving_averages . append ( 1000 * window_average ) # multiply by 1000 to go to spikes/sec i += 1 t = np . linspace ( self . electrode_times [ 0 ], self . electrode_times [ - 1 ], len ( spikeList ) - windowSize + 1 ) spike_rate = moving_averages # Window modes else : num_spikes = [] for i in range ( numberOfUpdates ): window = spikeList [ indexes [ i ]: indexes [ i + 1 ]] num_spikes . append ( sum ( window )) spike_rate = [ 1000 * num_spike / ( self . recordedTime / numberOfUpdates ) for num_spike in num_spikes ] t = np . linspace ( self . electrode_times [ 0 ], self . electrode_times [ - 1 ], numberOfUpdates ) t = [ int ( i ) for i in t ] else : spike_rate = [ 0 for i in range ( numberOfUpdates )] t = [ 0 for i in range ( numberOfUpdates )] self . SpikeRatePlot . plot ( t , spike_rate , pen = pg . mkPen ( themes [ CURRENT_THEME ][ 'blue1' ], width = 5 )) idx = map2idx ( self . current_row , self . current_col ) if debug : print ( \"length of recording: \" + str ( len ( self . electrode_times )) + \" model points\" ) print ( \"electrode times: \" + str ( self . electrode_times [ 0 ]) + \"-\" + str ( self . electrode_times [ - 1 ])) print ( \"spikes: \" + str ( self . electrode_spikes )) #print(\"double binned spikes: \" + str(num_spikes)) print ( \"number of spike bins: \" + str ( len ( self . electrode_spikes ))) print ( \"incoming spike times: \" + str ( self . electrode_spike_times )) print ( \"noise mean: \" + str ( self . session_parent . LoadedData . df . at [ idx , 'noise_mean' ])) print ( \"noise std: \" + str ( self . session_parent . LoadedData . df . at [ idx , 'noise_std' ]))","title":"individual channel analysis"},{"location":"controller/windows/window_individualchannel/#src.controller.windows.window_individualchannel.IndividualChannelInformation","text":"Source code in src/controller/windows/window_individualchannel.py class IndividualChannelInformation ( QWidget ): session_parent = None current_elec = 0 current_row = 0 current_col = 0 recordedTime = None has_data = None # List of dictionaries containing model packets with electrode info (model, times, spikes, etc). # Each packet is for the same electrode, but may have model from different times within recording session electrode_packets = [] # Lists containing values stored in the associated key in electrode_packets dictionaries electrode_times = [] electrode_data = [] electrode_spikes = [] electrode_spike_times = [] individualchannel_charts = {} # dictionary for all different individual channel charts individualchannel_charts_update_mapping = {} # dictionary for mapping charts to their update functions def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) uic . loadUi ( \"./src/view/layouts/IndividualChannelWindow.ui\" , self ) self . updateElectrodeNum . clicked . connect ( self . setElecNum ) self . updateRC . clicked . connect ( self . setRC ) self . individualchannel_charts = { 'ChannelTracePlot' : self . ChannelTracePlot , 'AmplitudeHistPlot' : self . AmplitudeHistPlot , 'SpikeRatePlot' : self . SpikeRatePlot } self . individualchannel_charts_update_mapping = { 'ChannelTracePlot' : self . updateChannelTrace , 'AmplitudeHistPlot' : self . updateAmplitudeHist , 'SpikeRatePlot' : self . updateSpikeRate } def setSessionParent ( self , session_parent ): self . session_parent = session_parent # self.setupCharts() TODO figure why this was here # Note: do NOT change name from \"update\" def update ( self , debug = False ): start = time . time () print ( \"Update individual channels: \" + str ( self . current_elec )) self . updateElectrodeData () # update the charts for chart in self . individualchannel_charts_update_mapping . keys (): self . individualchannel_charts_update_mapping [ chart ]() idx = map2idx ( self . current_row , self . current_col ) if debug : print ( 'std from array stats: ' + str ( self . session_parent . LoadedData . df . at [ idx , \"noise_std\" ])) print ( \"noise mean from array stats: \" + str ( self . session_parent . LoadedData . df . at [ idx , \"noise_mean\" ])) print ( 'std from direct calculation: ' + str ( np . std ( self . electrode_packets [ 0 ][ \"model\" ]))) self . totalSamples . setText ( \"Total number of samples: \" + str ( len ( self . electrode_data ))) self . timeRecorded . setText ( \"Total time recording electrode: \" + str ( self . recordedTime ) + \"ms\" ) self . numSpikes . setText ( \"Number of spikes: \" + str ( sum ( self . electrode_spikes ))) if debug : print ( 'number of spikes from array stats: ' + str ( self . session_parent . LoadedData . array_indexed [ 'spike_cnt' ][ self . current_row ][ self . current_col ])) end = time . time () if self . session_parent . gui_state [ 'is_mode_profiling' ]: print ( \"Individual Channel update time: \" + str ( np . round ( end - start , 2 ))) def updateElectrodeData ( self , debug = False ): self . electrode_packets . clear () self . electrode_spikes . clear () self . electrode_spike_times . clear () self . electrode_data . clear () self . electrode_times . clear () match = False X , Y = self . session_parent . data . get_last_trace_with_electrode_idx ( self . current_elec ) # TODO hook this data with rest of GUI \"\"\" # Create a list of dictionaries of model packets for the selected electrode for i in range(len_filtered_data): if self.session_parent.LoadedData.filtered_data[i]['channel_idx'] == self.current_elec: self.electrode_packets.append(self.session_parent.LoadedData.filtered_data[i]) match = True if debug: if not match: print(\"No model from this electrode yet\") filtered = True if self.session_parent.settings[\"filter\"] == \"None\": filtered = False # Get lists of times and model from each packet for the selected electrode for i in range(len(self.electrode_packets)): self.session_parent.LoadedData.\\ calculate_realtime_spike_info_for_channel_in_buffer(self.electrode_packets[i], filtered) self.electrode_spikes.extend(self.electrode_packets[i][\"spikeBins\"]) self.electrode_spike_times.extend(self.electrode_packets[i][\"incom_spike_times\"]) self.electrode_times.extend(self.electrode_packets[i]['times']) self.electrode_data.extend(self.electrode_packets[i]['model']) self.recordedTime = round((len(self.electrode_data)) * 0.05, 2) \"\"\" def updateAmplitudeHist ( self ): vals = self . electrode_data std = np . std ( vals ) vals = abs ( vals / std ) self . AmplitudeHistPlot . clear () y , x = np . histogram ( vals , bins = np . linspace ( 0 , 20 , 40 )) curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . AmplitudeHistPlot . addItem ( curve ) def updateSpikeRate ( self , movingAverage = True , windowSize = 15 , numberOfUpdates = 10 , debug = False ): \"\"\" movingAverage: If false, divide up the range into numberOfUpdates bins and average to find spike rate windowSize: Size of moving average window in milliseconds numberOfUpdates: How many times you want to update the spike rate if not doing moving average. Function divides the range of model into numberOfUpdates bins to time average spikes. debug: Print helpful model. \"\"\" self . SpikeRatePlot . clear () if debug : print ( \"self.electrode_times: \" + str ( self . electrode_times )) print ( \"self.electrode_spikes: \" + str ( self . electrode_spikes )) print ( \"Length of electrode times: \" + str ( len ( self . electrode_times ))) print ( \"Length of electrode spikes list: \" + str ( len ( self . electrode_spikes ))) spikeList = self . electrode_spikes indexes = np . linspace ( 0 , len ( spikeList ), numberOfUpdates + 1 ) indexes = [ int ( i ) for i in indexes ] t = [] spike_rate = [] # Only run if electrode has been recorded if self . recordedTime != 0 : # Perform moving average on spike list if movingAverage : moving_averages = [] i = 0 while i < len ( spikeList ) - windowSize + 1 : window_average = round ( np . sum ( spikeList [ i : i + windowSize ]) / windowSize , 2 ) moving_averages . append ( 1000 * window_average ) # multiply by 1000 to go to spikes/sec i += 1 t = np . linspace ( self . electrode_times [ 0 ], self . electrode_times [ - 1 ], len ( spikeList ) - windowSize + 1 ) spike_rate = moving_averages # Window modes else : num_spikes = [] for i in range ( numberOfUpdates ): window = spikeList [ indexes [ i ]: indexes [ i + 1 ]] num_spikes . append ( sum ( window )) spike_rate = [ 1000 * num_spike / ( self . recordedTime / numberOfUpdates ) for num_spike in num_spikes ] t = np . linspace ( self . electrode_times [ 0 ], self . electrode_times [ - 1 ], numberOfUpdates ) t = [ int ( i ) for i in t ] else : spike_rate = [ 0 for i in range ( numberOfUpdates )] t = [ 0 for i in range ( numberOfUpdates )] self . SpikeRatePlot . plot ( t , spike_rate , pen = pg . mkPen ( themes [ CURRENT_THEME ][ 'blue1' ], width = 5 )) idx = map2idx ( self . current_row , self . current_col ) if debug : print ( \"length of recording: \" + str ( len ( self . electrode_times )) + \" model points\" ) print ( \"electrode times: \" + str ( self . electrode_times [ 0 ]) + \"-\" + str ( self . electrode_times [ - 1 ])) print ( \"spikes: \" + str ( self . electrode_spikes )) #print(\"double binned spikes: \" + str(num_spikes)) print ( \"number of spike bins: \" + str ( len ( self . electrode_spikes ))) print ( \"incoming spike times: \" + str ( self . electrode_spike_times )) print ( \"noise mean: \" + str ( self . session_parent . LoadedData . df . at [ idx , 'noise_mean' ])) print ( \"noise std: \" + str ( self . session_parent . LoadedData . df . at [ idx , 'noise_std' ])) def updateChannelTrace ( self ): self . ChannelTracePlot . clear () self . ChannelTracePlot . plot ( self . electrode_times , self . electrode_data , pen = 'b' ) self . ChannelTracePlot . enableAutoRange ( axis = 'y' ) self . ChannelTracePlot . setAutoVisible ( y = True ) self . ChannelTracePlot . setLabel ( 'top' , '#' + str ( self . current_elec )) def setRC ( self ): \"\"\" Set the row and column entries and text boxes given an electrode number. Connected to \"Update Row and Column\" button \"\"\" input = self . InputElectrodeNumber . toPlainText () if input . isnumeric (): if 0 <= int ( input ) < 1024 and int ( input ) != self . current_elec : self . current_elec = int ( input ) self . current_row , self . current_col = self . idx2map ( self . current_elec ) self . InputElectrodeRow . setText ( str ( self . current_row )) self . InputElectrodeCol . setText ( str ( self . current_col )) self . update () else : pass self . InputElectrodeNumber . setText ( str ( self . current_elec )) else : pass self . InputElectrodeNumber . setText ( str ( self . current_elec )) def setElecNum ( self ): \"\"\" Given a row and column value, set the electrode number textbox and display plots Connected to the \"\"\" row = self . InputElectrodeRow . toPlainText () col = self . InputElectrodeCol . toPlainText () if row == \"\" : self . current_row = 0 self . InputElectrodeRow . setText ( \"0\" ) if col == \"\" : self . current_col = 0 self . InputElectrodeCol . setText ( \"0\" ) if row . isnumeric () and col . isnumeric (): row = int ( row ) col = int ( col ) if 0 <= row < 32 and row != self . current_row : self . current_row = row else : pass self . InputElectrodeRow . setText ( str ( self . current_row )) if 0 <= col < 32 and col != self . current_col : self . current_col = col else : pass self . InputElectrodeCol . setText ( str ( self . current_col )) self . current_elec = self . map2idx ( self . current_row , self . current_col ) self . update () self . InputElectrodeNumber . setText ( str ( self . current_elec )) def map2idx ( self , ch_row : int , ch_col : int ) -> object : \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx def idx2map ( self , ch_idx : int ): \"\"\" Given a channel index, return the channel's row and col Args: ch_idx: single numerical index for array (up to 1024) Returns: channel row and channel index \"\"\" if ch_idx > 1023 or ch_idx < 0 : print ( 'Chan num out of range' ) return - 1 else : ch_row = int ( ch_idx / 32 ) ch_col = int ( ch_idx - ch_row * 32 ) return ch_row , ch_col # see MainWindow.update_theme() for how this is called def update_theme ( self , current_theme , themes ): background_color = themes [ current_theme ][ \"background_color\" ] background_border = themes [ current_theme ][ \"background_borders\" ] button_color = themes [ current_theme ][ \"button\" ] font_color = themes [ current_theme ][ \"font_color\" ] self . setStyleSheet ( \"background-color: \" + background_border ) self . updateElectrodeNum . setStyleSheet ( \"background-color: \" + button_color ) self . updateRC . setStyleSheet ( \"background-color: \" + button_color ) self . label_elecnum . setStyleSheet ( \"color: \" + font_color ) self . label_2 . setStyleSheet ( \"color: \" + font_color ) self . label_3 . setStyleSheet ( \"color: \" + font_color ) self . numSpikes . setStyleSheet ( \"color: \" + font_color ) self . totalSamples . setStyleSheet ( \"color: \" + font_color ) self . timeRecorded . setStyleSheet ( \"color: \" + font_color ) self . InputElectrodeRow . setStyleSheet ( \"background-color: \" + button_color ) self . InputElectrodeCol . setStyleSheet ( \"background-color: \" + button_color ) self . InputElectrodeNumber . setStyleSheet ( \"background-color: \" + button_color ) for chart in self . individualchannel_charts . keys (): self . individualchannel_charts [ chart ] . setBackground ( background_color )","title":"IndividualChannelInformation"},{"location":"controller/windows/window_individualchannel/#src.controller.windows.window_individualchannel.IndividualChannelInformation.idx2map","text":"Given a channel index, return the channel's row and col Parameters: Name Type Description Default ch_idx int single numerical index for array (up to 1024) required Returns: Type Description channel row and channel index Source code in src/controller/windows/window_individualchannel.py def idx2map ( self , ch_idx : int ): \"\"\" Given a channel index, return the channel's row and col Args: ch_idx: single numerical index for array (up to 1024) Returns: channel row and channel index \"\"\" if ch_idx > 1023 or ch_idx < 0 : print ( 'Chan num out of range' ) return - 1 else : ch_row = int ( ch_idx / 32 ) ch_col = int ( ch_idx - ch_row * 32 ) return ch_row , ch_col","title":"idx2map()"},{"location":"controller/windows/window_individualchannel/#src.controller.windows.window_individualchannel.IndividualChannelInformation.map2idx","text":"Given a channel's row and col, return channel's index Parameters: Name Type Description Default ch_row int row index of channel in array (up to 32) required ch_col int column index of channel in array (up to 32) required Returns: numerical index of array Source code in src/controller/windows/window_individualchannel.py def map2idx ( self , ch_row : int , ch_col : int ) -> object : \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx","title":"map2idx()"},{"location":"controller/windows/window_individualchannel/#src.controller.windows.window_individualchannel.IndividualChannelInformation.setElecNum","text":"Given a row and column value, set the electrode number textbox and display plots Connected to the Source code in src/controller/windows/window_individualchannel.py def setElecNum ( self ): \"\"\" Given a row and column value, set the electrode number textbox and display plots Connected to the \"\"\" row = self . InputElectrodeRow . toPlainText () col = self . InputElectrodeCol . toPlainText () if row == \"\" : self . current_row = 0 self . InputElectrodeRow . setText ( \"0\" ) if col == \"\" : self . current_col = 0 self . InputElectrodeCol . setText ( \"0\" ) if row . isnumeric () and col . isnumeric (): row = int ( row ) col = int ( col ) if 0 <= row < 32 and row != self . current_row : self . current_row = row else : pass self . InputElectrodeRow . setText ( str ( self . current_row )) if 0 <= col < 32 and col != self . current_col : self . current_col = col else : pass self . InputElectrodeCol . setText ( str ( self . current_col )) self . current_elec = self . map2idx ( self . current_row , self . current_col ) self . update () self . InputElectrodeNumber . setText ( str ( self . current_elec ))","title":"setElecNum()"},{"location":"controller/windows/window_individualchannel/#src.controller.windows.window_individualchannel.IndividualChannelInformation.setRC","text":"Set the row and column entries and text boxes given an electrode number. Connected to \"Update Row and Column\" button Source code in src/controller/windows/window_individualchannel.py def setRC ( self ): \"\"\" Set the row and column entries and text boxes given an electrode number. Connected to \"Update Row and Column\" button \"\"\" input = self . InputElectrodeNumber . toPlainText () if input . isnumeric (): if 0 <= int ( input ) < 1024 and int ( input ) != self . current_elec : self . current_elec = int ( input ) self . current_row , self . current_col = self . idx2map ( self . current_elec ) self . InputElectrodeRow . setText ( str ( self . current_row )) self . InputElectrodeCol . setText ( str ( self . current_col )) self . update () else : pass self . InputElectrodeNumber . setText ( str ( self . current_elec )) else : pass self . InputElectrodeNumber . setText ( str ( self . current_elec ))","title":"setRC()"},{"location":"controller/windows/window_individualchannel/#src.controller.windows.window_individualchannel.IndividualChannelInformation.update","text":"update(self) update(self, QRect) update(self, QRegion) update(self, int, int, int, int) Source code in src/controller/windows/window_individualchannel.py def update ( self , debug = False ): start = time . time () print ( \"Update individual channels: \" + str ( self . current_elec )) self . updateElectrodeData () # update the charts for chart in self . individualchannel_charts_update_mapping . keys (): self . individualchannel_charts_update_mapping [ chart ]() idx = map2idx ( self . current_row , self . current_col ) if debug : print ( 'std from array stats: ' + str ( self . session_parent . LoadedData . df . at [ idx , \"noise_std\" ])) print ( \"noise mean from array stats: \" + str ( self . session_parent . LoadedData . df . at [ idx , \"noise_mean\" ])) print ( 'std from direct calculation: ' + str ( np . std ( self . electrode_packets [ 0 ][ \"model\" ]))) self . totalSamples . setText ( \"Total number of samples: \" + str ( len ( self . electrode_data ))) self . timeRecorded . setText ( \"Total time recording electrode: \" + str ( self . recordedTime ) + \"ms\" ) self . numSpikes . setText ( \"Number of spikes: \" + str ( sum ( self . electrode_spikes ))) if debug : print ( 'number of spikes from array stats: ' + str ( self . session_parent . LoadedData . array_indexed [ 'spike_cnt' ][ self . current_row ][ self . current_col ])) end = time . time () if self . session_parent . gui_state [ 'is_mode_profiling' ]: print ( \"Individual Channel update time: \" + str ( np . round ( end - start , 2 )))","title":"update()"},{"location":"controller/windows/window_individualchannel/#src.controller.windows.window_individualchannel.IndividualChannelInformation.updateSpikeRate","text":"movingAverage: If false, divide up the range into numberOfUpdates bins and average to find spike rate windowSize: Size of moving average window in milliseconds numberOfUpdates: How many times you want to update the spike rate if not doing moving average. Function divides the range of model into numberOfUpdates bins to time average spikes. debug: Print helpful model. Source code in src/controller/windows/window_individualchannel.py def updateSpikeRate ( self , movingAverage = True , windowSize = 15 , numberOfUpdates = 10 , debug = False ): \"\"\" movingAverage: If false, divide up the range into numberOfUpdates bins and average to find spike rate windowSize: Size of moving average window in milliseconds numberOfUpdates: How many times you want to update the spike rate if not doing moving average. Function divides the range of model into numberOfUpdates bins to time average spikes. debug: Print helpful model. \"\"\" self . SpikeRatePlot . clear () if debug : print ( \"self.electrode_times: \" + str ( self . electrode_times )) print ( \"self.electrode_spikes: \" + str ( self . electrode_spikes )) print ( \"Length of electrode times: \" + str ( len ( self . electrode_times ))) print ( \"Length of electrode spikes list: \" + str ( len ( self . electrode_spikes ))) spikeList = self . electrode_spikes indexes = np . linspace ( 0 , len ( spikeList ), numberOfUpdates + 1 ) indexes = [ int ( i ) for i in indexes ] t = [] spike_rate = [] # Only run if electrode has been recorded if self . recordedTime != 0 : # Perform moving average on spike list if movingAverage : moving_averages = [] i = 0 while i < len ( spikeList ) - windowSize + 1 : window_average = round ( np . sum ( spikeList [ i : i + windowSize ]) / windowSize , 2 ) moving_averages . append ( 1000 * window_average ) # multiply by 1000 to go to spikes/sec i += 1 t = np . linspace ( self . electrode_times [ 0 ], self . electrode_times [ - 1 ], len ( spikeList ) - windowSize + 1 ) spike_rate = moving_averages # Window modes else : num_spikes = [] for i in range ( numberOfUpdates ): window = spikeList [ indexes [ i ]: indexes [ i + 1 ]] num_spikes . append ( sum ( window )) spike_rate = [ 1000 * num_spike / ( self . recordedTime / numberOfUpdates ) for num_spike in num_spikes ] t = np . linspace ( self . electrode_times [ 0 ], self . electrode_times [ - 1 ], numberOfUpdates ) t = [ int ( i ) for i in t ] else : spike_rate = [ 0 for i in range ( numberOfUpdates )] t = [ 0 for i in range ( numberOfUpdates )] self . SpikeRatePlot . plot ( t , spike_rate , pen = pg . mkPen ( themes [ CURRENT_THEME ][ 'blue1' ], width = 5 )) idx = map2idx ( self . current_row , self . current_col ) if debug : print ( \"length of recording: \" + str ( len ( self . electrode_times )) + \" model points\" ) print ( \"electrode times: \" + str ( self . electrode_times [ 0 ]) + \"-\" + str ( self . electrode_times [ - 1 ])) print ( \"spikes: \" + str ( self . electrode_spikes )) #print(\"double binned spikes: \" + str(num_spikes)) print ( \"number of spike bins: \" + str ( len ( self . electrode_spikes ))) print ( \"incoming spike times: \" + str ( self . electrode_spike_times )) print ( \"noise mean: \" + str ( self . session_parent . LoadedData . df . at [ idx , 'noise_mean' ])) print ( \"noise std: \" + str ( self . session_parent . LoadedData . df . at [ idx , 'noise_std' ]))","title":"updateSpikeRate()"},{"location":"controller/windows/window_profiler/","text":"DataFrameModel ( QAbstractTableModel ) Source code in src/controller/windows/window_electrodelist.py class DataFrameModel ( QtCore . QAbstractTableModel ): DtypeRole = QtCore . Qt . UserRole + 1000 ValueRole = QtCore . Qt . UserRole + 1001 def __init__ ( self , df = pd . DataFrame (), parent = None ): super ( DataFrameModel , self ) . __init__ ( parent ) self . _dataframe = df def setDataFrame ( self , dataframe ): self . beginResetModel () self . _dataframe = dataframe . copy () self . endResetModel () def dataFrame ( self ): return self . _dataframe dataFrame = QtCore . pyqtProperty ( pd . DataFrame , fget = dataFrame , fset = setDataFrame ) @QtCore . pyqtSlot ( int , QtCore . Qt . Orientation , result = str ) def headerData ( self , section : int , orientation : QtCore . Qt . Orientation , role : int = QtCore . Qt . DisplayRole ): if role == QtCore . Qt . DisplayRole : if orientation == QtCore . Qt . Horizontal : return self . _dataframe . columns [ section ] else : return str ( self . _dataframe . index [ section ]) return QtCore . QVariant () def rowCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return len ( self . _dataframe . index ) def columnCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return self . _dataframe . columns . size def data ( self , index , role = QtCore . Qt . DisplayRole ): if not index . isValid () or not ( 0 <= index . row () < self . rowCount () \\ and 0 <= index . column () < self . columnCount ()): return QtCore . QVariant () row = self . _dataframe . index [ index . row ()] col = self . _dataframe . columns [ index . column ()] dt = self . _dataframe [ col ] . dtype val = self . _dataframe . iloc [ row ][ col ] if role == QtCore . Qt . DisplayRole : return str ( val ) elif role == DataFrameModel . ValueRole : return val if role == DataFrameModel . DtypeRole : return dt return QtCore . QVariant () def roleNames ( self ): roles = { QtCore . Qt . DisplayRole : b 'display' , DataFrameModel . DtypeRole : b 'dtype' , DataFrameModel . ValueRole : b 'value' } return roles # see MainWindow.update_theme() for how this is called def update_theme ( self , current_theme , themes ): pass columnCount ( self , parent =< PyQt5 . QtCore . QModelIndex object at 0x7f90224edb50 > ) columnCount(self, parent: QModelIndex = QModelIndex()) -> int Source code in src/controller/windows/window_electrodelist.py def columnCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return self . _dataframe . columns . size data ( self , index , role = 0 ) data(self, QModelIndex, role: int = Qt.ItemDataRole.DisplayRole) -> Any Source code in src/controller/windows/window_electrodelist.py def data ( self , index , role = QtCore . Qt . DisplayRole ): if not index . isValid () or not ( 0 <= index . row () < self . rowCount () \\ and 0 <= index . column () < self . columnCount ()): return QtCore . QVariant () row = self . _dataframe . index [ index . row ()] col = self . _dataframe . columns [ index . column ()] dt = self . _dataframe [ col ] . dtype val = self . _dataframe . iloc [ row ][ col ] if role == QtCore . Qt . DisplayRole : return str ( val ) elif role == DataFrameModel . ValueRole : return val if role == DataFrameModel . DtypeRole : return dt return QtCore . QVariant () headerData ( self , section , orientation , role = 0 ) headerData(self, int, Qt.Orientation, role: int = Qt.ItemDataRole.DisplayRole) -> Any Source code in src/controller/windows/window_electrodelist.py @QtCore . pyqtSlot ( int , QtCore . Qt . Orientation , result = str ) def headerData ( self , section : int , orientation : QtCore . Qt . Orientation , role : int = QtCore . Qt . DisplayRole ): if role == QtCore . Qt . DisplayRole : if orientation == QtCore . Qt . Horizontal : return self . _dataframe . columns [ section ] else : return str ( self . _dataframe . index [ section ]) return QtCore . QVariant () roleNames ( self ) roleNames(self) -> Dict[int, QByteArray] Source code in src/controller/windows/window_electrodelist.py def roleNames ( self ): roles = { QtCore . Qt . DisplayRole : b 'display' , DataFrameModel . DtypeRole : b 'dtype' , DataFrameModel . ValueRole : b 'value' } return roles rowCount ( self , parent =< PyQt5 . QtCore . QModelIndex object at 0x7f90224edad0 > ) rowCount(self, parent: QModelIndex = QModelIndex()) -> int Source code in src/controller/windows/window_electrodelist.py def rowCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return len ( self . _dataframe . index ) ElectrodeListInformation ( QWidget ) Source code in src/controller/windows/window_electrodelist.py class ElectrodeListInformation ( QWidget ): app = None current_elec = 0 current_row = 0 current_col = 0 model = None sortOption = None def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) uic . loadUi ( \"./src/view/layouts/AllChannelsList.ui\" , self ) self . sort_by = \"row\" self . chooseSortOption . activated . connect ( self . setSortOption ) def setSessionParent ( self , session_parent ): \"\"\" Args: session_parent: Returns: \"\"\" self . app = session_parent self . model = DataFrameModel ( self . app . data . df ) self . electrodeTable . setModel ( self . model ) self . setTheme () def update ( self ): \"\"\" Returns: \"\"\" self . model = DataFrameModel ( self . app . data . df ) self . model . sort ( 1 ) self . electrodeTable . setModel ( self . model ) def setSortOption ( self ): \"\"\" Returns: \"\"\" self . sortOption = self . chooseSortOption . currentText () print ( \"SORT OPTION: \" + self . sortOption ) self . update () def setTheme ( self ): #background_color = self.settings[\"\"] #self.electrodeTable.setBackground(background_color) # TODO set theme of electrode list pass setSessionParent ( self , session_parent ) Parameters: Name Type Description Default session_parent required Source code in src/controller/windows/window_electrodelist.py def setSessionParent ( self , session_parent ): \"\"\" Args: session_parent: Returns: \"\"\" self . app = session_parent self . model = DataFrameModel ( self . app . data . df ) self . electrodeTable . setModel ( self . model ) self . setTheme () setSortOption ( self ) Source code in src/controller/windows/window_electrodelist.py def setSortOption ( self ): \"\"\" Returns: \"\"\" self . sortOption = self . chooseSortOption . currentText () print ( \"SORT OPTION: \" + self . sortOption ) self . update () update ( self ) Source code in src/controller/windows/window_electrodelist.py def update ( self ): \"\"\" Returns: \"\"\" self . model = DataFrameModel ( self . app . data . df ) self . model . sort ( 1 ) self . electrodeTable . setModel ( self . model )","title":"profiler"},{"location":"controller/windows/window_profiler/#src.controller.windows.window_electrodelist.DataFrameModel","text":"Source code in src/controller/windows/window_electrodelist.py class DataFrameModel ( QtCore . QAbstractTableModel ): DtypeRole = QtCore . Qt . UserRole + 1000 ValueRole = QtCore . Qt . UserRole + 1001 def __init__ ( self , df = pd . DataFrame (), parent = None ): super ( DataFrameModel , self ) . __init__ ( parent ) self . _dataframe = df def setDataFrame ( self , dataframe ): self . beginResetModel () self . _dataframe = dataframe . copy () self . endResetModel () def dataFrame ( self ): return self . _dataframe dataFrame = QtCore . pyqtProperty ( pd . DataFrame , fget = dataFrame , fset = setDataFrame ) @QtCore . pyqtSlot ( int , QtCore . Qt . Orientation , result = str ) def headerData ( self , section : int , orientation : QtCore . Qt . Orientation , role : int = QtCore . Qt . DisplayRole ): if role == QtCore . Qt . DisplayRole : if orientation == QtCore . Qt . Horizontal : return self . _dataframe . columns [ section ] else : return str ( self . _dataframe . index [ section ]) return QtCore . QVariant () def rowCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return len ( self . _dataframe . index ) def columnCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return self . _dataframe . columns . size def data ( self , index , role = QtCore . Qt . DisplayRole ): if not index . isValid () or not ( 0 <= index . row () < self . rowCount () \\ and 0 <= index . column () < self . columnCount ()): return QtCore . QVariant () row = self . _dataframe . index [ index . row ()] col = self . _dataframe . columns [ index . column ()] dt = self . _dataframe [ col ] . dtype val = self . _dataframe . iloc [ row ][ col ] if role == QtCore . Qt . DisplayRole : return str ( val ) elif role == DataFrameModel . ValueRole : return val if role == DataFrameModel . DtypeRole : return dt return QtCore . QVariant () def roleNames ( self ): roles = { QtCore . Qt . DisplayRole : b 'display' , DataFrameModel . DtypeRole : b 'dtype' , DataFrameModel . ValueRole : b 'value' } return roles # see MainWindow.update_theme() for how this is called def update_theme ( self , current_theme , themes ): pass","title":"DataFrameModel"},{"location":"controller/windows/window_profiler/#src.controller.windows.window_electrodelist.DataFrameModel.columnCount","text":"columnCount(self, parent: QModelIndex = QModelIndex()) -> int Source code in src/controller/windows/window_electrodelist.py def columnCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return self . _dataframe . columns . size","title":"columnCount()"},{"location":"controller/windows/window_profiler/#src.controller.windows.window_electrodelist.DataFrameModel.data","text":"data(self, QModelIndex, role: int = Qt.ItemDataRole.DisplayRole) -> Any Source code in src/controller/windows/window_electrodelist.py def data ( self , index , role = QtCore . Qt . DisplayRole ): if not index . isValid () or not ( 0 <= index . row () < self . rowCount () \\ and 0 <= index . column () < self . columnCount ()): return QtCore . QVariant () row = self . _dataframe . index [ index . row ()] col = self . _dataframe . columns [ index . column ()] dt = self . _dataframe [ col ] . dtype val = self . _dataframe . iloc [ row ][ col ] if role == QtCore . Qt . DisplayRole : return str ( val ) elif role == DataFrameModel . ValueRole : return val if role == DataFrameModel . DtypeRole : return dt return QtCore . QVariant ()","title":"data()"},{"location":"controller/windows/window_profiler/#src.controller.windows.window_electrodelist.DataFrameModel.headerData","text":"headerData(self, int, Qt.Orientation, role: int = Qt.ItemDataRole.DisplayRole) -> Any Source code in src/controller/windows/window_electrodelist.py @QtCore . pyqtSlot ( int , QtCore . Qt . Orientation , result = str ) def headerData ( self , section : int , orientation : QtCore . Qt . Orientation , role : int = QtCore . Qt . DisplayRole ): if role == QtCore . Qt . DisplayRole : if orientation == QtCore . Qt . Horizontal : return self . _dataframe . columns [ section ] else : return str ( self . _dataframe . index [ section ]) return QtCore . QVariant ()","title":"headerData()"},{"location":"controller/windows/window_profiler/#src.controller.windows.window_electrodelist.DataFrameModel.roleNames","text":"roleNames(self) -> Dict[int, QByteArray] Source code in src/controller/windows/window_electrodelist.py def roleNames ( self ): roles = { QtCore . Qt . DisplayRole : b 'display' , DataFrameModel . DtypeRole : b 'dtype' , DataFrameModel . ValueRole : b 'value' } return roles","title":"roleNames()"},{"location":"controller/windows/window_profiler/#src.controller.windows.window_electrodelist.DataFrameModel.rowCount","text":"rowCount(self, parent: QModelIndex = QModelIndex()) -> int Source code in src/controller/windows/window_electrodelist.py def rowCount ( self , parent = QtCore . QModelIndex ()): if parent . isValid (): return 0 return len ( self . _dataframe . index )","title":"rowCount()"},{"location":"controller/windows/window_profiler/#src.controller.windows.window_electrodelist.ElectrodeListInformation","text":"Source code in src/controller/windows/window_electrodelist.py class ElectrodeListInformation ( QWidget ): app = None current_elec = 0 current_row = 0 current_col = 0 model = None sortOption = None def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) uic . loadUi ( \"./src/view/layouts/AllChannelsList.ui\" , self ) self . sort_by = \"row\" self . chooseSortOption . activated . connect ( self . setSortOption ) def setSessionParent ( self , session_parent ): \"\"\" Args: session_parent: Returns: \"\"\" self . app = session_parent self . model = DataFrameModel ( self . app . data . df ) self . electrodeTable . setModel ( self . model ) self . setTheme () def update ( self ): \"\"\" Returns: \"\"\" self . model = DataFrameModel ( self . app . data . df ) self . model . sort ( 1 ) self . electrodeTable . setModel ( self . model ) def setSortOption ( self ): \"\"\" Returns: \"\"\" self . sortOption = self . chooseSortOption . currentText () print ( \"SORT OPTION: \" + self . sortOption ) self . update () def setTheme ( self ): #background_color = self.settings[\"\"] #self.electrodeTable.setBackground(background_color) # TODO set theme of electrode list pass","title":"ElectrodeListInformation"},{"location":"controller/windows/window_profiler/#src.controller.windows.window_electrodelist.ElectrodeListInformation.setSessionParent","text":"Parameters: Name Type Description Default session_parent required Source code in src/controller/windows/window_electrodelist.py def setSessionParent ( self , session_parent ): \"\"\" Args: session_parent: Returns: \"\"\" self . app = session_parent self . model = DataFrameModel ( self . app . data . df ) self . electrodeTable . setModel ( self . model ) self . setTheme ()","title":"setSessionParent()"},{"location":"controller/windows/window_profiler/#src.controller.windows.window_electrodelist.ElectrodeListInformation.setSortOption","text":"Source code in src/controller/windows/window_electrodelist.py def setSortOption ( self ): \"\"\" Returns: \"\"\" self . sortOption = self . chooseSortOption . currentText () print ( \"SORT OPTION: \" + self . sortOption ) self . update ()","title":"setSortOption()"},{"location":"controller/windows/window_profiler/#src.controller.windows.window_electrodelist.ElectrodeListInformation.update","text":"Source code in src/controller/windows/window_electrodelist.py def update ( self ): \"\"\" Returns: \"\"\" self . model = DataFrameModel ( self . app . data . df ) self . model . sort ( 1 ) self . electrodeTable . setModel ( self . model )","title":"update()"},{"location":"controller/windows/window_sessionparameters/","text":"","title":"session parameters"},{"location":"controller/windows/window_sessionstartup/","text":"","title":"session startup"},{"location":"general/getting-started/","text":"Development Getting Started Guide Note: If you would like to know how to run a compiled version of the app, refer to Intro to the GUI 1. Setting up the development environment The retina chip GUI is built completely in Python, the GUI is written with PyQt5 , the plots with PyQtGraph , and the data is manipulated through a combination of numpy , pandas , and scipy . Any IDE which can be used to edit Python code is suitable for development purposes. a. Conda environment Install and setup Anaconda . Within the Github Repository , the file dc1_vis.yml contains a list of all the packages needed to set up the development environment. A new conda environment with all the necessary packages can be installed with the command: conda env create --name rc1-gui --file dc1_vis.yml Note: this package list contains the relevant packages to run on MacOS + Apple Silicon (Huy's current development environment.) If certain packages don't install properly, this is probably because there are platform (i.e. Windows, MacOS Intel) specific packages for them. Just conda install <insert-package-name> the packages that do not install properly. b. Github Repository Clone code from the Github Repository . Additional Information: PyQt and PyQtGraph Use PyQt5 (the latest version) and PyQtGraph (specifically the v0.12 builds). For more information about the library, refers to these useful links: PyQt5 Official Documentation : https://doc.qt.io/qtforpython/ PyQt5 Useful Tutorials: : https://www.pythonguis.com/pyqt5/ PyQtGraph Official Documentation : https://pyqtgraph.readthedocs.io/en/latest/developer_guide/index.html 2. Running developer build for the first time This GUI can be run either within the terminal or inside a Python IDE such as PyCharm. a. To run in terminal On new terminal session, conda activate <name-of-env> to load relevant Python libraries Navigate to the location of run.py within the cloned repository Execute command python run.py b. To run in PyCharm The top-right bar should contain drop down menu to choose run configuration. Click on Edit configurations... Create a new configuration or edit an existing one Change the Script path to the location of run.py , i.e. /dc1DataVis/app/run.py Setup Python interpreter to be the Conda environment which you setup in part 1 The GUI should load when you press the play button now 3. Notes on important files and where files are located (last updated Jan 2023) Executing /app/run.py will startup the application. The beginning of the file contains editable parameters that will be passed through to the application ( MainWindow.py ) for the session, which can be modified by the developer. It will also be possible to toggle these parameters within the GUI in the future. Other than run.py , the entire codebase for the GUI is located within the folder dc1DataVis/app/src . Every file within the src folder should have a corresponding documentation page within this wiki. src/MainWindow.py The main application for the entire GUI! Every other script links to this file or run.py. If unsure what a file does, check where it is loaded in relation to this file. The rest of the application logic is split in a standard MVC (model-view-control) pattern, as distinguished by folders with the respective role. src/Model Files associated with loading, processing, and retrieving data for visualization.1 src/View Files associated with the layout of the GUI elements themselves (designed in QtDesigner), and associated color themes src/Controller Any logic to show or manipulate GUI windows, whether through user input and automatically through the course of the program. src/Testing This contains all the test cases for unit testing the GUI.","title":"Getting Started"},{"location":"general/getting-started/#development-getting-started-guide","text":"Note: If you would like to know how to run a compiled version of the app, refer to Intro to the GUI","title":"Development Getting Started Guide"},{"location":"general/getting-started/#1-setting-up-the-development-environment","text":"The retina chip GUI is built completely in Python, the GUI is written with PyQt5 , the plots with PyQtGraph , and the data is manipulated through a combination of numpy , pandas , and scipy . Any IDE which can be used to edit Python code is suitable for development purposes.","title":"1. Setting up the development environment"},{"location":"general/getting-started/#a-conda-environment","text":"Install and setup Anaconda . Within the Github Repository , the file dc1_vis.yml contains a list of all the packages needed to set up the development environment. A new conda environment with all the necessary packages can be installed with the command: conda env create --name rc1-gui --file dc1_vis.yml Note: this package list contains the relevant packages to run on MacOS + Apple Silicon (Huy's current development environment.) If certain packages don't install properly, this is probably because there are platform (i.e. Windows, MacOS Intel) specific packages for them. Just conda install <insert-package-name> the packages that do not install properly.","title":"a. Conda environment"},{"location":"general/getting-started/#b-github-repository","text":"Clone code from the Github Repository .","title":"b. Github Repository"},{"location":"general/getting-started/#additional-information-pyqt-and-pyqtgraph","text":"Use PyQt5 (the latest version) and PyQtGraph (specifically the v0.12 builds). For more information about the library, refers to these useful links: PyQt5 Official Documentation : https://doc.qt.io/qtforpython/ PyQt5 Useful Tutorials: : https://www.pythonguis.com/pyqt5/ PyQtGraph Official Documentation : https://pyqtgraph.readthedocs.io/en/latest/developer_guide/index.html","title":"Additional Information: PyQt and PyQtGraph"},{"location":"general/getting-started/#2-running-developer-build-for-the-first-time","text":"This GUI can be run either within the terminal or inside a Python IDE such as PyCharm.","title":"2. Running developer build for the first time"},{"location":"general/getting-started/#a-to-run-in-terminal","text":"On new terminal session, conda activate <name-of-env> to load relevant Python libraries Navigate to the location of run.py within the cloned repository Execute command python run.py","title":"a. To run in terminal"},{"location":"general/getting-started/#b-to-run-in-pycharm","text":"The top-right bar should contain drop down menu to choose run configuration. Click on Edit configurations... Create a new configuration or edit an existing one Change the Script path to the location of run.py , i.e. /dc1DataVis/app/run.py Setup Python interpreter to be the Conda environment which you setup in part 1 The GUI should load when you press the play button now","title":"b. To run in PyCharm"},{"location":"general/getting-started/#3-notes-on-important-files-and-where-files-are-located-last-updated-jan-2023","text":"Executing /app/run.py will startup the application. The beginning of the file contains editable parameters that will be passed through to the application ( MainWindow.py ) for the session, which can be modified by the developer. It will also be possible to toggle these parameters within the GUI in the future. Other than run.py , the entire codebase for the GUI is located within the folder dc1DataVis/app/src . Every file within the src folder should have a corresponding documentation page within this wiki.","title":"3. Notes on important files and where files are located (last updated Jan 2023)"},{"location":"general/getting-started/#srcmainwindowpy","text":"The main application for the entire GUI! Every other script links to this file or run.py. If unsure what a file does, check where it is loaded in relation to this file. The rest of the application logic is split in a standard MVC (model-view-control) pattern, as distinguished by folders with the respective role.","title":"src/MainWindow.py"},{"location":"general/getting-started/#srcmodel","text":"Files associated with loading, processing, and retrieving data for visualization.1","title":"src/Model"},{"location":"general/getting-started/#srcview","text":"Files associated with the layout of the GUI elements themselves (designed in QtDesigner), and associated color themes","title":"src/View"},{"location":"general/getting-started/#srccontroller","text":"Any logic to show or manipulate GUI windows, whether through user input and automatically through the course of the program.","title":"src/Controller"},{"location":"general/getting-started/#srctesting","text":"This contains all the test cases for unit testing the GUI.","title":"src/Testing"},{"location":"general/intro-to-gui/","text":"Introduction to Retina Chip GUI 1. Downloading application The latest version of the rc-gui is available here: 2. Acceptable Data Formats 3. Opening the application 4. Choose session parameters 5. Types of Visualizations a. Spike Finding Plots b. Noise Plots c. Spike Search Plots d. Diagnostic Plot 6. Additional Tools 7. Debugging and Profiling the GUI","title":"Introduction to Retina Chip GUI"},{"location":"general/intro-to-gui/#introduction-to-retina-chip-gui","text":"","title":"Introduction to Retina Chip GUI"},{"location":"general/intro-to-gui/#1-downloading-application","text":"The latest version of the rc-gui is available here:","title":"1. Downloading application"},{"location":"general/intro-to-gui/#2-acceptable-data-formats","text":"","title":"2. Acceptable Data Formats"},{"location":"general/intro-to-gui/#3-opening-the-application","text":"","title":"3. Opening the application"},{"location":"general/intro-to-gui/#4-choose-session-parameters","text":"","title":"4. Choose session parameters"},{"location":"general/intro-to-gui/#5-types-of-visualizations","text":"","title":"5. Types of Visualizations"},{"location":"general/intro-to-gui/#a-spike-finding-plots","text":"","title":"a. Spike Finding Plots"},{"location":"general/intro-to-gui/#b-noise-plots","text":"","title":"b. Noise Plots"},{"location":"general/intro-to-gui/#c-spike-search-plots","text":"","title":"c. Spike Search Plots"},{"location":"general/intro-to-gui/#d-diagnostic-plot","text":"","title":"d. Diagnostic Plot"},{"location":"general/intro-to-gui/#6-additional-tools","text":"","title":"6. Additional Tools"},{"location":"general/intro-to-gui/#7-debugging-and-profiling-the-gui","text":"","title":"7. Debugging and Profiling the GUI"},{"location":"model/DC1DataContainer/","text":"DC1 Data Container DC1DataContainer Container for holding recording model for the DC1 retina chip. Each container is designed to hold all the relevant information extracted from model collected from a SINGLE recording, of any particular type. To-Dos: TODO figure out time alignment of the model / the actual sampling rate / check for dropped packets TODO figure out time budget for model processing + filtering Source code in src/model/DC1DataContainer.py class DC1DataContainer : \"\"\" Container for holding recording model for the DC1 retina chip. Each container is designed to hold all the relevant information extracted from model collected from a SINGLE recording, of any particular type. To-Dos: ---------- TODO figure out time alignment of the model / the actual sampling rate / check for dropped packets TODO figure out time budget for model processing + filtering \"\"\" # +++++ CONSTANTS +++++ # DC1/RC1.5 is a multi-electrode array (MEA) with 32 x 32 channels (1024 total) ARRAY_NUM_ROWS , ARRAY_NUM_COLS = 32 , 32 count_track , time_track = None , None # calculated statistics spike_data = { 'times' : np . zeros (( 32 , 32 )), # np.array with dims 32 x 32 x num_bins 'amplitude' : np . zeros (( 32 , 32 )) } # new model structs to_serialize , to_show = None , None avg_spike_rate_x = [] avg_spike_rate_y = [] def __init__ ( self , app , recording_info = {}, data_processing_settings = {}): \"\"\" Args: app: recording_info: data_processing_settings: \"\"\" self . app = app # reference to MainWindow self . time_track , self . count_track = 0 , 0 self . time_track_processed , self . count_track_processed = 0 , 0 # channel-level information # indexed via row, col of array # value: a dict containing all info for a certain electrode # self.array_indexed_df = pd.Dataframe() # TODO make array-indexed pandas df to replace below df_columns = [ \"row\" , \"col\" , # indexing \"avg_filtered_amp\" , \"avg_unfiltered_amp\" , \"channel_noise_mean\" , \"channel_noise_std\" , # noise \"start_time\" , \"start_count\" , \"buf_recording_len\" , \"N\" , \"packet_idx\" , # timing \"spikes_avg_amp\" , \"spikes_cnt\" , \"spikes_std\" , \"spikes_cum_cnt\" , \"num_bins_per_buffer\" , #spikes \"array_dot_color\" , \"array_dot_size\" # specific plot info ] initial_data = [] for i in range ( 32 ): for j in range ( 32 ): initial_data . append ([ i , j , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]) self . df = pd . DataFrame ( initial_data , columns = df_columns ) self . stats = { \"largest_spike_cnt\" : 0 } self . array_spike_times = { \"spike_bins\" : [[] for i in range ( self . ARRAY_NUM_ROWS * self . ARRAY_NUM_COLS )], \"spike_bins_max_amps\" : [[] for i in range ( self . ARRAY_NUM_ROWS * self . ARRAY_NUM_COLS )] } # ===================== # buffer-level information # indexed via key: buffer number (0 - MAX_NUMBER_OF_BUFFERS) # value: self . buffer_indexed = [] self . to_serialize = queue . Queue () self . to_show = queue . Queue () def append_buf ( self , buf ): \"\"\" Args: buf: Returns: \"\"\" packet_idx = buf [ 'packet_idx' ] channel_idxs = [] # for buffer_indexed model struct # calculate times N = buf [ \"packet_data\" ][ 0 ][ \"N\" ] len_packet_time = N * 0.05 # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms next_times = np . linspace ( self . time_track , self . time_track + len_packet_time , N ) self . time_track += len_packet_time self . count_track += N avg_packet_spike_count = 0 packet_data = buf [ 'packet_data' ] for packet in packet_data : # load model # packet keys: 'data_real', 'cnt_real', 'N', # 'channel_idx', 'preprocessed_data', 'filtered_data', # 'stats_cnt', 'stats_noise+mean', 'stats_noise+std' this_channel_idx = packet [ 'channel_idx' ] # for buffer_indexed model struct channel_idxs . append ( this_channel_idx ) # reformatting packet for to_show model struct packet [ \"times\" ] = next_times # for array_indexed model struct r , c = idx2map ( this_channel_idx ) # TODO make this adapt for when multiple packets record from the same channel # use formula Maddy gave df_columns = [ \"row\" , \"col\" , # indexing \"avg_filtered_amp\" , \"avg_unfiltered_amp\" , \"noise_mean\" , \"noise_std\" , # noise \"start_time\" , \"start_count\" , \"buf_recording_len\" , \"N\" , \"packet_idx\" , # timing \"spikes_avg_amp\" , \"spikes_cnt\" , \"spikes_std\" , \"spikes_cum_cnt\" , \"num_bins_per_buffer\" ] # spikes self . df . at [ this_channel_idx , \"N\" ] += packet [ \"stats_cnt\" ] self . df . at [ this_channel_idx , \"avg_unfiltered_amp\" ] = packet [ \"stats_avg+unfiltered+amp\" ] self . df . at [ this_channel_idx , \"noise_mean\" ] = packet [ \"stats_noise+mean\" ] self . df . at [ this_channel_idx , \"noise_std\" ] = packet [ \"stats_noise+std\" ] self . df . at [ this_channel_idx , \"buf_recording_len\" ] = packet [ \"stats_buf+recording+len\" ] self . df . at [ this_channel_idx , \"avg_unfiltered_amp\" ] = packet [ \"stats_avg+unfiltered+amp\" ] self . df . at [ this_channel_idx , \"spikes_cnt\" ] = packet [ \"stats_spikes+cnt\" ] self . df . at [ this_channel_idx , \"spikes_cum_cnt\" ] += packet [ \"stats_spikes+cnt\" ] self . df . at [ this_channel_idx , \"spikes_avg_amp\" ] += packet [ \"stats_spikes+avg+amp\" ] self . df . at [ this_channel_idx , \"spikes_std\" ] += packet [ \"stats_spikes+std\" ] \"\"\" self.array_indexed = { \"stats_num+spike+bins+in+buffer\": np.zeros((self.ARRAY_NUM_ROWS, self.ARRAY_NUM_COLS)), \"spike_bins\": [([] for i in range(self.ARRAY_NUM_ROWS)) for j in range(self.ARRAY_NUM_COLS)], \"spike_bins_max_amps\": [([] for i in range(self.ARRAY_NUM_ROWS)) for j in range(self.ARRAY_NUM_COLS)] } \"\"\" # TODO put spike bins here #print('array spike times -> spike_bins', packet[\"spike_bins\"]) #print('array spike times -> spike_bins_max_amp', packet[\"spike_bins_max_amps\"]) self . array_spike_times [ \"spike_bins\" ][ this_channel_idx ] = packet [ \"spike_bins\" ] self . array_spike_times [ \"spike_bins_max_amps\" ][ this_channel_idx ] = packet [ \"spike_bins_max_amps\" ] avg_packet_spike_count += packet [ \"stats_spikes+cnt\" ] # buffer-level information buffer_indexed_dict = { \"file_dir\" : buf [ \"file_dir\" ], \"filter_type\" : buf [ \"filter_type\" ], \"N\" : N , \"time_elapsed\" : len_packet_time , # TODO check if this is accurate for all recording types \"channel_idxs\" : channel_idxs , \"num_detected_spikes\" : avg_packet_spike_count / len ( packet_data ) # for spike rate plot } self . buffer_indexed . append ( buffer_indexed_dict ) self . calculate_moving_spike_rate_avg () self . to_show . put ( buf ) # return the channels in the buffer return buffer_indexed_dict [ \"channel_idxs\" ] def calculate_moving_spike_rate_avg ( self ): \"\"\" Returns: \"\"\" avg_spike_rate = 0 time_elapsed = 0 SPIKE_RATE_WINDOW_SIZE = 4 if len ( self . buffer_indexed ) < SPIKE_RATE_WINDOW_SIZE : for buffer in self . buffer_indexed : avg_spike_rate += buffer [ \"num_detected_spikes\" ] time_elapsed += buffer [ \"time_elapsed\" ] else : for buffer in self . buffer_indexed [ - 1 - SPIKE_RATE_WINDOW_SIZE : - 1 ]: avg_spike_rate += buffer [ \"num_detected_spikes\" ] time_elapsed += buffer [ \"time_elapsed\" ] #print('avg spike rate before division', avg_spike_rate) avg_spike_rate /= time_elapsed x = self . time_track y = avg_spike_rate self . avg_spike_rate_x . append ( x ) self . avg_spike_rate_y . append ( y ) def find_last_buffer_with_electrode_idx ( self , electrode_idx ): \"\"\" Args: electrode_idx: Returns: \"\"\" # return buffer which contains an electrode idx # start from the end len_processed_buffer = len ( self . buffer_indexed ) for i in reversed ( range ( len_processed_buffer )): if electrode_idx in self . buffer_indexed [ i ][ \"channel_idxs\" ]: return i return - 1 def find_all_buffers_with_electrode_idx ( self , electrode_idx ): \"\"\" Args: electrode_idx: Returns: \"\"\" buffers = [] len_processed_buffer = len ( self . buffer_indexed ) for i in range ( len_processed_buffer ): if electrode_idx in self . buffer_indexed [ i ][ \"channel_idxs\" ]: buffers . append ( i ) return buffers def get_last_trace_with_electrode_idx ( self , electrode_idx ): \"\"\" Args: electrode_idx: Returns: \"\"\" buffer_idx = self . find_last_buffer_with_electrode_idx ( electrode_idx ) if buffer_idx == - 1 : return None , None else : params = { \"file_dir\" : self . buffer_indexed [ buffer_idx ][ \"file_dir\" ], \"filter_type\" : self . buffer_indexed [ buffer_idx ][ \"filter_type\" ], \"SPIKING_THRESHOLD\" : self . app . settings [ \"spikeThreshold\" ], \"BIN_SIZE\" : self . app . settings [ \"binSize\" ] } N , Y = None , None packet = load_one_mat_file ( params ) for channel_data in packet [ \"packet_data\" ]: if channel_data [ \"channel_idx\" ] == electrode_idx : Y = channel_data [ \"filtered_data\" ] N = channel_data [ \"N\" ] time_elapsed = self . buffer_indexed [ buffer_idx ][ \"time_elapsed\" ] SAMPLING_PERIOD = 0.05 # check data_loading_mat.py for more details end_time = N * SAMPLING_PERIOD X = np . linspace ( time_elapsed , time_elapsed + end_time , N + 1 ) return X , Y __init__ ( self , app , recording_info = {}, data_processing_settings = {}) special Parameters: Name Type Description Default app required recording_info {} data_processing_settings {} Source code in src/model/DC1DataContainer.py def __init__ ( self , app , recording_info = {}, data_processing_settings = {}): \"\"\" Args: app: recording_info: data_processing_settings: \"\"\" self . app = app # reference to MainWindow self . time_track , self . count_track = 0 , 0 self . time_track_processed , self . count_track_processed = 0 , 0 # channel-level information # indexed via row, col of array # value: a dict containing all info for a certain electrode # self.array_indexed_df = pd.Dataframe() # TODO make array-indexed pandas df to replace below df_columns = [ \"row\" , \"col\" , # indexing \"avg_filtered_amp\" , \"avg_unfiltered_amp\" , \"channel_noise_mean\" , \"channel_noise_std\" , # noise \"start_time\" , \"start_count\" , \"buf_recording_len\" , \"N\" , \"packet_idx\" , # timing \"spikes_avg_amp\" , \"spikes_cnt\" , \"spikes_std\" , \"spikes_cum_cnt\" , \"num_bins_per_buffer\" , #spikes \"array_dot_color\" , \"array_dot_size\" # specific plot info ] initial_data = [] for i in range ( 32 ): for j in range ( 32 ): initial_data . append ([ i , j , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]) self . df = pd . DataFrame ( initial_data , columns = df_columns ) self . stats = { \"largest_spike_cnt\" : 0 } self . array_spike_times = { \"spike_bins\" : [[] for i in range ( self . ARRAY_NUM_ROWS * self . ARRAY_NUM_COLS )], \"spike_bins_max_amps\" : [[] for i in range ( self . ARRAY_NUM_ROWS * self . ARRAY_NUM_COLS )] } # ===================== # buffer-level information # indexed via key: buffer number (0 - MAX_NUMBER_OF_BUFFERS) # value: self . buffer_indexed = [] self . to_serialize = queue . Queue () self . to_show = queue . Queue () append_buf ( self , buf ) Parameters: Name Type Description Default buf required Source code in src/model/DC1DataContainer.py def append_buf ( self , buf ): \"\"\" Args: buf: Returns: \"\"\" packet_idx = buf [ 'packet_idx' ] channel_idxs = [] # for buffer_indexed model struct # calculate times N = buf [ \"packet_data\" ][ 0 ][ \"N\" ] len_packet_time = N * 0.05 # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms next_times = np . linspace ( self . time_track , self . time_track + len_packet_time , N ) self . time_track += len_packet_time self . count_track += N avg_packet_spike_count = 0 packet_data = buf [ 'packet_data' ] for packet in packet_data : # load model # packet keys: 'data_real', 'cnt_real', 'N', # 'channel_idx', 'preprocessed_data', 'filtered_data', # 'stats_cnt', 'stats_noise+mean', 'stats_noise+std' this_channel_idx = packet [ 'channel_idx' ] # for buffer_indexed model struct channel_idxs . append ( this_channel_idx ) # reformatting packet for to_show model struct packet [ \"times\" ] = next_times # for array_indexed model struct r , c = idx2map ( this_channel_idx ) # TODO make this adapt for when multiple packets record from the same channel # use formula Maddy gave df_columns = [ \"row\" , \"col\" , # indexing \"avg_filtered_amp\" , \"avg_unfiltered_amp\" , \"noise_mean\" , \"noise_std\" , # noise \"start_time\" , \"start_count\" , \"buf_recording_len\" , \"N\" , \"packet_idx\" , # timing \"spikes_avg_amp\" , \"spikes_cnt\" , \"spikes_std\" , \"spikes_cum_cnt\" , \"num_bins_per_buffer\" ] # spikes self . df . at [ this_channel_idx , \"N\" ] += packet [ \"stats_cnt\" ] self . df . at [ this_channel_idx , \"avg_unfiltered_amp\" ] = packet [ \"stats_avg+unfiltered+amp\" ] self . df . at [ this_channel_idx , \"noise_mean\" ] = packet [ \"stats_noise+mean\" ] self . df . at [ this_channel_idx , \"noise_std\" ] = packet [ \"stats_noise+std\" ] self . df . at [ this_channel_idx , \"buf_recording_len\" ] = packet [ \"stats_buf+recording+len\" ] self . df . at [ this_channel_idx , \"avg_unfiltered_amp\" ] = packet [ \"stats_avg+unfiltered+amp\" ] self . df . at [ this_channel_idx , \"spikes_cnt\" ] = packet [ \"stats_spikes+cnt\" ] self . df . at [ this_channel_idx , \"spikes_cum_cnt\" ] += packet [ \"stats_spikes+cnt\" ] self . df . at [ this_channel_idx , \"spikes_avg_amp\" ] += packet [ \"stats_spikes+avg+amp\" ] self . df . at [ this_channel_idx , \"spikes_std\" ] += packet [ \"stats_spikes+std\" ] \"\"\" self.array_indexed = { \"stats_num+spike+bins+in+buffer\": np.zeros((self.ARRAY_NUM_ROWS, self.ARRAY_NUM_COLS)), \"spike_bins\": [([] for i in range(self.ARRAY_NUM_ROWS)) for j in range(self.ARRAY_NUM_COLS)], \"spike_bins_max_amps\": [([] for i in range(self.ARRAY_NUM_ROWS)) for j in range(self.ARRAY_NUM_COLS)] } \"\"\" # TODO put spike bins here #print('array spike times -> spike_bins', packet[\"spike_bins\"]) #print('array spike times -> spike_bins_max_amp', packet[\"spike_bins_max_amps\"]) self . array_spike_times [ \"spike_bins\" ][ this_channel_idx ] = packet [ \"spike_bins\" ] self . array_spike_times [ \"spike_bins_max_amps\" ][ this_channel_idx ] = packet [ \"spike_bins_max_amps\" ] avg_packet_spike_count += packet [ \"stats_spikes+cnt\" ] # buffer-level information buffer_indexed_dict = { \"file_dir\" : buf [ \"file_dir\" ], \"filter_type\" : buf [ \"filter_type\" ], \"N\" : N , \"time_elapsed\" : len_packet_time , # TODO check if this is accurate for all recording types \"channel_idxs\" : channel_idxs , \"num_detected_spikes\" : avg_packet_spike_count / len ( packet_data ) # for spike rate plot } self . buffer_indexed . append ( buffer_indexed_dict ) self . calculate_moving_spike_rate_avg () self . to_show . put ( buf ) # return the channels in the buffer return buffer_indexed_dict [ \"channel_idxs\" ] calculate_moving_spike_rate_avg ( self ) Source code in src/model/DC1DataContainer.py def calculate_moving_spike_rate_avg ( self ): \"\"\" Returns: \"\"\" avg_spike_rate = 0 time_elapsed = 0 SPIKE_RATE_WINDOW_SIZE = 4 if len ( self . buffer_indexed ) < SPIKE_RATE_WINDOW_SIZE : for buffer in self . buffer_indexed : avg_spike_rate += buffer [ \"num_detected_spikes\" ] time_elapsed += buffer [ \"time_elapsed\" ] else : for buffer in self . buffer_indexed [ - 1 - SPIKE_RATE_WINDOW_SIZE : - 1 ]: avg_spike_rate += buffer [ \"num_detected_spikes\" ] time_elapsed += buffer [ \"time_elapsed\" ] #print('avg spike rate before division', avg_spike_rate) avg_spike_rate /= time_elapsed x = self . time_track y = avg_spike_rate self . avg_spike_rate_x . append ( x ) self . avg_spike_rate_y . append ( y ) find_all_buffers_with_electrode_idx ( self , electrode_idx ) Parameters: Name Type Description Default electrode_idx required Source code in src/model/DC1DataContainer.py def find_all_buffers_with_electrode_idx ( self , electrode_idx ): \"\"\" Args: electrode_idx: Returns: \"\"\" buffers = [] len_processed_buffer = len ( self . buffer_indexed ) for i in range ( len_processed_buffer ): if electrode_idx in self . buffer_indexed [ i ][ \"channel_idxs\" ]: buffers . append ( i ) return buffers find_last_buffer_with_electrode_idx ( self , electrode_idx ) Parameters: Name Type Description Default electrode_idx required Source code in src/model/DC1DataContainer.py def find_last_buffer_with_electrode_idx ( self , electrode_idx ): \"\"\" Args: electrode_idx: Returns: \"\"\" # return buffer which contains an electrode idx # start from the end len_processed_buffer = len ( self . buffer_indexed ) for i in reversed ( range ( len_processed_buffer )): if electrode_idx in self . buffer_indexed [ i ][ \"channel_idxs\" ]: return i return - 1 get_last_trace_with_electrode_idx ( self , electrode_idx ) Parameters: Name Type Description Default electrode_idx required Source code in src/model/DC1DataContainer.py def get_last_trace_with_electrode_idx ( self , electrode_idx ): \"\"\" Args: electrode_idx: Returns: \"\"\" buffer_idx = self . find_last_buffer_with_electrode_idx ( electrode_idx ) if buffer_idx == - 1 : return None , None else : params = { \"file_dir\" : self . buffer_indexed [ buffer_idx ][ \"file_dir\" ], \"filter_type\" : self . buffer_indexed [ buffer_idx ][ \"filter_type\" ], \"SPIKING_THRESHOLD\" : self . app . settings [ \"spikeThreshold\" ], \"BIN_SIZE\" : self . app . settings [ \"binSize\" ] } N , Y = None , None packet = load_one_mat_file ( params ) for channel_data in packet [ \"packet_data\" ]: if channel_data [ \"channel_idx\" ] == electrode_idx : Y = channel_data [ \"filtered_data\" ] N = channel_data [ \"N\" ] time_elapsed = self . buffer_indexed [ buffer_idx ][ \"time_elapsed\" ] SAMPLING_PERIOD = 0.05 # check data_loading_mat.py for more details end_time = N * SAMPLING_PERIOD X = np . linspace ( time_elapsed , time_elapsed + end_time , N + 1 ) return X , Y map2idx ( ch_row , ch_col ) Given a channel's row and col, return channel's index Parameters: Name Type Description Default ch_row int row index of channel in array (up to 32) required ch_col int column index of channel in array (up to 32) required Returns: numerical index of array Source code in src/model/DC1DataContainer.py def map2idx ( ch_row : int , ch_col : int ): \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx","title":"data structs"},{"location":"model/DC1DataContainer/#dc1-data-container","text":"","title":"DC1 Data Container"},{"location":"model/DC1DataContainer/#src.model.DC1DataContainer.DC1DataContainer","text":"Container for holding recording model for the DC1 retina chip. Each container is designed to hold all the relevant information extracted from model collected from a SINGLE recording, of any particular type.","title":"DC1DataContainer"},{"location":"model/DC1DataContainer/#src.model.DC1DataContainer.DC1DataContainer--to-dos","text":"TODO figure out time alignment of the model / the actual sampling rate / check for dropped packets TODO figure out time budget for model processing + filtering Source code in src/model/DC1DataContainer.py class DC1DataContainer : \"\"\" Container for holding recording model for the DC1 retina chip. Each container is designed to hold all the relevant information extracted from model collected from a SINGLE recording, of any particular type. To-Dos: ---------- TODO figure out time alignment of the model / the actual sampling rate / check for dropped packets TODO figure out time budget for model processing + filtering \"\"\" # +++++ CONSTANTS +++++ # DC1/RC1.5 is a multi-electrode array (MEA) with 32 x 32 channels (1024 total) ARRAY_NUM_ROWS , ARRAY_NUM_COLS = 32 , 32 count_track , time_track = None , None # calculated statistics spike_data = { 'times' : np . zeros (( 32 , 32 )), # np.array with dims 32 x 32 x num_bins 'amplitude' : np . zeros (( 32 , 32 )) } # new model structs to_serialize , to_show = None , None avg_spike_rate_x = [] avg_spike_rate_y = [] def __init__ ( self , app , recording_info = {}, data_processing_settings = {}): \"\"\" Args: app: recording_info: data_processing_settings: \"\"\" self . app = app # reference to MainWindow self . time_track , self . count_track = 0 , 0 self . time_track_processed , self . count_track_processed = 0 , 0 # channel-level information # indexed via row, col of array # value: a dict containing all info for a certain electrode # self.array_indexed_df = pd.Dataframe() # TODO make array-indexed pandas df to replace below df_columns = [ \"row\" , \"col\" , # indexing \"avg_filtered_amp\" , \"avg_unfiltered_amp\" , \"channel_noise_mean\" , \"channel_noise_std\" , # noise \"start_time\" , \"start_count\" , \"buf_recording_len\" , \"N\" , \"packet_idx\" , # timing \"spikes_avg_amp\" , \"spikes_cnt\" , \"spikes_std\" , \"spikes_cum_cnt\" , \"num_bins_per_buffer\" , #spikes \"array_dot_color\" , \"array_dot_size\" # specific plot info ] initial_data = [] for i in range ( 32 ): for j in range ( 32 ): initial_data . append ([ i , j , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]) self . df = pd . DataFrame ( initial_data , columns = df_columns ) self . stats = { \"largest_spike_cnt\" : 0 } self . array_spike_times = { \"spike_bins\" : [[] for i in range ( self . ARRAY_NUM_ROWS * self . ARRAY_NUM_COLS )], \"spike_bins_max_amps\" : [[] for i in range ( self . ARRAY_NUM_ROWS * self . ARRAY_NUM_COLS )] } # ===================== # buffer-level information # indexed via key: buffer number (0 - MAX_NUMBER_OF_BUFFERS) # value: self . buffer_indexed = [] self . to_serialize = queue . Queue () self . to_show = queue . Queue () def append_buf ( self , buf ): \"\"\" Args: buf: Returns: \"\"\" packet_idx = buf [ 'packet_idx' ] channel_idxs = [] # for buffer_indexed model struct # calculate times N = buf [ \"packet_data\" ][ 0 ][ \"N\" ] len_packet_time = N * 0.05 # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms next_times = np . linspace ( self . time_track , self . time_track + len_packet_time , N ) self . time_track += len_packet_time self . count_track += N avg_packet_spike_count = 0 packet_data = buf [ 'packet_data' ] for packet in packet_data : # load model # packet keys: 'data_real', 'cnt_real', 'N', # 'channel_idx', 'preprocessed_data', 'filtered_data', # 'stats_cnt', 'stats_noise+mean', 'stats_noise+std' this_channel_idx = packet [ 'channel_idx' ] # for buffer_indexed model struct channel_idxs . append ( this_channel_idx ) # reformatting packet for to_show model struct packet [ \"times\" ] = next_times # for array_indexed model struct r , c = idx2map ( this_channel_idx ) # TODO make this adapt for when multiple packets record from the same channel # use formula Maddy gave df_columns = [ \"row\" , \"col\" , # indexing \"avg_filtered_amp\" , \"avg_unfiltered_amp\" , \"noise_mean\" , \"noise_std\" , # noise \"start_time\" , \"start_count\" , \"buf_recording_len\" , \"N\" , \"packet_idx\" , # timing \"spikes_avg_amp\" , \"spikes_cnt\" , \"spikes_std\" , \"spikes_cum_cnt\" , \"num_bins_per_buffer\" ] # spikes self . df . at [ this_channel_idx , \"N\" ] += packet [ \"stats_cnt\" ] self . df . at [ this_channel_idx , \"avg_unfiltered_amp\" ] = packet [ \"stats_avg+unfiltered+amp\" ] self . df . at [ this_channel_idx , \"noise_mean\" ] = packet [ \"stats_noise+mean\" ] self . df . at [ this_channel_idx , \"noise_std\" ] = packet [ \"stats_noise+std\" ] self . df . at [ this_channel_idx , \"buf_recording_len\" ] = packet [ \"stats_buf+recording+len\" ] self . df . at [ this_channel_idx , \"avg_unfiltered_amp\" ] = packet [ \"stats_avg+unfiltered+amp\" ] self . df . at [ this_channel_idx , \"spikes_cnt\" ] = packet [ \"stats_spikes+cnt\" ] self . df . at [ this_channel_idx , \"spikes_cum_cnt\" ] += packet [ \"stats_spikes+cnt\" ] self . df . at [ this_channel_idx , \"spikes_avg_amp\" ] += packet [ \"stats_spikes+avg+amp\" ] self . df . at [ this_channel_idx , \"spikes_std\" ] += packet [ \"stats_spikes+std\" ] \"\"\" self.array_indexed = { \"stats_num+spike+bins+in+buffer\": np.zeros((self.ARRAY_NUM_ROWS, self.ARRAY_NUM_COLS)), \"spike_bins\": [([] for i in range(self.ARRAY_NUM_ROWS)) for j in range(self.ARRAY_NUM_COLS)], \"spike_bins_max_amps\": [([] for i in range(self.ARRAY_NUM_ROWS)) for j in range(self.ARRAY_NUM_COLS)] } \"\"\" # TODO put spike bins here #print('array spike times -> spike_bins', packet[\"spike_bins\"]) #print('array spike times -> spike_bins_max_amp', packet[\"spike_bins_max_amps\"]) self . array_spike_times [ \"spike_bins\" ][ this_channel_idx ] = packet [ \"spike_bins\" ] self . array_spike_times [ \"spike_bins_max_amps\" ][ this_channel_idx ] = packet [ \"spike_bins_max_amps\" ] avg_packet_spike_count += packet [ \"stats_spikes+cnt\" ] # buffer-level information buffer_indexed_dict = { \"file_dir\" : buf [ \"file_dir\" ], \"filter_type\" : buf [ \"filter_type\" ], \"N\" : N , \"time_elapsed\" : len_packet_time , # TODO check if this is accurate for all recording types \"channel_idxs\" : channel_idxs , \"num_detected_spikes\" : avg_packet_spike_count / len ( packet_data ) # for spike rate plot } self . buffer_indexed . append ( buffer_indexed_dict ) self . calculate_moving_spike_rate_avg () self . to_show . put ( buf ) # return the channels in the buffer return buffer_indexed_dict [ \"channel_idxs\" ] def calculate_moving_spike_rate_avg ( self ): \"\"\" Returns: \"\"\" avg_spike_rate = 0 time_elapsed = 0 SPIKE_RATE_WINDOW_SIZE = 4 if len ( self . buffer_indexed ) < SPIKE_RATE_WINDOW_SIZE : for buffer in self . buffer_indexed : avg_spike_rate += buffer [ \"num_detected_spikes\" ] time_elapsed += buffer [ \"time_elapsed\" ] else : for buffer in self . buffer_indexed [ - 1 - SPIKE_RATE_WINDOW_SIZE : - 1 ]: avg_spike_rate += buffer [ \"num_detected_spikes\" ] time_elapsed += buffer [ \"time_elapsed\" ] #print('avg spike rate before division', avg_spike_rate) avg_spike_rate /= time_elapsed x = self . time_track y = avg_spike_rate self . avg_spike_rate_x . append ( x ) self . avg_spike_rate_y . append ( y ) def find_last_buffer_with_electrode_idx ( self , electrode_idx ): \"\"\" Args: electrode_idx: Returns: \"\"\" # return buffer which contains an electrode idx # start from the end len_processed_buffer = len ( self . buffer_indexed ) for i in reversed ( range ( len_processed_buffer )): if electrode_idx in self . buffer_indexed [ i ][ \"channel_idxs\" ]: return i return - 1 def find_all_buffers_with_electrode_idx ( self , electrode_idx ): \"\"\" Args: electrode_idx: Returns: \"\"\" buffers = [] len_processed_buffer = len ( self . buffer_indexed ) for i in range ( len_processed_buffer ): if electrode_idx in self . buffer_indexed [ i ][ \"channel_idxs\" ]: buffers . append ( i ) return buffers def get_last_trace_with_electrode_idx ( self , electrode_idx ): \"\"\" Args: electrode_idx: Returns: \"\"\" buffer_idx = self . find_last_buffer_with_electrode_idx ( electrode_idx ) if buffer_idx == - 1 : return None , None else : params = { \"file_dir\" : self . buffer_indexed [ buffer_idx ][ \"file_dir\" ], \"filter_type\" : self . buffer_indexed [ buffer_idx ][ \"filter_type\" ], \"SPIKING_THRESHOLD\" : self . app . settings [ \"spikeThreshold\" ], \"BIN_SIZE\" : self . app . settings [ \"binSize\" ] } N , Y = None , None packet = load_one_mat_file ( params ) for channel_data in packet [ \"packet_data\" ]: if channel_data [ \"channel_idx\" ] == electrode_idx : Y = channel_data [ \"filtered_data\" ] N = channel_data [ \"N\" ] time_elapsed = self . buffer_indexed [ buffer_idx ][ \"time_elapsed\" ] SAMPLING_PERIOD = 0.05 # check data_loading_mat.py for more details end_time = N * SAMPLING_PERIOD X = np . linspace ( time_elapsed , time_elapsed + end_time , N + 1 ) return X , Y","title":"To-Dos:"},{"location":"model/DC1DataContainer/#src.model.DC1DataContainer.DC1DataContainer.__init__","text":"Parameters: Name Type Description Default app required recording_info {} data_processing_settings {} Source code in src/model/DC1DataContainer.py def __init__ ( self , app , recording_info = {}, data_processing_settings = {}): \"\"\" Args: app: recording_info: data_processing_settings: \"\"\" self . app = app # reference to MainWindow self . time_track , self . count_track = 0 , 0 self . time_track_processed , self . count_track_processed = 0 , 0 # channel-level information # indexed via row, col of array # value: a dict containing all info for a certain electrode # self.array_indexed_df = pd.Dataframe() # TODO make array-indexed pandas df to replace below df_columns = [ \"row\" , \"col\" , # indexing \"avg_filtered_amp\" , \"avg_unfiltered_amp\" , \"channel_noise_mean\" , \"channel_noise_std\" , # noise \"start_time\" , \"start_count\" , \"buf_recording_len\" , \"N\" , \"packet_idx\" , # timing \"spikes_avg_amp\" , \"spikes_cnt\" , \"spikes_std\" , \"spikes_cum_cnt\" , \"num_bins_per_buffer\" , #spikes \"array_dot_color\" , \"array_dot_size\" # specific plot info ] initial_data = [] for i in range ( 32 ): for j in range ( 32 ): initial_data . append ([ i , j , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]) self . df = pd . DataFrame ( initial_data , columns = df_columns ) self . stats = { \"largest_spike_cnt\" : 0 } self . array_spike_times = { \"spike_bins\" : [[] for i in range ( self . ARRAY_NUM_ROWS * self . ARRAY_NUM_COLS )], \"spike_bins_max_amps\" : [[] for i in range ( self . ARRAY_NUM_ROWS * self . ARRAY_NUM_COLS )] } # ===================== # buffer-level information # indexed via key: buffer number (0 - MAX_NUMBER_OF_BUFFERS) # value: self . buffer_indexed = [] self . to_serialize = queue . Queue () self . to_show = queue . Queue ()","title":"__init__()"},{"location":"model/DC1DataContainer/#src.model.DC1DataContainer.DC1DataContainer.append_buf","text":"Parameters: Name Type Description Default buf required Source code in src/model/DC1DataContainer.py def append_buf ( self , buf ): \"\"\" Args: buf: Returns: \"\"\" packet_idx = buf [ 'packet_idx' ] channel_idxs = [] # for buffer_indexed model struct # calculate times N = buf [ \"packet_data\" ][ 0 ][ \"N\" ] len_packet_time = N * 0.05 # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms next_times = np . linspace ( self . time_track , self . time_track + len_packet_time , N ) self . time_track += len_packet_time self . count_track += N avg_packet_spike_count = 0 packet_data = buf [ 'packet_data' ] for packet in packet_data : # load model # packet keys: 'data_real', 'cnt_real', 'N', # 'channel_idx', 'preprocessed_data', 'filtered_data', # 'stats_cnt', 'stats_noise+mean', 'stats_noise+std' this_channel_idx = packet [ 'channel_idx' ] # for buffer_indexed model struct channel_idxs . append ( this_channel_idx ) # reformatting packet for to_show model struct packet [ \"times\" ] = next_times # for array_indexed model struct r , c = idx2map ( this_channel_idx ) # TODO make this adapt for when multiple packets record from the same channel # use formula Maddy gave df_columns = [ \"row\" , \"col\" , # indexing \"avg_filtered_amp\" , \"avg_unfiltered_amp\" , \"noise_mean\" , \"noise_std\" , # noise \"start_time\" , \"start_count\" , \"buf_recording_len\" , \"N\" , \"packet_idx\" , # timing \"spikes_avg_amp\" , \"spikes_cnt\" , \"spikes_std\" , \"spikes_cum_cnt\" , \"num_bins_per_buffer\" ] # spikes self . df . at [ this_channel_idx , \"N\" ] += packet [ \"stats_cnt\" ] self . df . at [ this_channel_idx , \"avg_unfiltered_amp\" ] = packet [ \"stats_avg+unfiltered+amp\" ] self . df . at [ this_channel_idx , \"noise_mean\" ] = packet [ \"stats_noise+mean\" ] self . df . at [ this_channel_idx , \"noise_std\" ] = packet [ \"stats_noise+std\" ] self . df . at [ this_channel_idx , \"buf_recording_len\" ] = packet [ \"stats_buf+recording+len\" ] self . df . at [ this_channel_idx , \"avg_unfiltered_amp\" ] = packet [ \"stats_avg+unfiltered+amp\" ] self . df . at [ this_channel_idx , \"spikes_cnt\" ] = packet [ \"stats_spikes+cnt\" ] self . df . at [ this_channel_idx , \"spikes_cum_cnt\" ] += packet [ \"stats_spikes+cnt\" ] self . df . at [ this_channel_idx , \"spikes_avg_amp\" ] += packet [ \"stats_spikes+avg+amp\" ] self . df . at [ this_channel_idx , \"spikes_std\" ] += packet [ \"stats_spikes+std\" ] \"\"\" self.array_indexed = { \"stats_num+spike+bins+in+buffer\": np.zeros((self.ARRAY_NUM_ROWS, self.ARRAY_NUM_COLS)), \"spike_bins\": [([] for i in range(self.ARRAY_NUM_ROWS)) for j in range(self.ARRAY_NUM_COLS)], \"spike_bins_max_amps\": [([] for i in range(self.ARRAY_NUM_ROWS)) for j in range(self.ARRAY_NUM_COLS)] } \"\"\" # TODO put spike bins here #print('array spike times -> spike_bins', packet[\"spike_bins\"]) #print('array spike times -> spike_bins_max_amp', packet[\"spike_bins_max_amps\"]) self . array_spike_times [ \"spike_bins\" ][ this_channel_idx ] = packet [ \"spike_bins\" ] self . array_spike_times [ \"spike_bins_max_amps\" ][ this_channel_idx ] = packet [ \"spike_bins_max_amps\" ] avg_packet_spike_count += packet [ \"stats_spikes+cnt\" ] # buffer-level information buffer_indexed_dict = { \"file_dir\" : buf [ \"file_dir\" ], \"filter_type\" : buf [ \"filter_type\" ], \"N\" : N , \"time_elapsed\" : len_packet_time , # TODO check if this is accurate for all recording types \"channel_idxs\" : channel_idxs , \"num_detected_spikes\" : avg_packet_spike_count / len ( packet_data ) # for spike rate plot } self . buffer_indexed . append ( buffer_indexed_dict ) self . calculate_moving_spike_rate_avg () self . to_show . put ( buf ) # return the channels in the buffer return buffer_indexed_dict [ \"channel_idxs\" ]","title":"append_buf()"},{"location":"model/DC1DataContainer/#src.model.DC1DataContainer.DC1DataContainer.calculate_moving_spike_rate_avg","text":"Source code in src/model/DC1DataContainer.py def calculate_moving_spike_rate_avg ( self ): \"\"\" Returns: \"\"\" avg_spike_rate = 0 time_elapsed = 0 SPIKE_RATE_WINDOW_SIZE = 4 if len ( self . buffer_indexed ) < SPIKE_RATE_WINDOW_SIZE : for buffer in self . buffer_indexed : avg_spike_rate += buffer [ \"num_detected_spikes\" ] time_elapsed += buffer [ \"time_elapsed\" ] else : for buffer in self . buffer_indexed [ - 1 - SPIKE_RATE_WINDOW_SIZE : - 1 ]: avg_spike_rate += buffer [ \"num_detected_spikes\" ] time_elapsed += buffer [ \"time_elapsed\" ] #print('avg spike rate before division', avg_spike_rate) avg_spike_rate /= time_elapsed x = self . time_track y = avg_spike_rate self . avg_spike_rate_x . append ( x ) self . avg_spike_rate_y . append ( y )","title":"calculate_moving_spike_rate_avg()"},{"location":"model/DC1DataContainer/#src.model.DC1DataContainer.DC1DataContainer.find_all_buffers_with_electrode_idx","text":"Parameters: Name Type Description Default electrode_idx required Source code in src/model/DC1DataContainer.py def find_all_buffers_with_electrode_idx ( self , electrode_idx ): \"\"\" Args: electrode_idx: Returns: \"\"\" buffers = [] len_processed_buffer = len ( self . buffer_indexed ) for i in range ( len_processed_buffer ): if electrode_idx in self . buffer_indexed [ i ][ \"channel_idxs\" ]: buffers . append ( i ) return buffers","title":"find_all_buffers_with_electrode_idx()"},{"location":"model/DC1DataContainer/#src.model.DC1DataContainer.DC1DataContainer.find_last_buffer_with_electrode_idx","text":"Parameters: Name Type Description Default electrode_idx required Source code in src/model/DC1DataContainer.py def find_last_buffer_with_electrode_idx ( self , electrode_idx ): \"\"\" Args: electrode_idx: Returns: \"\"\" # return buffer which contains an electrode idx # start from the end len_processed_buffer = len ( self . buffer_indexed ) for i in reversed ( range ( len_processed_buffer )): if electrode_idx in self . buffer_indexed [ i ][ \"channel_idxs\" ]: return i return - 1","title":"find_last_buffer_with_electrode_idx()"},{"location":"model/DC1DataContainer/#src.model.DC1DataContainer.DC1DataContainer.get_last_trace_with_electrode_idx","text":"Parameters: Name Type Description Default electrode_idx required Source code in src/model/DC1DataContainer.py def get_last_trace_with_electrode_idx ( self , electrode_idx ): \"\"\" Args: electrode_idx: Returns: \"\"\" buffer_idx = self . find_last_buffer_with_electrode_idx ( electrode_idx ) if buffer_idx == - 1 : return None , None else : params = { \"file_dir\" : self . buffer_indexed [ buffer_idx ][ \"file_dir\" ], \"filter_type\" : self . buffer_indexed [ buffer_idx ][ \"filter_type\" ], \"SPIKING_THRESHOLD\" : self . app . settings [ \"spikeThreshold\" ], \"BIN_SIZE\" : self . app . settings [ \"binSize\" ] } N , Y = None , None packet = load_one_mat_file ( params ) for channel_data in packet [ \"packet_data\" ]: if channel_data [ \"channel_idx\" ] == electrode_idx : Y = channel_data [ \"filtered_data\" ] N = channel_data [ \"N\" ] time_elapsed = self . buffer_indexed [ buffer_idx ][ \"time_elapsed\" ] SAMPLING_PERIOD = 0.05 # check data_loading_mat.py for more details end_time = N * SAMPLING_PERIOD X = np . linspace ( time_elapsed , time_elapsed + end_time , N + 1 ) return X , Y","title":"get_last_trace_with_electrode_idx()"},{"location":"model/DC1DataContainer/#src.model.DC1DataContainer.map2idx","text":"Given a channel's row and col, return channel's index Parameters: Name Type Description Default ch_row int row index of channel in array (up to 32) required ch_col int column index of channel in array (up to 32) required Returns: numerical index of array Source code in src/model/DC1DataContainer.py def map2idx ( ch_row : int , ch_col : int ): \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx","title":"map2idx()"},{"location":"model/data_loading_mat/","text":"Data Loading (.MAT) Functions for loading model files into form that can be read by GUI idx2map ( ch_idx ) Given a channel index, return the channel's row and col Parameters: Name Type Description Default ch_idx int single numerical index for array (up to 1024) required Returns: Type Description channel row and channel index Source code in src/model/data_loading_mat.py def idx2map ( ch_idx : int ): \"\"\" Given a channel index, return the channel's row and col Args: ch_idx: single numerical index for array (up to 1024) Returns: channel row and channel index \"\"\" if ch_idx > 1023 or ch_idx < 0 : print ( 'Chan num out of range' ) return - 1 else : ch_row = int ( ch_idx / 32 ) ch_col = int ( ch_idx - ch_row * 32 ) return ch_row , ch_col init_data_loading ( path ) Parameters: Name Type Description Default path str required Source code in src/model/data_loading_mat.py def init_data_loading ( path : str ): \"\"\" Args: path: Returns: \"\"\" bufDir = os . listdir ( path ) num_of_buf = len ( bufDir ) bramdepth = 65536 datarun = os . path . basename ( path ) datapiece = os . path . basename ( os . path . dirname ( path )) # initialize variables dataAll = np . zeros (( 32 , 32 , int ( bramdepth * num_of_buf / 2 ))) # Largest possible value of dataAll, perfect recording, only double cnt cntAll = np . zeros (( 32 , 32 , int ( bramdepth * num_of_buf / 2 ))) times = np . zeros (( int ( bramdepth * num_of_buf / 2 ))) loadingDict = { \"path\" : path , \"datarun\" : datarun , \"datapiece\" : datapiece , \"bufDir\" : bufDir , \"num_of_buf\" : num_of_buf , \"bramDepth\" : bramdepth , \"dataAll\" : dataAll , \"cntAll\" : cntAll , \"times\" : times } return loadingDict load_first_buffer_info ( app ) Parameters: Name Type Description Default app MainWindow required Source code in src/model/data_loading_mat.py def load_first_buffer_info ( app ): \"\"\" Args: app: MainWindow Returns: \"\"\" data_run = os . path . basename ( app . settings [ \"path\" ]) file_dir = app . settings [ \"path\" ] + \"/\" + data_run + \"_\" + str ( 0 ) + \".mat\" first_file_params = { \"file_dir\" : file_dir , \"filter_type\" : app . settings [ \"filter\" ], \"packet_idx\" : 0 , \"SPIKING_THRESHOLD\" : app . settings [ \"spikeThreshold\" ], \"BIN_SIZE\" : app . settings [ \"binSize\" ] } packet = load_one_mat_file ( first_file_params ) app . data . to_serialize . put ( packet ) app . curr_buf_idx = 1 NUM_CHANNELS_PER_BUFFER = len ( packet [ \"packet_data\" ]) return NUM_CHANNELS_PER_BUFFER load_one_mat_file ( params ) Parameters: Name Type Description Default params required Source code in src/model/data_loading_mat.py def load_one_mat_file ( params ): \"\"\" Args: params: Returns: \"\"\" # this is designed to be multi-processed file_dir = params [ \"file_dir\" ] filter_type = params [ \"filter_type\" ] SPIKING_THRESHOLD = params [ \"SPIKING_THRESHOLD\" ] BIN_SIZE = params [ \"BIN_SIZE\" ] mat_contents = sio . loadmat ( file_dir ) dataRaw = mat_contents [ 'gmem1' ][ 0 ][:] from src.model.raw_data_helpers import removeMultipleCounts data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) # Note: this code does not timestamp model bc that cannot be parallelized properly packet_data = preprocess_raw_data ( data_real , cnt_real , N ) packet = { \"packet_data\" : packet_data , \"packet_idx\" : params [ \"packet_idx\" ], \"file_dir\" : params [ \"file_dir\" ], \"filter_type\" : params [ \"filter_type\" ] } from src.model.filters import filter_preprocessed_data packet = filter_preprocessed_data ( packet , filter_type = filter_type ) from src.model.statistics import calculate_channel_stats packet = calculate_channel_stats ( packet , SPIKING_THRESHOLD , BIN_SIZE ) return packet map2idx ( ch_row , ch_col ) Given a channel's row and col, return channel's index Parameters: Name Type Description Default ch_row int row index of channel in array (up to 32) required ch_col int column index of channel in array (up to 32) required Returns: numerical index of array Source code in src/model/data_loading_mat.py def map2idx ( ch_row : int , ch_col : int ): \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx preprocess_raw_data ( data_real , cnt_real , N , SAMPLING_PERIOD = 0.05 ) Parameters: Name Type Description Default data_real required cnt_real required N required SAMPLING_PERIOD 0.05 Source code in src/model/data_loading_mat.py def preprocess_raw_data ( data_real , cnt_real , N , SAMPLING_PERIOD = 0.05 ): \"\"\" Args: data_real: cnt_real: N: SAMPLING_PERIOD: Returns: \"\"\" # Determine time estimate and sample counts for the total combined buffers # (note this does not take into account communication delays - hence an estimate) end_time = N * SAMPLING_PERIOD # 20kHz sampling rate, means time_recording (ms) = num_sam * 0.05ms # we are not determining absolute time, because we want to parallelize this, # and time tracking must be done in sequence times = np . linspace ( 0 , end_time , N + 1 ) # identify relevant, nonzero channels, and then append only this model into recorded_data from src.model.raw_data_helpers import identify_relevant_channels num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels = identify_relevant_channels ( data_real ) packet_data = [] for i in range ( recorded_channels . shape [ 0 ]): # process each channel index channel_idx = int ( recorded_channels [ i ][ 0 ]) x , y = idx2map ( channel_idx ) start_idx = recorded_channels [ i ][ 0 ] channel_data = data_real [ x , y , start_idx : N ] # channel_times = self.times[self.count_track + start_idx: self.count_track+N] can't do # prune the times in the packet where nothing is recorded (aka when model == 0) # TODO turn on # actual_recording_times = (channel_data != 0] # channel_times = channel_times[actual_recording_times] # channel_data = channel_data[actual_recording_times] channel_data = { \"data_real\" : data_real , \"cnt_real\" : cnt_real , \"N\" : N , \"channel_idx\" : channel_idx , \"preprocessed_data\" : channel_data } packet_data . append ( channel_data ) return packet_data","title":"data loading (.mat files)"},{"location":"model/data_loading_mat/#data-loading-mat","text":"Functions for loading model files into form that can be read by GUI","title":"Data Loading (.MAT)"},{"location":"model/data_loading_mat/#src.model.data_loading_mat.idx2map","text":"Given a channel index, return the channel's row and col Parameters: Name Type Description Default ch_idx int single numerical index for array (up to 1024) required Returns: Type Description channel row and channel index Source code in src/model/data_loading_mat.py def idx2map ( ch_idx : int ): \"\"\" Given a channel index, return the channel's row and col Args: ch_idx: single numerical index for array (up to 1024) Returns: channel row and channel index \"\"\" if ch_idx > 1023 or ch_idx < 0 : print ( 'Chan num out of range' ) return - 1 else : ch_row = int ( ch_idx / 32 ) ch_col = int ( ch_idx - ch_row * 32 ) return ch_row , ch_col","title":"idx2map()"},{"location":"model/data_loading_mat/#src.model.data_loading_mat.init_data_loading","text":"Parameters: Name Type Description Default path str required Source code in src/model/data_loading_mat.py def init_data_loading ( path : str ): \"\"\" Args: path: Returns: \"\"\" bufDir = os . listdir ( path ) num_of_buf = len ( bufDir ) bramdepth = 65536 datarun = os . path . basename ( path ) datapiece = os . path . basename ( os . path . dirname ( path )) # initialize variables dataAll = np . zeros (( 32 , 32 , int ( bramdepth * num_of_buf / 2 ))) # Largest possible value of dataAll, perfect recording, only double cnt cntAll = np . zeros (( 32 , 32 , int ( bramdepth * num_of_buf / 2 ))) times = np . zeros (( int ( bramdepth * num_of_buf / 2 ))) loadingDict = { \"path\" : path , \"datarun\" : datarun , \"datapiece\" : datapiece , \"bufDir\" : bufDir , \"num_of_buf\" : num_of_buf , \"bramDepth\" : bramdepth , \"dataAll\" : dataAll , \"cntAll\" : cntAll , \"times\" : times } return loadingDict","title":"init_data_loading()"},{"location":"model/data_loading_mat/#src.model.data_loading_mat.load_first_buffer_info","text":"Parameters: Name Type Description Default app MainWindow required Source code in src/model/data_loading_mat.py def load_first_buffer_info ( app ): \"\"\" Args: app: MainWindow Returns: \"\"\" data_run = os . path . basename ( app . settings [ \"path\" ]) file_dir = app . settings [ \"path\" ] + \"/\" + data_run + \"_\" + str ( 0 ) + \".mat\" first_file_params = { \"file_dir\" : file_dir , \"filter_type\" : app . settings [ \"filter\" ], \"packet_idx\" : 0 , \"SPIKING_THRESHOLD\" : app . settings [ \"spikeThreshold\" ], \"BIN_SIZE\" : app . settings [ \"binSize\" ] } packet = load_one_mat_file ( first_file_params ) app . data . to_serialize . put ( packet ) app . curr_buf_idx = 1 NUM_CHANNELS_PER_BUFFER = len ( packet [ \"packet_data\" ]) return NUM_CHANNELS_PER_BUFFER","title":"load_first_buffer_info()"},{"location":"model/data_loading_mat/#src.model.data_loading_mat.load_one_mat_file","text":"Parameters: Name Type Description Default params required Source code in src/model/data_loading_mat.py def load_one_mat_file ( params ): \"\"\" Args: params: Returns: \"\"\" # this is designed to be multi-processed file_dir = params [ \"file_dir\" ] filter_type = params [ \"filter_type\" ] SPIKING_THRESHOLD = params [ \"SPIKING_THRESHOLD\" ] BIN_SIZE = params [ \"BIN_SIZE\" ] mat_contents = sio . loadmat ( file_dir ) dataRaw = mat_contents [ 'gmem1' ][ 0 ][:] from src.model.raw_data_helpers import removeMultipleCounts data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) # Note: this code does not timestamp model bc that cannot be parallelized properly packet_data = preprocess_raw_data ( data_real , cnt_real , N ) packet = { \"packet_data\" : packet_data , \"packet_idx\" : params [ \"packet_idx\" ], \"file_dir\" : params [ \"file_dir\" ], \"filter_type\" : params [ \"filter_type\" ] } from src.model.filters import filter_preprocessed_data packet = filter_preprocessed_data ( packet , filter_type = filter_type ) from src.model.statistics import calculate_channel_stats packet = calculate_channel_stats ( packet , SPIKING_THRESHOLD , BIN_SIZE ) return packet","title":"load_one_mat_file()"},{"location":"model/data_loading_mat/#src.model.data_loading_mat.map2idx","text":"Given a channel's row and col, return channel's index Parameters: Name Type Description Default ch_row int row index of channel in array (up to 32) required ch_col int column index of channel in array (up to 32) required Returns: numerical index of array Source code in src/model/data_loading_mat.py def map2idx ( ch_row : int , ch_col : int ): \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx","title":"map2idx()"},{"location":"model/data_loading_mat/#src.model.data_loading_mat.preprocess_raw_data","text":"Parameters: Name Type Description Default data_real required cnt_real required N required SAMPLING_PERIOD 0.05 Source code in src/model/data_loading_mat.py def preprocess_raw_data ( data_real , cnt_real , N , SAMPLING_PERIOD = 0.05 ): \"\"\" Args: data_real: cnt_real: N: SAMPLING_PERIOD: Returns: \"\"\" # Determine time estimate and sample counts for the total combined buffers # (note this does not take into account communication delays - hence an estimate) end_time = N * SAMPLING_PERIOD # 20kHz sampling rate, means time_recording (ms) = num_sam * 0.05ms # we are not determining absolute time, because we want to parallelize this, # and time tracking must be done in sequence times = np . linspace ( 0 , end_time , N + 1 ) # identify relevant, nonzero channels, and then append only this model into recorded_data from src.model.raw_data_helpers import identify_relevant_channels num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels = identify_relevant_channels ( data_real ) packet_data = [] for i in range ( recorded_channels . shape [ 0 ]): # process each channel index channel_idx = int ( recorded_channels [ i ][ 0 ]) x , y = idx2map ( channel_idx ) start_idx = recorded_channels [ i ][ 0 ] channel_data = data_real [ x , y , start_idx : N ] # channel_times = self.times[self.count_track + start_idx: self.count_track+N] can't do # prune the times in the packet where nothing is recorded (aka when model == 0) # TODO turn on # actual_recording_times = (channel_data != 0] # channel_times = channel_times[actual_recording_times] # channel_data = channel_data[actual_recording_times] channel_data = { \"data_real\" : data_real , \"cnt_real\" : cnt_real , \"N\" : N , \"channel_idx\" : channel_idx , \"preprocessed_data\" : channel_data } packet_data . append ( channel_data ) return packet_data","title":"preprocess_raw_data()"},{"location":"model/data_loading_npz/","text":"Data Loading (.NPZ)","title":"data loading (.npz files)"},{"location":"model/data_loading_npz/#data-loading-npz","text":"","title":"Data Loading (.NPZ)"},{"location":"model/filters/","text":"Filters applyFilterAuto ( channel_data , dataFilt ) Source code in src/model/filters.py def applyFilterAuto ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" samFreq = 20e3 * 1.0 passband = [ 250 , 4000 ] stopband = [ 5 , 6000 ] max_loss_passband = 3 min_loss_stopband = 30 order , normal_cutoff = signal . buttord ( passband , stopband , max_loss_passband , min_loss_stopband , fs = samFreq ) b , a = signal . butter ( order , normal_cutoff , btype = 'bandpass' , fs = samFreq ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt applyFilterAutoTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterAutoTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" samFreq = 20e3 * 1.0 passband = [ 250 , 4000 ] stopband = [ 5 , 6000 ] max_loss_passband = 3 min_loss_stopband = 30 order , normal_cutoff = signal . buttord ( passband , stopband , max_loss_passband , min_loss_stopband , fs = samFreq ) b , a = signal . butter ( order , normal_cutoff , btype = 'bandpass' , fs = samFreq ) print ( 'Order = ' + str ( order )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterFastBandpass ( channel_data , dataFilt ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterFastBandpass ( channel_data , dataFilt ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt applyFilterFastBandpassTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterFastBandpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , analog = False ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterFasterBandpass ( channel_data , dataFilt ) Source code in src/model/filters.py def applyFilterFasterBandpass ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq sos1 = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , output = 'sos' ) dataFilt = signal . sosfiltfilt ( sos1 , channel_data ) return dataFilt applyFilterFasterBandpassTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterFasterBandpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq sos1 = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , output = 'sos' ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . sosfiltfilt ( sos1 , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterH0bandpass ( channel_data , dataFilt ) Source code in src/model/filters.py def applyFilterH0bandpass ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 5 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt applyFilterH0bandpassTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterH0bandpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 5 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) print ( 'Order = ' + str ( 5 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterHierlemann ( channel_data , dataFilt ) Source code in src/model/filters.py def applyFilterHierlemann ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" BP_LOW_CUTOFF = 100.0 NUM_TAPS = 75 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 dataFilt = signal . filtfilt ( TAPS , [ a ], channel_data ) return dataFilt applyFilterHierlemannTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterHierlemannTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" BP_LOW_CUTOFF = 100.0 NUM_TAPS = 75 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( TAPS , [ a ], dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterHighpass ( channel_data , dataFilt ) Source code in src/model/filters.py def applyFilterHighpass ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff = 250 / nyq b , a = signal . butter ( 5 , [ cutoff ], btype = \"highpass\" , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt applyFilterHighpassTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterHighpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff = 250 / nyq b , a = signal . butter ( 5 , [ cutoff ], btype = \"highpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterLitke ( channel_data , dataFilt ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterLitke ( channel_data , dataFilt ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 2000 / nyq b , a = signal . butter ( 2 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt applyFilterLitkeTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterLitkeTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 2000 / nyq b , a = signal . butter ( 2 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterModHierlemann ( channel_data , dataFilt ) Parameters: Name Type Description Default channel_data required dataFilt required Source code in src/model/filters.py def applyFilterModHierlemann ( channel_data , dataFilt ): \"\"\" Args: channel_data: dataFilt: Returns: \"\"\" BP_LOW_CUTOFF = 250.0 BP_HIGH_CUTOFF = 4000.0 NUM_TAPS = 100 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , BP_HIGH_CUTOFF ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 dataFilt = signal . filtfilt ( TAPS , [ a ], channel_data ) return dataFilt applyFilterModHierlemannTimed ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterModHierlemannTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" BP_LOW_CUTOFF = 250.0 BP_HIGH_CUTOFF = 4000.0 NUM_TAPS = 100 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , BP_HIGH_CUTOFF ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( TAPS , [ a ], dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterToAllData ( dataAll , numChan , chMap , filtType = 'Modified Hierlemann' , debug = False ) Parameters: Name Type Description Default dataAll required numChan required chMap required filtType 'Modified Hierlemann' Source code in src/model/filters.py def applyFilterToAllData ( dataAll , numChan , chMap , filtType = 'Modified Hierlemann' , debug = False ): \"\"\" Args: dataAll: numChan: chMap: filtType: Returns: \"\"\" # Future update: only calculate for channels recorded not all dataFilt = np . zeros (( np . shape ( dataAll ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemannTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Modified Hierlemann' : dataFilt = applyFilterModHierlemannTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Highpass' : dataFilt = applyFilterHighpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'H0 Bandpass' : dataFilt = applyFilterH0bandpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Auto' : dataFilt = applyFilterAutoTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Fast Bandpass' : dataFilt = applyFilterFastBandpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Faster Bandpass' : dataFilt = applyFilterFasterBandpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Litke' : dataFilt = applyFilterLitkeTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'None' : dataFilt = np . copy ( dataAll ) else : dataFilt = np . copy ( dataAll ) print ( 'Filter not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) if debug : print ( \"Filter type: \" + str ( filtType )) return dataFilt applyFilterToChannelData ( channel_data , filtType = 'Hierlemann' , debug = False ) Parameters: Name Type Description Default channel_data required filtType 'Hierlemann' Source code in src/model/filters.py def applyFilterToChannelData ( channel_data , filtType = 'Hierlemann' , debug = False ): \"\"\" Args: channel_data: filtType: Returns: \"\"\" dataFilt = np . zeros (( np . shape ( channel_data ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemann ( channel_data , dataFilt ) elif filtType == 'Modified Hierlemann' : dataFilt = applyFilterModHierlemann ( channel_data , dataFilt ) elif filtType == 'Highpass' : dataFilt = applyFilterHighpass ( channel_data , dataFilt ) elif filtType == 'H0 Bandpass' : dataFilt = applyFilterH0bandpass ( channel_data , dataFilt ) elif filtType == 'Auto' : dataFilt = applyFilterAuto ( channel_data , dataFilt ) elif filtType == 'Fast Bandpass' : dataFilt = applyFilterFastBandpass ( channel_data , dataFilt ) elif filtType == 'Faster Bandpass' : dataFilt = applyFilterFasterBandpass ( channel_data , dataFilt ) elif filtType == 'Litke' : dataFilt = applyFilterLitke ( channel_data , dataFilt ) elif filtType == 'None' : dataFilt = np . copy ( channel_data ) else : dataFilt = np . copy ( channel_data ) print ( 'Filter type \"' + str ( filtType ) + '\" not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) if debug : print ( \"Filter type: \" + str ( filtType )) return dataFilt","title":"filters"},{"location":"model/filters/#filters","text":"","title":"Filters"},{"location":"model/filters/#src.model.filters.applyFilterAuto","text":"Source code in src/model/filters.py def applyFilterAuto ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" samFreq = 20e3 * 1.0 passband = [ 250 , 4000 ] stopband = [ 5 , 6000 ] max_loss_passband = 3 min_loss_stopband = 30 order , normal_cutoff = signal . buttord ( passband , stopband , max_loss_passband , min_loss_stopband , fs = samFreq ) b , a = signal . butter ( order , normal_cutoff , btype = 'bandpass' , fs = samFreq ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt","title":"applyFilterAuto()"},{"location":"model/filters/#src.model.filters.applyFilterAutoTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterAutoTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" samFreq = 20e3 * 1.0 passband = [ 250 , 4000 ] stopband = [ 5 , 6000 ] max_loss_passband = 3 min_loss_stopband = 30 order , normal_cutoff = signal . buttord ( passband , stopband , max_loss_passband , min_loss_stopband , fs = samFreq ) b , a = signal . butter ( order , normal_cutoff , btype = 'bandpass' , fs = samFreq ) print ( 'Order = ' + str ( order )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterAutoTimed()"},{"location":"model/filters/#src.model.filters.applyFilterFastBandpass","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterFastBandpass ( channel_data , dataFilt ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt","title":"applyFilterFastBandpass()"},{"location":"model/filters/#src.model.filters.applyFilterFastBandpassTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterFastBandpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , analog = False ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterFastBandpassTimed()"},{"location":"model/filters/#src.model.filters.applyFilterFasterBandpass","text":"Source code in src/model/filters.py def applyFilterFasterBandpass ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq sos1 = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , output = 'sos' ) dataFilt = signal . sosfiltfilt ( sos1 , channel_data ) return dataFilt","title":"applyFilterFasterBandpass()"},{"location":"model/filters/#src.model.filters.applyFilterFasterBandpassTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterFasterBandpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq sos1 = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , output = 'sos' ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . sosfiltfilt ( sos1 , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterFasterBandpassTimed()"},{"location":"model/filters/#src.model.filters.applyFilterH0bandpass","text":"Source code in src/model/filters.py def applyFilterH0bandpass ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 5 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt","title":"applyFilterH0bandpass()"},{"location":"model/filters/#src.model.filters.applyFilterH0bandpassTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterH0bandpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 5 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) print ( 'Order = ' + str ( 5 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterH0bandpassTimed()"},{"location":"model/filters/#src.model.filters.applyFilterHierlemann","text":"Source code in src/model/filters.py def applyFilterHierlemann ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" BP_LOW_CUTOFF = 100.0 NUM_TAPS = 75 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 dataFilt = signal . filtfilt ( TAPS , [ a ], channel_data ) return dataFilt","title":"applyFilterHierlemann()"},{"location":"model/filters/#src.model.filters.applyFilterHierlemannTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterHierlemannTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" BP_LOW_CUTOFF = 100.0 NUM_TAPS = 75 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( TAPS , [ a ], dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterHierlemannTimed()"},{"location":"model/filters/#src.model.filters.applyFilterHighpass","text":"Source code in src/model/filters.py def applyFilterHighpass ( channel_data , dataFilt ): \"\"\" Args: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff = 250 / nyq b , a = signal . butter ( 5 , [ cutoff ], btype = \"highpass\" , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt","title":"applyFilterHighpass()"},{"location":"model/filters/#src.model.filters.applyFilterHighpassTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterHighpassTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff = 250 / nyq b , a = signal . butter ( 5 , [ cutoff ], btype = \"highpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterHighpassTimed()"},{"location":"model/filters/#src.model.filters.applyFilterLitke","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterLitke ( channel_data , dataFilt ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 2000 / nyq b , a = signal . butter ( 2 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) dataFilt = signal . filtfilt ( b , a , channel_data ) return dataFilt","title":"applyFilterLitke()"},{"location":"model/filters/#src.model.filters.applyFilterLitkeTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterLitkeTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 2000 / nyq b , a = signal . butter ( 2 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterLitkeTimed()"},{"location":"model/filters/#src.model.filters.applyFilterModHierlemann","text":"Parameters: Name Type Description Default channel_data required dataFilt required Source code in src/model/filters.py def applyFilterModHierlemann ( channel_data , dataFilt ): \"\"\" Args: channel_data: dataFilt: Returns: \"\"\" BP_LOW_CUTOFF = 250.0 BP_HIGH_CUTOFF = 4000.0 NUM_TAPS = 100 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , BP_HIGH_CUTOFF ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 dataFilt = signal . filtfilt ( TAPS , [ a ], channel_data ) return dataFilt","title":"applyFilterModHierlemann()"},{"location":"model/filters/#src.model.filters.applyFilterModHierlemannTimed","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in src/model/filters.py def applyFilterModHierlemannTimed ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" BP_LOW_CUTOFF = 250.0 BP_HIGH_CUTOFF = 4000.0 NUM_TAPS = 100 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , BP_HIGH_CUTOFF ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( TAPS , [ a ], dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterModHierlemannTimed()"},{"location":"model/filters/#src.model.filters.applyFilterToAllData","text":"Parameters: Name Type Description Default dataAll required numChan required chMap required filtType 'Modified Hierlemann' Source code in src/model/filters.py def applyFilterToAllData ( dataAll , numChan , chMap , filtType = 'Modified Hierlemann' , debug = False ): \"\"\" Args: dataAll: numChan: chMap: filtType: Returns: \"\"\" # Future update: only calculate for channels recorded not all dataFilt = np . zeros (( np . shape ( dataAll ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemannTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Modified Hierlemann' : dataFilt = applyFilterModHierlemannTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Highpass' : dataFilt = applyFilterHighpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'H0 Bandpass' : dataFilt = applyFilterH0bandpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Auto' : dataFilt = applyFilterAutoTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Fast Bandpass' : dataFilt = applyFilterFastBandpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Faster Bandpass' : dataFilt = applyFilterFasterBandpassTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Litke' : dataFilt = applyFilterLitkeTimed ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'None' : dataFilt = np . copy ( dataAll ) else : dataFilt = np . copy ( dataAll ) print ( 'Filter not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) if debug : print ( \"Filter type: \" + str ( filtType )) return dataFilt","title":"applyFilterToAllData()"},{"location":"model/filters/#src.model.filters.applyFilterToChannelData","text":"Parameters: Name Type Description Default channel_data required filtType 'Hierlemann' Source code in src/model/filters.py def applyFilterToChannelData ( channel_data , filtType = 'Hierlemann' , debug = False ): \"\"\" Args: channel_data: filtType: Returns: \"\"\" dataFilt = np . zeros (( np . shape ( channel_data ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemann ( channel_data , dataFilt ) elif filtType == 'Modified Hierlemann' : dataFilt = applyFilterModHierlemann ( channel_data , dataFilt ) elif filtType == 'Highpass' : dataFilt = applyFilterHighpass ( channel_data , dataFilt ) elif filtType == 'H0 Bandpass' : dataFilt = applyFilterH0bandpass ( channel_data , dataFilt ) elif filtType == 'Auto' : dataFilt = applyFilterAuto ( channel_data , dataFilt ) elif filtType == 'Fast Bandpass' : dataFilt = applyFilterFastBandpass ( channel_data , dataFilt ) elif filtType == 'Faster Bandpass' : dataFilt = applyFilterFasterBandpass ( channel_data , dataFilt ) elif filtType == 'Litke' : dataFilt = applyFilterLitke ( channel_data , dataFilt ) elif filtType == 'None' : dataFilt = np . copy ( channel_data ) else : dataFilt = np . copy ( channel_data ) print ( 'Filter type \"' + str ( filtType ) + '\" not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) if debug : print ( \"Filter type: \" + str ( filtType )) return dataFilt","title":"applyFilterToChannelData()"},{"location":"model/raw_data_helpers/","text":"Raw Data Helpers identify_relevant_channels ( raw_data ) Only n number of channels can be recorded at a given time due to bandwidth concerns--the rest are shut off. For given model recorded at during a certain window, find which channels were recorded. Parameters: Name Type Description Default raw_data_all unprocessed model in a given time window (num_channels_X x num_channels_Y x time_len) required Returns: Type Description num_channels number of channels that were found to have been recorded for given model channel_map: list of channels that were recorded, i.e. nonzero (x/y_coords, num_channels) channel_id: list of channels that were recorded, but identified by a single numerical ID start_idx: @param raw_data: all the raw model loaded thus far from files Source code in src/model/raw_data_helpers.py def identify_relevant_channels ( raw_data : np . array ): \"\"\" Only n number of channels can be recorded at a given time due to bandwidth concerns--the rest are shut off. For given model recorded at during a certain window, find which channels were recorded. Args: raw_data_all: unprocessed model in a given time window (num_channels_X x num_channels_Y x time_len) Returns: num_channels: number of channels that were found to have been recorded for given model channel_map: list of channels that were recorded, i.e. nonzero (x/y_coords, num_channels) channel_id: list of channels that were recorded, but identified by a single numerical ID start_idx: @param raw_data: all the raw model loaded thus far from files \"\"\" # This bit takes the longest. ~ 30 sec for whole array 4 channel recording num_samples = np . count_nonzero ( raw_data , axis = 2 ) num_channels = np . count_nonzero ( num_samples ) # Map and Identify recorded channels find_coords = np . nonzero ( num_samples ) channel_map = np . array ( find_coords ) channel_id = np . zeros ( num_channels ) start_idx = np . zeros ( num_channels ) from src.model.data_loading_mat import map2idx for k in range ( 0 , num_channels ): channel_id [ k ] = map2idx ( channel_map [ 0 , k ], channel_map [ 1 , k ]) start_idx [ k ] = ( raw_data [ channel_map [ 0 , k ], channel_map [ 1 , k ], :] != 0 ) . argmax ( axis = 0 ) recorded_channels = np . stack (( channel_id , start_idx ), axis = 1 ) . astype ( int ) #return recorded_channels return num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels removeMultipleCounts ( dataRaw ) Parameters: Name Type Description Default dataRaw required Source code in src/model/raw_data_helpers.py def removeMultipleCounts ( dataRaw ): \"\"\" Args: dataRaw: Returns: \"\"\" # Initialize Variables Needed for Each Buffer chan_index_pre = 1025 # Check for chan changes, double cnt cnt_pre = 0 # Check for cnt changes, double cnt N = 0 # Sample times (DOES NOT ALLOW NON-COLLISION FREE SAMPLES) data_real = np . zeros ( ( 32 , 32 , len ( dataRaw ) - 2 )) # Initialize to max possible length. Note: Throw out first two values b/c garbo cnt_real = np . zeros (( 32 , 32 , len ( dataRaw ) - 2 )) # Convert model and remove double/triple counts for i in range ( 2 , len ( dataRaw ) - 1 ): # Convert bit number into binary word = ( np . binary_repr ( dataRaw [ i ], 32 )) # Break that binary into it's respective pieces and convert to bit number cnt = int ( word [ 12 : 14 ], 2 ) col = int ( word [ 27 : 32 ], 2 ) row = int ( word [ 22 : 27 ], 2 ) chan_index = row * 32 + col # Only record the unique non-double count sample if ( i == 2 or ( cnt_pre != cnt or chan_index != chan_index_pre )): # Sample time only changes when cnt changes if cnt != cnt_pre : N += 1 # On the occurance the first cnt is not 0, make sure sample time is 0 if i == 2 : N = 0 # Update variables cnt_pre = cnt chan_index_pre = chan_index # Record pertinent model data_real [ row ][ col ][ N ] = int ( word [ 14 : 22 ], 2 ) cnt_real [ row ][ col ][ N ] = cnt return data_real , cnt_real , N","title":"raw data helpers"},{"location":"model/raw_data_helpers/#raw-data-helpers","text":"","title":"Raw Data Helpers"},{"location":"model/raw_data_helpers/#src.model.raw_data_helpers.identify_relevant_channels","text":"Only n number of channels can be recorded at a given time due to bandwidth concerns--the rest are shut off. For given model recorded at during a certain window, find which channels were recorded. Parameters: Name Type Description Default raw_data_all unprocessed model in a given time window (num_channels_X x num_channels_Y x time_len) required Returns: Type Description num_channels number of channels that were found to have been recorded for given model channel_map: list of channels that were recorded, i.e. nonzero (x/y_coords, num_channels) channel_id: list of channels that were recorded, but identified by a single numerical ID start_idx: @param raw_data: all the raw model loaded thus far from files Source code in src/model/raw_data_helpers.py def identify_relevant_channels ( raw_data : np . array ): \"\"\" Only n number of channels can be recorded at a given time due to bandwidth concerns--the rest are shut off. For given model recorded at during a certain window, find which channels were recorded. Args: raw_data_all: unprocessed model in a given time window (num_channels_X x num_channels_Y x time_len) Returns: num_channels: number of channels that were found to have been recorded for given model channel_map: list of channels that were recorded, i.e. nonzero (x/y_coords, num_channels) channel_id: list of channels that were recorded, but identified by a single numerical ID start_idx: @param raw_data: all the raw model loaded thus far from files \"\"\" # This bit takes the longest. ~ 30 sec for whole array 4 channel recording num_samples = np . count_nonzero ( raw_data , axis = 2 ) num_channels = np . count_nonzero ( num_samples ) # Map and Identify recorded channels find_coords = np . nonzero ( num_samples ) channel_map = np . array ( find_coords ) channel_id = np . zeros ( num_channels ) start_idx = np . zeros ( num_channels ) from src.model.data_loading_mat import map2idx for k in range ( 0 , num_channels ): channel_id [ k ] = map2idx ( channel_map [ 0 , k ], channel_map [ 1 , k ]) start_idx [ k ] = ( raw_data [ channel_map [ 0 , k ], channel_map [ 1 , k ], :] != 0 ) . argmax ( axis = 0 ) recorded_channels = np . stack (( channel_id , start_idx ), axis = 1 ) . astype ( int ) #return recorded_channels return num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels","title":"identify_relevant_channels()"},{"location":"model/raw_data_helpers/#src.model.raw_data_helpers.removeMultipleCounts","text":"Parameters: Name Type Description Default dataRaw required Source code in src/model/raw_data_helpers.py def removeMultipleCounts ( dataRaw ): \"\"\" Args: dataRaw: Returns: \"\"\" # Initialize Variables Needed for Each Buffer chan_index_pre = 1025 # Check for chan changes, double cnt cnt_pre = 0 # Check for cnt changes, double cnt N = 0 # Sample times (DOES NOT ALLOW NON-COLLISION FREE SAMPLES) data_real = np . zeros ( ( 32 , 32 , len ( dataRaw ) - 2 )) # Initialize to max possible length. Note: Throw out first two values b/c garbo cnt_real = np . zeros (( 32 , 32 , len ( dataRaw ) - 2 )) # Convert model and remove double/triple counts for i in range ( 2 , len ( dataRaw ) - 1 ): # Convert bit number into binary word = ( np . binary_repr ( dataRaw [ i ], 32 )) # Break that binary into it's respective pieces and convert to bit number cnt = int ( word [ 12 : 14 ], 2 ) col = int ( word [ 27 : 32 ], 2 ) row = int ( word [ 22 : 27 ], 2 ) chan_index = row * 32 + col # Only record the unique non-double count sample if ( i == 2 or ( cnt_pre != cnt or chan_index != chan_index_pre )): # Sample time only changes when cnt changes if cnt != cnt_pre : N += 1 # On the occurance the first cnt is not 0, make sure sample time is 0 if i == 2 : N = 0 # Update variables cnt_pre = cnt chan_index_pre = chan_index # Record pertinent model data_real [ row ][ col ][ N ] = int ( word [ 14 : 22 ], 2 ) cnt_real [ row ][ col ][ N ] = cnt return data_real , cnt_real , N","title":"removeMultipleCounts()"},{"location":"model/spike_detection/","text":"Spike Detection Contains functions for detecting spikes Includes Gaussian Mixture Model (GMM) and Thresholding Huy Nguyen, John Bailey, Maddy Hays (2022) binSpikeTimes ( buf_recording_len , incom_spike_idx , incom_spike_amps , BIN_SIZE ) Parameters: Name Type Description Default buf_recording_len required incom_spike_idx required incom_spike_amps required BIN_SIZE required Source code in src/model/spike_detection.py def binSpikeTimes ( buf_recording_len , incom_spike_idx , incom_spike_amps , BIN_SIZE ): \"\"\" Args: buf_recording_len: incom_spike_idx: incom_spike_amps: BIN_SIZE: Returns: \"\"\" NUM_BINS_IN_BUFFER = math . floor ( buf_recording_len / BIN_SIZE ) # initialize an array of spike bins, with no spikes detected spikeBins = np . zeros ( NUM_BINS_IN_BUFFER , dtype = bool ) spikeBinsMaxAmp = np . zeros ( NUM_BINS_IN_BUFFER , dtype = float ) for bin_idx in range ( int ( buf_recording_len / BIN_SIZE )): bin_start = bin_idx * BIN_SIZE bin_end = ( bin_idx + 1 ) * BIN_SIZE spikes_within_bin = ( bin_start <= incom_spike_idx ) & ( incom_spike_idx < bin_end ) if np . count_nonzero ( spikes_within_bin ) != 0 : spikeBins [ bin_idx ] = True spiking_amps = incom_spike_amps [ spikes_within_bin ] spikeBinsMaxAmp [ bin_idx ] = np . max ( spiking_amps ) return spikeBins , spikeBinsMaxAmp , NUM_BINS_IN_BUFFER findSpikesGMM ( electrode_data , channel_idx , debug = False ) @param electrode_data: Data to apply GMM to (i.e. self.electrode_data in individual channels file) @param chan_idx: Index of electrode channel @param debug: Prints model if True @return: spikeMeanGMM, spikeStdGMM, noiseMeanGMM, noiseStdGMM Source code in src/model/spike_detection.py def findSpikesGMM ( electrode_data , channel_idx , debug = False ): \"\"\" @param electrode_data: Data to apply GMM to (i.e. self.electrode_data in individual channels file) @param chan_idx: Index of electrode channel @param debug: Prints model if True @return: spikeMeanGMM, spikeStdGMM, noiseMeanGMM, noiseStdGMM \"\"\" spikeMeanGMM = 0 noiseMeanGMM = 0 spikeStdGMM = 0 noiseStdGMM = 0 # Get model and perform GM y = electrode_data gmSam = np . reshape ( y ,( len ( y ), 1 )) gm = GaussianMixture ( n_components = 2 ) . fit ( gmSam ) # Get means, weights, st devs means = gm . means_ . flatten () weights = gm . weights_ . flatten () stanDevs = np . sqrt ( gm . covariances_ ) . flatten () # Assign means and standard deviations by finding which index # represents spikes and which noise (noise should have 0 mean) noiseIdx = 0 spikesIdx = 0 for i in range ( len ( means )): if means [ i ] == np . min ( np . abs ( means )): noiseMeanGMM = means [ i ] noiseIdx = i else : spikeMeanGMM = means [ i ] spikesIdx = i spikeStdGMM = stanDevs [ spikesIdx ] noiseStdGMM = stanDevs [ noiseIdx ] if debug : print ( \"Channel for GMM: \" + str ( channel_idx )) print ( \"spike mean: \" + str ( spikeMeanGMM ) + \"| spike std: \" + str ( spikeStdGMM ) + \"| noise mean: \" + str ( noiseMeanGMM ) + \"| noise std: \" + str ( noiseStdGMM )) return spikeMeanGMM , spikeStdGMM , noiseMeanGMM , noiseStdGMM getAboveThresholdActivity ( data , channel_noise_mean , channel_noise_std , spiking_threshold ) Parameters: Name Type Description Default data required channel_noise_mean required channel_noise_std required spiking_threshold required Source code in src/model/spike_detection.py def getAboveThresholdActivity ( data , channel_noise_mean , channel_noise_std , spiking_threshold ): \"\"\" Args: data: channel_noise_mean: channel_noise_std: spiking_threshold: Returns: \"\"\" below_threshold = channel_noise_mean - ( spiking_threshold * channel_noise_std ) above_threshold_activity = ( data <= below_threshold ) incom_spike_idx = np . argwhere ( above_threshold_activity ) . flatten () incom_spike_amplitude = data [ incom_spike_idx ] return incom_spike_idx , incom_spike_amplitude","title":"spike detection"},{"location":"model/spike_detection/#spike-detection","text":"Contains functions for detecting spikes Includes Gaussian Mixture Model (GMM) and Thresholding Huy Nguyen, John Bailey, Maddy Hays (2022)","title":"Spike Detection"},{"location":"model/spike_detection/#src.model.spike_detection.binSpikeTimes","text":"Parameters: Name Type Description Default buf_recording_len required incom_spike_idx required incom_spike_amps required BIN_SIZE required Source code in src/model/spike_detection.py def binSpikeTimes ( buf_recording_len , incom_spike_idx , incom_spike_amps , BIN_SIZE ): \"\"\" Args: buf_recording_len: incom_spike_idx: incom_spike_amps: BIN_SIZE: Returns: \"\"\" NUM_BINS_IN_BUFFER = math . floor ( buf_recording_len / BIN_SIZE ) # initialize an array of spike bins, with no spikes detected spikeBins = np . zeros ( NUM_BINS_IN_BUFFER , dtype = bool ) spikeBinsMaxAmp = np . zeros ( NUM_BINS_IN_BUFFER , dtype = float ) for bin_idx in range ( int ( buf_recording_len / BIN_SIZE )): bin_start = bin_idx * BIN_SIZE bin_end = ( bin_idx + 1 ) * BIN_SIZE spikes_within_bin = ( bin_start <= incom_spike_idx ) & ( incom_spike_idx < bin_end ) if np . count_nonzero ( spikes_within_bin ) != 0 : spikeBins [ bin_idx ] = True spiking_amps = incom_spike_amps [ spikes_within_bin ] spikeBinsMaxAmp [ bin_idx ] = np . max ( spiking_amps ) return spikeBins , spikeBinsMaxAmp , NUM_BINS_IN_BUFFER","title":"binSpikeTimes()"},{"location":"model/spike_detection/#src.model.spike_detection.findSpikesGMM","text":"@param electrode_data: Data to apply GMM to (i.e. self.electrode_data in individual channels file) @param chan_idx: Index of electrode channel @param debug: Prints model if True @return: spikeMeanGMM, spikeStdGMM, noiseMeanGMM, noiseStdGMM Source code in src/model/spike_detection.py def findSpikesGMM ( electrode_data , channel_idx , debug = False ): \"\"\" @param electrode_data: Data to apply GMM to (i.e. self.electrode_data in individual channels file) @param chan_idx: Index of electrode channel @param debug: Prints model if True @return: spikeMeanGMM, spikeStdGMM, noiseMeanGMM, noiseStdGMM \"\"\" spikeMeanGMM = 0 noiseMeanGMM = 0 spikeStdGMM = 0 noiseStdGMM = 0 # Get model and perform GM y = electrode_data gmSam = np . reshape ( y ,( len ( y ), 1 )) gm = GaussianMixture ( n_components = 2 ) . fit ( gmSam ) # Get means, weights, st devs means = gm . means_ . flatten () weights = gm . weights_ . flatten () stanDevs = np . sqrt ( gm . covariances_ ) . flatten () # Assign means and standard deviations by finding which index # represents spikes and which noise (noise should have 0 mean) noiseIdx = 0 spikesIdx = 0 for i in range ( len ( means )): if means [ i ] == np . min ( np . abs ( means )): noiseMeanGMM = means [ i ] noiseIdx = i else : spikeMeanGMM = means [ i ] spikesIdx = i spikeStdGMM = stanDevs [ spikesIdx ] noiseStdGMM = stanDevs [ noiseIdx ] if debug : print ( \"Channel for GMM: \" + str ( channel_idx )) print ( \"spike mean: \" + str ( spikeMeanGMM ) + \"| spike std: \" + str ( spikeStdGMM ) + \"| noise mean: \" + str ( noiseMeanGMM ) + \"| noise std: \" + str ( noiseStdGMM )) return spikeMeanGMM , spikeStdGMM , noiseMeanGMM , noiseStdGMM","title":"findSpikesGMM()"},{"location":"model/spike_detection/#src.model.spike_detection.getAboveThresholdActivity","text":"Parameters: Name Type Description Default data required channel_noise_mean required channel_noise_std required spiking_threshold required Source code in src/model/spike_detection.py def getAboveThresholdActivity ( data , channel_noise_mean , channel_noise_std , spiking_threshold ): \"\"\" Args: data: channel_noise_mean: channel_noise_std: spiking_threshold: Returns: \"\"\" below_threshold = channel_noise_mean - ( spiking_threshold * channel_noise_std ) above_threshold_activity = ( data <= below_threshold ) incom_spike_idx = np . argwhere ( above_threshold_activity ) . flatten () incom_spike_amplitude = data [ incom_spike_idx ] return incom_spike_idx , incom_spike_amplitude","title":"getAboveThresholdActivity()"},{"location":"model/statistics/","text":"Statistics calculate_channel_stats ( packet , SPIKING_THRESHOLD , BIN_SIZE ) Parameters: Name Type Description Default packet required SPIKING_THRESHOLD required BIN_SIZE required Source code in src/model/statistics.py def calculate_channel_stats ( packet , SPIKING_THRESHOLD , BIN_SIZE ): \"\"\" Args: packet: SPIKING_THRESHOLD: BIN_SIZE: Returns: \"\"\" for idx , channel_data in enumerate ( packet [ \"packet_data\" ]): channel_data [ \"stats_avg+unfiltered+amp\" ] = np . mean ( channel_data [ \"preprocessed_data\" ]) channel_data [ \"stats_cnt\" ] = len ( channel_data [ \"filtered_data\" ]) channel_data [ \"stats_noise+mean\" ] = np . mean ( channel_data [ \"filtered_data\" ]) channel_data [ \"stats_noise+std\" ] = np . std ( channel_data [ \"filtered_data\" ]) channel_data [ \"stats_buf+recording+len\" ] = channel_data [ \"stats_cnt\" ] * 0.05 # assuming 20 khZ sampling rate # TODO [later] add GMM spikes SPIKE_DETECTION_METHOD = \"threshold\" if SPIKE_DETECTION_METHOD == \"threshold\" : from src.model.spike_detection import getAboveThresholdActivity , binSpikeTimes incom_spike_idx , incom_spike_amplitude = getAboveThresholdActivity ( channel_data [ \"filtered_data\" ], channel_data [ \"stats_noise+mean\" ], channel_data [ \"stats_noise+std\" ], SPIKING_THRESHOLD ) spikeBins , spikeBinsMaxAmp , NUM_BINS_IN_BUFFER = binSpikeTimes ( channel_data [ \"stats_buf+recording+len\" ], incom_spike_idx , incom_spike_amplitude , BIN_SIZE ) channel_data [ \"stats_spikes+cnt\" ] = sum ( spikeBins ) channel_data [ \"stats_spikes+avg+amp\" ] = np . mean ( spikeBinsMaxAmp ) channel_data [ \"stats_spikes+std\" ] = np . std ( spikeBinsMaxAmp ) channel_data [ \"spike_bins\" ] = spikeBins channel_data [ \"spike_bins_max_amps\" ] = spikeBinsMaxAmp channel_data [ \"stats_num+spike+bins+in+buffer\" ] = NUM_BINS_IN_BUFFER return packet","title":"statistics"},{"location":"model/statistics/#statistics","text":"","title":"Statistics"},{"location":"model/statistics/#src.model.statistics.calculate_channel_stats","text":"Parameters: Name Type Description Default packet required SPIKING_THRESHOLD required BIN_SIZE required Source code in src/model/statistics.py def calculate_channel_stats ( packet , SPIKING_THRESHOLD , BIN_SIZE ): \"\"\" Args: packet: SPIKING_THRESHOLD: BIN_SIZE: Returns: \"\"\" for idx , channel_data in enumerate ( packet [ \"packet_data\" ]): channel_data [ \"stats_avg+unfiltered+amp\" ] = np . mean ( channel_data [ \"preprocessed_data\" ]) channel_data [ \"stats_cnt\" ] = len ( channel_data [ \"filtered_data\" ]) channel_data [ \"stats_noise+mean\" ] = np . mean ( channel_data [ \"filtered_data\" ]) channel_data [ \"stats_noise+std\" ] = np . std ( channel_data [ \"filtered_data\" ]) channel_data [ \"stats_buf+recording+len\" ] = channel_data [ \"stats_cnt\" ] * 0.05 # assuming 20 khZ sampling rate # TODO [later] add GMM spikes SPIKE_DETECTION_METHOD = \"threshold\" if SPIKE_DETECTION_METHOD == \"threshold\" : from src.model.spike_detection import getAboveThresholdActivity , binSpikeTimes incom_spike_idx , incom_spike_amplitude = getAboveThresholdActivity ( channel_data [ \"filtered_data\" ], channel_data [ \"stats_noise+mean\" ], channel_data [ \"stats_noise+std\" ], SPIKING_THRESHOLD ) spikeBins , spikeBinsMaxAmp , NUM_BINS_IN_BUFFER = binSpikeTimes ( channel_data [ \"stats_buf+recording+len\" ], incom_spike_idx , incom_spike_amplitude , BIN_SIZE ) channel_data [ \"stats_spikes+cnt\" ] = sum ( spikeBins ) channel_data [ \"stats_spikes+avg+amp\" ] = np . mean ( spikeBinsMaxAmp ) channel_data [ \"stats_spikes+std\" ] = np . std ( spikeBinsMaxAmp ) channel_data [ \"spike_bins\" ] = spikeBins channel_data [ \"spike_bins_max_amps\" ] = spikeBinsMaxAmp channel_data [ \"stats_num+spike+bins+in+buffer\" ] = NUM_BINS_IN_BUFFER return packet","title":"calculate_channel_stats()"},{"location":"tests/test_startup/","text":"","title":"Test startup"},{"location":"view/gui_themes/","text":"","title":"themes"},{"location":"view/layouts/","text":"","title":"layouts"}]}