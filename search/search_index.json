{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DC 1 Visualization This is the main project page for DC1 visualization GUIs. Authors: Huy Nguyen, John Bailey, Maddy Hays To setup development environment, check out Getting Started","title":"Introduction"},{"location":"#dc-1-visualization","text":"This is the main project page for DC1 visualization GUIs. Authors: Huy Nguyen, John Bailey, Maddy Hays To setup development environment, check out Getting Started","title":"DC 1 Visualization"},{"location":"DC1DataContainer/","text":"DC1 Data Container DC1DataContainer Container for holding all different types of data. Source code in app/src/data/DC1DataContainer.py class DC1DataContainer (): \"\"\" Container for holding all different types of data. \"\"\" # raw_data --> recorded_data --> filtered_data # raw_data: data loader from .mat files raw_data , counts , times = None , None , None count_track , time_track = None , None container_length = None # recorded_data: nonzero data # each element in recorded_data is data for one channel recorded recorded_data = [] count_track_processed , time_track_processed = None , None # filtered_data: recorded_data gone through a filter # each element in filtered_data is filtered data for one channel filtered_data = [] # array_statistics: overall array stats array_stats = { \"size\" : np . zeros (( 32 , 32 , 0 )), # For each dot, size by # of samples \"num_sam\" : np . zeros (( 32 , 32 , 1 )), # Temp variable to allow sample counting \"colors\" : np . zeros (( 32 , 32 , 0 )), # For each dot, color by avg amplitude \"avg_val\" : np . zeros (( 32 , 32 , 1 )), # Temp variable for calculating average amplitude \"noise_mean\" : np . zeros (( 32 , 32 )), \"noise_std\" : np . zeros (( 32 , 32 )), \"noise_cnt\" : np . zeros (( 32 , 32 )), \"spike_avg\" : np . zeros (( 32 , 32 )), \"spike_std\" : np . zeros (( 32 , 32 )), \"spike_cnt\" : np . zeros (( 32 , 32 )), \"size\" : None , \"times\" : None , \"array spike rate times\" : [], # x \"array spike rate\" : [] # y } spikeThreshold = 3 # How many standard deviations above noise to find spikes # TODO combine with identity_relevant_channels def __init__ ( self ): self . time_track = 0 self . count_track = 0 self . count_track_processed = 0 self . time_track_processed = 0 self . raw_data = np . zeros (( 32 , 32 , 1000 )) self . counts = np . zeros (( 32 , 32 , 1000 )) self . times = np . zeros (( 1000 ,)) self . container_length = 1000 def setSpikeThreshold ( self , threshold ): self . spikeThreshold = threshold def extend_data_containers ( self , mode = 'double' ): \"\"\"Change data containers dynamically to accommodate longer time windows of data Args: mode: how to expand data containers Returns: Nothing \"\"\" if mode == 'double' : padding_data = np . zeros ( self . raw_data . shape ) padding_cnt = np . zeros ( self . counts . shape ) padding_times = np . zeros ( self . times . shape ) self . raw_data = np . concatenate (( self . raw_data , padding_data ), axis = 2 ) self . counts = np . concatenate (( self . counts , padding_cnt ), axis = 2 ) self . times = np . concatenate (( self . times , padding_times )) self . container_length *= 2 def append_raw_data ( self , data_real , cnt_real , N , sampling_period = 0.05 ): \"\"\" appends raw data in buffer to end of data container, append nonzero data to recorded_data Args: data_real: cnt_real: N: sampling_period: Returns: \"\"\" while self . raw_data . shape [ 2 ] < self . count_track + N : self . extend_data_containers () self . raw_data [:, :, self . count_track : self . count_track + N ] = data_real [:, :, : N ] self . counts [:, :, self . count_track : self . count_track + N ] = cnt_real [:, :, : N ] # Determine time estimate and sample counts for the total combined buffers # =============================== # (note this does not take into account communication delays - hence an estimate) end_time = N * sampling_period # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms # For the first buffer, we assume the first sample comes in at time 0 if self . time_track == 0 : new_times = np . linspace ( 0 , end_time , N + 1 ) self . times [ 0 : len ( new_times )] = new_times # For buffers after the first, we place these values directly after the previous buffer else : new_times = np . linspace ( self . time_track , self . time_track + end_time , N ) self . times [ self . count_track : self . count_track + N ] = new_times # identify relevant, nonzero channels, and then append only this data into recorded_data num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels = identify_relevant_channels ( data_real ) for i in range ( recorded_channels . shape [ 0 ]): channel_idx = int ( recorded_channels [ i ][ 0 ]) start_idx = recorded_channels [ i ][ 0 ] x , y = idx2map ( channel_idx ) channel_data = { 'channel_idx' : channel_idx , 'start_idx' : int ( self . count_track + start_idx ), # start_idx is based only on buffer, so need to add time from previous buffers 'data' : data_real [ x , y , start_idx : N ], # TODO make this accurate 'times' : self . times [ self . count_track + start_idx : self . count_track + N ] } self . recorded_data . append ( channel_data ) self . time_track += end_time self . count_track += N # TODO this shouldn't call update_filtered_data -> should be async, and threaded def update_filtered_data ( self , num_threads = 4 , filtType = 'modHierlemann' ): # subtract recorded_data by filtered_data len_recorded_data = len ( self . recorded_data ) len_filtered_data = len ( self . filtered_data ) # TODO parallelize filtering if len_filtered_data < len_recorded_data : while len_filtered_data < len_recorded_data : to_filter_idx = len_filtered_data to_filter_data = self . recorded_data [ to_filter_idx ][ 'data' ] filtered_data = applyFilterToChannelData ( to_filter_data , filtType = filtType ) filtered_data = { 'channel_idx' : self . recorded_data [ to_filter_idx ][ 'channel_idx' ], 'start_idx' : self . recorded_data [ to_filter_idx ][ 'start_idx' ], # start_idx is based only on buffer, so need to add time from previous buffers 'data' : filtered_data , # TODO make this accurate 'times' : self . recorded_data [ to_filter_idx ][ 'times' ] } self . filtered_data . append ( filtered_data ) len_filtered_data += 1 def update_array_stats ( self , data_real , N ): \"\"\" Args: data_real: N: Returns: \"\"\" # AX1,AX3,AX4) Sample Counting (Note: Appends are an artifact from previous real time codes) self . array_stats [ 'num_sam' ][:, :, 0 ] = np . count_nonzero ( data_real , axis = 2 ) incom_cnt = self . array_stats [ 'num_sam' ][:, :, 0 ] # AX1,AX3,AX4) Finding average ADC of samples per electrode mask = np . copy ( data_real ) mask [ mask == 0 ] = np . nan import warnings with warnings . catch_warnings (): warnings . simplefilter ( \"ignore\" , category = RuntimeWarning ) self . array_stats [ 'avg_val' ][:, :, 0 ] = np . nanmean ( mask , axis = 2 ) avg_val = np . nan_to_num ( self . array_stats [ 'avg_val' ], nan = 0 ) incom_mean = avg_val [:, :, 0 ] # AX3,AX4) Finding standard deviation ADC of samples per electrode incom_std = np . nanstd ( mask , axis = 2 ) incom_std = np . nan_to_num ( incom_std , nan = 0 ) # AX3,AX4) Building standard deviation of samples per electrode as buffers come in pre_mean = np . copy ( self . array_stats [ \"noise_mean\" ]) pre_std = np . copy ( self . array_stats [ \"noise_std\" ]) pre_cnt = np . copy ( self . array_stats [ \"noise_cnt\" ]) cnt_div = pre_cnt + incom_cnt cnt_div [ cnt_div == 0 ] = np . nan self . array_stats [ \"noise_mean\" ] = np . nan_to_num (( pre_cnt * pre_mean + incom_cnt * incom_mean ) / ( cnt_div ), nan = 0 ) self . array_stats [ \"noise_std\" ] = np . sqrt ( np . nan_to_num (( pre_cnt * ( pre_std ** 2 + ( pre_mean - self . array_stats [ \"noise_mean\" ]) ** 2 ) + incom_cnt * ( incom_std ** 2 + ( incom_mean - self . array_stats [ \"noise_mean\" ]) ** 2 )) / ( cnt_div ), nan = 0 )) self . array_stats [ \"noise_cnt\" ] = np . nan_to_num ( pre_cnt + incom_cnt , nan = 0 ) # NEW AX1) chan_cnt = np . count_nonzero ( self . array_stats [ 'num_sam' ]) chan_elec = np . zeros (( chan_cnt , 2 )) chan_ind = np . argsort ( self . array_stats [ 'num_sam' ] . flatten ())[ - chan_cnt :] chan_elec [:, 0 ] = ( chan_ind [:] / 32 ) . astype ( int ) chan_elec [:, 1 ] = chan_ind [:] - ( chan_elec [:, 0 ] * 32 ) chan_elec = chan_elec . astype ( int ) incom_spike_cnt = np . zeros (( 32 , 32 )) incom_spike_avg = np . zeros (( 32 , 32 )) incom_spike_std = np . zeros (( 32 , 32 )) mask2 = np . copy ( data_real ) print ( \"spike threhsold\" , self . spikeThreshold ) for x in range ( len ( chan_ind )): self . array_stats [ \"noise_std\" ] = self . array_stats [ \"noise_std\" ] incom_spike_cnt [ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] = np . count_nonzero ( mask [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] >= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + self . spikeThreshold * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]) mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] <= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + self . spikeThreshold * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]] = np . nan with warnings . catch_warnings (): warnings . simplefilter ( \"ignore\" , category = RuntimeWarning ) incom_spike_avg = np . nanmean ( mask2 , axis = 2 ) incom_spike_avg = np . nan_to_num ( incom_spike_avg , nan = 0 ) incom_spike_std = np . nanstd ( mask2 , axis = 2 ) incom_spike_std = np . nan_to_num ( incom_spike_std , nan = 0 ) pre_spike_avg = np . copy ( self . array_stats [ \"spike_avg\" ]) pre_spike_std = np . copy ( self . array_stats [ \"spike_std\" ]) pre_spike_cnt = np . copy ( self . array_stats [ \"spike_cnt\" ]) new_spike_cnt = pre_spike_cnt + incom_spike_cnt new_spike_cnt [ new_spike_cnt == 0 ] = np . nan self . array_stats [ \"spike_avg\" ] = np . nan_to_num (( pre_spike_cnt * pre_spike_avg + incom_spike_cnt * incom_spike_avg ) / ( new_spike_cnt ), nan = 0 ) self . array_stats [ \"spike_std\" ] = np . sqrt ( np . nan_to_num (( pre_spike_cnt * ( pre_spike_std ** 2 + ( pre_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 ) + incom_spike_cnt * ( incom_spike_std ** 2 + ( incom_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 )) / ( new_spike_cnt ), nan = 0 )) self . array_stats [ \"spike_cnt\" ] = np . nan_to_num ( new_spike_cnt , nan = 0 ) # AX2) Determine the Time of Each Sample total_time = N * 0.05 # Sampling rate 1/0.05 ms self . array_stats [ \"times\" ] = np . linspace ( 0 , total_time , N ) self . array_stats [ \"array spike rate times\" ] . append ( total_time / 1000 ) self . array_stats [ \"array spike rate\" ] . append ( np . sum ( incom_spike_avg )) append_raw_data ( self , data_real , cnt_real , N , sampling_period = 0.05 ) appends raw data in buffer to end of data container, append nonzero data to recorded_data Parameters: Name Type Description Default data_real required cnt_real required N required sampling_period 0.05 Source code in app/src/data/DC1DataContainer.py def append_raw_data ( self , data_real , cnt_real , N , sampling_period = 0.05 ): \"\"\" appends raw data in buffer to end of data container, append nonzero data to recorded_data Args: data_real: cnt_real: N: sampling_period: Returns: \"\"\" while self . raw_data . shape [ 2 ] < self . count_track + N : self . extend_data_containers () self . raw_data [:, :, self . count_track : self . count_track + N ] = data_real [:, :, : N ] self . counts [:, :, self . count_track : self . count_track + N ] = cnt_real [:, :, : N ] # Determine time estimate and sample counts for the total combined buffers # =============================== # (note this does not take into account communication delays - hence an estimate) end_time = N * sampling_period # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms # For the first buffer, we assume the first sample comes in at time 0 if self . time_track == 0 : new_times = np . linspace ( 0 , end_time , N + 1 ) self . times [ 0 : len ( new_times )] = new_times # For buffers after the first, we place these values directly after the previous buffer else : new_times = np . linspace ( self . time_track , self . time_track + end_time , N ) self . times [ self . count_track : self . count_track + N ] = new_times # identify relevant, nonzero channels, and then append only this data into recorded_data num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels = identify_relevant_channels ( data_real ) for i in range ( recorded_channels . shape [ 0 ]): channel_idx = int ( recorded_channels [ i ][ 0 ]) start_idx = recorded_channels [ i ][ 0 ] x , y = idx2map ( channel_idx ) channel_data = { 'channel_idx' : channel_idx , 'start_idx' : int ( self . count_track + start_idx ), # start_idx is based only on buffer, so need to add time from previous buffers 'data' : data_real [ x , y , start_idx : N ], # TODO make this accurate 'times' : self . times [ self . count_track + start_idx : self . count_track + N ] } self . recorded_data . append ( channel_data ) self . time_track += end_time self . count_track += N extend_data_containers ( self , mode = 'double' ) Change data containers dynamically to accommodate longer time windows of data Parameters: Name Type Description Default mode how to expand data containers 'double' Returns: Type Description Nothing Source code in app/src/data/DC1DataContainer.py def extend_data_containers ( self , mode = 'double' ): \"\"\"Change data containers dynamically to accommodate longer time windows of data Args: mode: how to expand data containers Returns: Nothing \"\"\" if mode == 'double' : padding_data = np . zeros ( self . raw_data . shape ) padding_cnt = np . zeros ( self . counts . shape ) padding_times = np . zeros ( self . times . shape ) self . raw_data = np . concatenate (( self . raw_data , padding_data ), axis = 2 ) self . counts = np . concatenate (( self . counts , padding_cnt ), axis = 2 ) self . times = np . concatenate (( self . times , padding_times )) self . container_length *= 2 update_array_stats ( self , data_real , N ) Parameters: Name Type Description Default data_real required N required Source code in app/src/data/DC1DataContainer.py def update_array_stats ( self , data_real , N ): \"\"\" Args: data_real: N: Returns: \"\"\" # AX1,AX3,AX4) Sample Counting (Note: Appends are an artifact from previous real time codes) self . array_stats [ 'num_sam' ][:, :, 0 ] = np . count_nonzero ( data_real , axis = 2 ) incom_cnt = self . array_stats [ 'num_sam' ][:, :, 0 ] # AX1,AX3,AX4) Finding average ADC of samples per electrode mask = np . copy ( data_real ) mask [ mask == 0 ] = np . nan import warnings with warnings . catch_warnings (): warnings . simplefilter ( \"ignore\" , category = RuntimeWarning ) self . array_stats [ 'avg_val' ][:, :, 0 ] = np . nanmean ( mask , axis = 2 ) avg_val = np . nan_to_num ( self . array_stats [ 'avg_val' ], nan = 0 ) incom_mean = avg_val [:, :, 0 ] # AX3,AX4) Finding standard deviation ADC of samples per electrode incom_std = np . nanstd ( mask , axis = 2 ) incom_std = np . nan_to_num ( incom_std , nan = 0 ) # AX3,AX4) Building standard deviation of samples per electrode as buffers come in pre_mean = np . copy ( self . array_stats [ \"noise_mean\" ]) pre_std = np . copy ( self . array_stats [ \"noise_std\" ]) pre_cnt = np . copy ( self . array_stats [ \"noise_cnt\" ]) cnt_div = pre_cnt + incom_cnt cnt_div [ cnt_div == 0 ] = np . nan self . array_stats [ \"noise_mean\" ] = np . nan_to_num (( pre_cnt * pre_mean + incom_cnt * incom_mean ) / ( cnt_div ), nan = 0 ) self . array_stats [ \"noise_std\" ] = np . sqrt ( np . nan_to_num (( pre_cnt * ( pre_std ** 2 + ( pre_mean - self . array_stats [ \"noise_mean\" ]) ** 2 ) + incom_cnt * ( incom_std ** 2 + ( incom_mean - self . array_stats [ \"noise_mean\" ]) ** 2 )) / ( cnt_div ), nan = 0 )) self . array_stats [ \"noise_cnt\" ] = np . nan_to_num ( pre_cnt + incom_cnt , nan = 0 ) # NEW AX1) chan_cnt = np . count_nonzero ( self . array_stats [ 'num_sam' ]) chan_elec = np . zeros (( chan_cnt , 2 )) chan_ind = np . argsort ( self . array_stats [ 'num_sam' ] . flatten ())[ - chan_cnt :] chan_elec [:, 0 ] = ( chan_ind [:] / 32 ) . astype ( int ) chan_elec [:, 1 ] = chan_ind [:] - ( chan_elec [:, 0 ] * 32 ) chan_elec = chan_elec . astype ( int ) incom_spike_cnt = np . zeros (( 32 , 32 )) incom_spike_avg = np . zeros (( 32 , 32 )) incom_spike_std = np . zeros (( 32 , 32 )) mask2 = np . copy ( data_real ) print ( \"spike threhsold\" , self . spikeThreshold ) for x in range ( len ( chan_ind )): self . array_stats [ \"noise_std\" ] = self . array_stats [ \"noise_std\" ] incom_spike_cnt [ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] = np . count_nonzero ( mask [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] >= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + self . spikeThreshold * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]) mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] <= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + self . spikeThreshold * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]] = np . nan with warnings . catch_warnings (): warnings . simplefilter ( \"ignore\" , category = RuntimeWarning ) incom_spike_avg = np . nanmean ( mask2 , axis = 2 ) incom_spike_avg = np . nan_to_num ( incom_spike_avg , nan = 0 ) incom_spike_std = np . nanstd ( mask2 , axis = 2 ) incom_spike_std = np . nan_to_num ( incom_spike_std , nan = 0 ) pre_spike_avg = np . copy ( self . array_stats [ \"spike_avg\" ]) pre_spike_std = np . copy ( self . array_stats [ \"spike_std\" ]) pre_spike_cnt = np . copy ( self . array_stats [ \"spike_cnt\" ]) new_spike_cnt = pre_spike_cnt + incom_spike_cnt new_spike_cnt [ new_spike_cnt == 0 ] = np . nan self . array_stats [ \"spike_avg\" ] = np . nan_to_num (( pre_spike_cnt * pre_spike_avg + incom_spike_cnt * incom_spike_avg ) / ( new_spike_cnt ), nan = 0 ) self . array_stats [ \"spike_std\" ] = np . sqrt ( np . nan_to_num (( pre_spike_cnt * ( pre_spike_std ** 2 + ( pre_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 ) + incom_spike_cnt * ( incom_spike_std ** 2 + ( incom_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 )) / ( new_spike_cnt ), nan = 0 )) self . array_stats [ \"spike_cnt\" ] = np . nan_to_num ( new_spike_cnt , nan = 0 ) # AX2) Determine the Time of Each Sample total_time = N * 0.05 # Sampling rate 1/0.05 ms self . array_stats [ \"times\" ] = np . linspace ( 0 , total_time , N ) self . array_stats [ \"array spike rate times\" ] . append ( total_time / 1000 ) self . array_stats [ \"array spike rate\" ] . append ( np . sum ( incom_spike_avg ))","title":"Data Container"},{"location":"DC1DataContainer/#dc1-data-container","text":"","title":"DC1 Data Container"},{"location":"DC1DataContainer/#dc1DataVis.app.src.data.DC1DataContainer.DC1DataContainer","text":"Container for holding all different types of data. Source code in app/src/data/DC1DataContainer.py class DC1DataContainer (): \"\"\" Container for holding all different types of data. \"\"\" # raw_data --> recorded_data --> filtered_data # raw_data: data loader from .mat files raw_data , counts , times = None , None , None count_track , time_track = None , None container_length = None # recorded_data: nonzero data # each element in recorded_data is data for one channel recorded recorded_data = [] count_track_processed , time_track_processed = None , None # filtered_data: recorded_data gone through a filter # each element in filtered_data is filtered data for one channel filtered_data = [] # array_statistics: overall array stats array_stats = { \"size\" : np . zeros (( 32 , 32 , 0 )), # For each dot, size by # of samples \"num_sam\" : np . zeros (( 32 , 32 , 1 )), # Temp variable to allow sample counting \"colors\" : np . zeros (( 32 , 32 , 0 )), # For each dot, color by avg amplitude \"avg_val\" : np . zeros (( 32 , 32 , 1 )), # Temp variable for calculating average amplitude \"noise_mean\" : np . zeros (( 32 , 32 )), \"noise_std\" : np . zeros (( 32 , 32 )), \"noise_cnt\" : np . zeros (( 32 , 32 )), \"spike_avg\" : np . zeros (( 32 , 32 )), \"spike_std\" : np . zeros (( 32 , 32 )), \"spike_cnt\" : np . zeros (( 32 , 32 )), \"size\" : None , \"times\" : None , \"array spike rate times\" : [], # x \"array spike rate\" : [] # y } spikeThreshold = 3 # How many standard deviations above noise to find spikes # TODO combine with identity_relevant_channels def __init__ ( self ): self . time_track = 0 self . count_track = 0 self . count_track_processed = 0 self . time_track_processed = 0 self . raw_data = np . zeros (( 32 , 32 , 1000 )) self . counts = np . zeros (( 32 , 32 , 1000 )) self . times = np . zeros (( 1000 ,)) self . container_length = 1000 def setSpikeThreshold ( self , threshold ): self . spikeThreshold = threshold def extend_data_containers ( self , mode = 'double' ): \"\"\"Change data containers dynamically to accommodate longer time windows of data Args: mode: how to expand data containers Returns: Nothing \"\"\" if mode == 'double' : padding_data = np . zeros ( self . raw_data . shape ) padding_cnt = np . zeros ( self . counts . shape ) padding_times = np . zeros ( self . times . shape ) self . raw_data = np . concatenate (( self . raw_data , padding_data ), axis = 2 ) self . counts = np . concatenate (( self . counts , padding_cnt ), axis = 2 ) self . times = np . concatenate (( self . times , padding_times )) self . container_length *= 2 def append_raw_data ( self , data_real , cnt_real , N , sampling_period = 0.05 ): \"\"\" appends raw data in buffer to end of data container, append nonzero data to recorded_data Args: data_real: cnt_real: N: sampling_period: Returns: \"\"\" while self . raw_data . shape [ 2 ] < self . count_track + N : self . extend_data_containers () self . raw_data [:, :, self . count_track : self . count_track + N ] = data_real [:, :, : N ] self . counts [:, :, self . count_track : self . count_track + N ] = cnt_real [:, :, : N ] # Determine time estimate and sample counts for the total combined buffers # =============================== # (note this does not take into account communication delays - hence an estimate) end_time = N * sampling_period # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms # For the first buffer, we assume the first sample comes in at time 0 if self . time_track == 0 : new_times = np . linspace ( 0 , end_time , N + 1 ) self . times [ 0 : len ( new_times )] = new_times # For buffers after the first, we place these values directly after the previous buffer else : new_times = np . linspace ( self . time_track , self . time_track + end_time , N ) self . times [ self . count_track : self . count_track + N ] = new_times # identify relevant, nonzero channels, and then append only this data into recorded_data num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels = identify_relevant_channels ( data_real ) for i in range ( recorded_channels . shape [ 0 ]): channel_idx = int ( recorded_channels [ i ][ 0 ]) start_idx = recorded_channels [ i ][ 0 ] x , y = idx2map ( channel_idx ) channel_data = { 'channel_idx' : channel_idx , 'start_idx' : int ( self . count_track + start_idx ), # start_idx is based only on buffer, so need to add time from previous buffers 'data' : data_real [ x , y , start_idx : N ], # TODO make this accurate 'times' : self . times [ self . count_track + start_idx : self . count_track + N ] } self . recorded_data . append ( channel_data ) self . time_track += end_time self . count_track += N # TODO this shouldn't call update_filtered_data -> should be async, and threaded def update_filtered_data ( self , num_threads = 4 , filtType = 'modHierlemann' ): # subtract recorded_data by filtered_data len_recorded_data = len ( self . recorded_data ) len_filtered_data = len ( self . filtered_data ) # TODO parallelize filtering if len_filtered_data < len_recorded_data : while len_filtered_data < len_recorded_data : to_filter_idx = len_filtered_data to_filter_data = self . recorded_data [ to_filter_idx ][ 'data' ] filtered_data = applyFilterToChannelData ( to_filter_data , filtType = filtType ) filtered_data = { 'channel_idx' : self . recorded_data [ to_filter_idx ][ 'channel_idx' ], 'start_idx' : self . recorded_data [ to_filter_idx ][ 'start_idx' ], # start_idx is based only on buffer, so need to add time from previous buffers 'data' : filtered_data , # TODO make this accurate 'times' : self . recorded_data [ to_filter_idx ][ 'times' ] } self . filtered_data . append ( filtered_data ) len_filtered_data += 1 def update_array_stats ( self , data_real , N ): \"\"\" Args: data_real: N: Returns: \"\"\" # AX1,AX3,AX4) Sample Counting (Note: Appends are an artifact from previous real time codes) self . array_stats [ 'num_sam' ][:, :, 0 ] = np . count_nonzero ( data_real , axis = 2 ) incom_cnt = self . array_stats [ 'num_sam' ][:, :, 0 ] # AX1,AX3,AX4) Finding average ADC of samples per electrode mask = np . copy ( data_real ) mask [ mask == 0 ] = np . nan import warnings with warnings . catch_warnings (): warnings . simplefilter ( \"ignore\" , category = RuntimeWarning ) self . array_stats [ 'avg_val' ][:, :, 0 ] = np . nanmean ( mask , axis = 2 ) avg_val = np . nan_to_num ( self . array_stats [ 'avg_val' ], nan = 0 ) incom_mean = avg_val [:, :, 0 ] # AX3,AX4) Finding standard deviation ADC of samples per electrode incom_std = np . nanstd ( mask , axis = 2 ) incom_std = np . nan_to_num ( incom_std , nan = 0 ) # AX3,AX4) Building standard deviation of samples per electrode as buffers come in pre_mean = np . copy ( self . array_stats [ \"noise_mean\" ]) pre_std = np . copy ( self . array_stats [ \"noise_std\" ]) pre_cnt = np . copy ( self . array_stats [ \"noise_cnt\" ]) cnt_div = pre_cnt + incom_cnt cnt_div [ cnt_div == 0 ] = np . nan self . array_stats [ \"noise_mean\" ] = np . nan_to_num (( pre_cnt * pre_mean + incom_cnt * incom_mean ) / ( cnt_div ), nan = 0 ) self . array_stats [ \"noise_std\" ] = np . sqrt ( np . nan_to_num (( pre_cnt * ( pre_std ** 2 + ( pre_mean - self . array_stats [ \"noise_mean\" ]) ** 2 ) + incom_cnt * ( incom_std ** 2 + ( incom_mean - self . array_stats [ \"noise_mean\" ]) ** 2 )) / ( cnt_div ), nan = 0 )) self . array_stats [ \"noise_cnt\" ] = np . nan_to_num ( pre_cnt + incom_cnt , nan = 0 ) # NEW AX1) chan_cnt = np . count_nonzero ( self . array_stats [ 'num_sam' ]) chan_elec = np . zeros (( chan_cnt , 2 )) chan_ind = np . argsort ( self . array_stats [ 'num_sam' ] . flatten ())[ - chan_cnt :] chan_elec [:, 0 ] = ( chan_ind [:] / 32 ) . astype ( int ) chan_elec [:, 1 ] = chan_ind [:] - ( chan_elec [:, 0 ] * 32 ) chan_elec = chan_elec . astype ( int ) incom_spike_cnt = np . zeros (( 32 , 32 )) incom_spike_avg = np . zeros (( 32 , 32 )) incom_spike_std = np . zeros (( 32 , 32 )) mask2 = np . copy ( data_real ) print ( \"spike threhsold\" , self . spikeThreshold ) for x in range ( len ( chan_ind )): self . array_stats [ \"noise_std\" ] = self . array_stats [ \"noise_std\" ] incom_spike_cnt [ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] = np . count_nonzero ( mask [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] >= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + self . spikeThreshold * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]) mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] <= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + self . spikeThreshold * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]] = np . nan with warnings . catch_warnings (): warnings . simplefilter ( \"ignore\" , category = RuntimeWarning ) incom_spike_avg = np . nanmean ( mask2 , axis = 2 ) incom_spike_avg = np . nan_to_num ( incom_spike_avg , nan = 0 ) incom_spike_std = np . nanstd ( mask2 , axis = 2 ) incom_spike_std = np . nan_to_num ( incom_spike_std , nan = 0 ) pre_spike_avg = np . copy ( self . array_stats [ \"spike_avg\" ]) pre_spike_std = np . copy ( self . array_stats [ \"spike_std\" ]) pre_spike_cnt = np . copy ( self . array_stats [ \"spike_cnt\" ]) new_spike_cnt = pre_spike_cnt + incom_spike_cnt new_spike_cnt [ new_spike_cnt == 0 ] = np . nan self . array_stats [ \"spike_avg\" ] = np . nan_to_num (( pre_spike_cnt * pre_spike_avg + incom_spike_cnt * incom_spike_avg ) / ( new_spike_cnt ), nan = 0 ) self . array_stats [ \"spike_std\" ] = np . sqrt ( np . nan_to_num (( pre_spike_cnt * ( pre_spike_std ** 2 + ( pre_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 ) + incom_spike_cnt * ( incom_spike_std ** 2 + ( incom_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 )) / ( new_spike_cnt ), nan = 0 )) self . array_stats [ \"spike_cnt\" ] = np . nan_to_num ( new_spike_cnt , nan = 0 ) # AX2) Determine the Time of Each Sample total_time = N * 0.05 # Sampling rate 1/0.05 ms self . array_stats [ \"times\" ] = np . linspace ( 0 , total_time , N ) self . array_stats [ \"array spike rate times\" ] . append ( total_time / 1000 ) self . array_stats [ \"array spike rate\" ] . append ( np . sum ( incom_spike_avg ))","title":"DC1DataContainer"},{"location":"DC1DataContainer/#dc1DataVis.app.src.data.DC1DataContainer.DC1DataContainer.append_raw_data","text":"appends raw data in buffer to end of data container, append nonzero data to recorded_data Parameters: Name Type Description Default data_real required cnt_real required N required sampling_period 0.05 Source code in app/src/data/DC1DataContainer.py def append_raw_data ( self , data_real , cnt_real , N , sampling_period = 0.05 ): \"\"\" appends raw data in buffer to end of data container, append nonzero data to recorded_data Args: data_real: cnt_real: N: sampling_period: Returns: \"\"\" while self . raw_data . shape [ 2 ] < self . count_track + N : self . extend_data_containers () self . raw_data [:, :, self . count_track : self . count_track + N ] = data_real [:, :, : N ] self . counts [:, :, self . count_track : self . count_track + N ] = cnt_real [:, :, : N ] # Determine time estimate and sample counts for the total combined buffers # =============================== # (note this does not take into account communication delays - hence an estimate) end_time = N * sampling_period # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms # For the first buffer, we assume the first sample comes in at time 0 if self . time_track == 0 : new_times = np . linspace ( 0 , end_time , N + 1 ) self . times [ 0 : len ( new_times )] = new_times # For buffers after the first, we place these values directly after the previous buffer else : new_times = np . linspace ( self . time_track , self . time_track + end_time , N ) self . times [ self . count_track : self . count_track + N ] = new_times # identify relevant, nonzero channels, and then append only this data into recorded_data num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels = identify_relevant_channels ( data_real ) for i in range ( recorded_channels . shape [ 0 ]): channel_idx = int ( recorded_channels [ i ][ 0 ]) start_idx = recorded_channels [ i ][ 0 ] x , y = idx2map ( channel_idx ) channel_data = { 'channel_idx' : channel_idx , 'start_idx' : int ( self . count_track + start_idx ), # start_idx is based only on buffer, so need to add time from previous buffers 'data' : data_real [ x , y , start_idx : N ], # TODO make this accurate 'times' : self . times [ self . count_track + start_idx : self . count_track + N ] } self . recorded_data . append ( channel_data ) self . time_track += end_time self . count_track += N","title":"append_raw_data()"},{"location":"DC1DataContainer/#dc1DataVis.app.src.data.DC1DataContainer.DC1DataContainer.extend_data_containers","text":"Change data containers dynamically to accommodate longer time windows of data Parameters: Name Type Description Default mode how to expand data containers 'double' Returns: Type Description Nothing Source code in app/src/data/DC1DataContainer.py def extend_data_containers ( self , mode = 'double' ): \"\"\"Change data containers dynamically to accommodate longer time windows of data Args: mode: how to expand data containers Returns: Nothing \"\"\" if mode == 'double' : padding_data = np . zeros ( self . raw_data . shape ) padding_cnt = np . zeros ( self . counts . shape ) padding_times = np . zeros ( self . times . shape ) self . raw_data = np . concatenate (( self . raw_data , padding_data ), axis = 2 ) self . counts = np . concatenate (( self . counts , padding_cnt ), axis = 2 ) self . times = np . concatenate (( self . times , padding_times )) self . container_length *= 2","title":"extend_data_containers()"},{"location":"DC1DataContainer/#dc1DataVis.app.src.data.DC1DataContainer.DC1DataContainer.update_array_stats","text":"Parameters: Name Type Description Default data_real required N required Source code in app/src/data/DC1DataContainer.py def update_array_stats ( self , data_real , N ): \"\"\" Args: data_real: N: Returns: \"\"\" # AX1,AX3,AX4) Sample Counting (Note: Appends are an artifact from previous real time codes) self . array_stats [ 'num_sam' ][:, :, 0 ] = np . count_nonzero ( data_real , axis = 2 ) incom_cnt = self . array_stats [ 'num_sam' ][:, :, 0 ] # AX1,AX3,AX4) Finding average ADC of samples per electrode mask = np . copy ( data_real ) mask [ mask == 0 ] = np . nan import warnings with warnings . catch_warnings (): warnings . simplefilter ( \"ignore\" , category = RuntimeWarning ) self . array_stats [ 'avg_val' ][:, :, 0 ] = np . nanmean ( mask , axis = 2 ) avg_val = np . nan_to_num ( self . array_stats [ 'avg_val' ], nan = 0 ) incom_mean = avg_val [:, :, 0 ] # AX3,AX4) Finding standard deviation ADC of samples per electrode incom_std = np . nanstd ( mask , axis = 2 ) incom_std = np . nan_to_num ( incom_std , nan = 0 ) # AX3,AX4) Building standard deviation of samples per electrode as buffers come in pre_mean = np . copy ( self . array_stats [ \"noise_mean\" ]) pre_std = np . copy ( self . array_stats [ \"noise_std\" ]) pre_cnt = np . copy ( self . array_stats [ \"noise_cnt\" ]) cnt_div = pre_cnt + incom_cnt cnt_div [ cnt_div == 0 ] = np . nan self . array_stats [ \"noise_mean\" ] = np . nan_to_num (( pre_cnt * pre_mean + incom_cnt * incom_mean ) / ( cnt_div ), nan = 0 ) self . array_stats [ \"noise_std\" ] = np . sqrt ( np . nan_to_num (( pre_cnt * ( pre_std ** 2 + ( pre_mean - self . array_stats [ \"noise_mean\" ]) ** 2 ) + incom_cnt * ( incom_std ** 2 + ( incom_mean - self . array_stats [ \"noise_mean\" ]) ** 2 )) / ( cnt_div ), nan = 0 )) self . array_stats [ \"noise_cnt\" ] = np . nan_to_num ( pre_cnt + incom_cnt , nan = 0 ) # NEW AX1) chan_cnt = np . count_nonzero ( self . array_stats [ 'num_sam' ]) chan_elec = np . zeros (( chan_cnt , 2 )) chan_ind = np . argsort ( self . array_stats [ 'num_sam' ] . flatten ())[ - chan_cnt :] chan_elec [:, 0 ] = ( chan_ind [:] / 32 ) . astype ( int ) chan_elec [:, 1 ] = chan_ind [:] - ( chan_elec [:, 0 ] * 32 ) chan_elec = chan_elec . astype ( int ) incom_spike_cnt = np . zeros (( 32 , 32 )) incom_spike_avg = np . zeros (( 32 , 32 )) incom_spike_std = np . zeros (( 32 , 32 )) mask2 = np . copy ( data_real ) print ( \"spike threhsold\" , self . spikeThreshold ) for x in range ( len ( chan_ind )): self . array_stats [ \"noise_std\" ] = self . array_stats [ \"noise_std\" ] incom_spike_cnt [ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] = np . count_nonzero ( mask [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] >= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + self . spikeThreshold * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]) mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] <= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + self . spikeThreshold * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]] = np . nan with warnings . catch_warnings (): warnings . simplefilter ( \"ignore\" , category = RuntimeWarning ) incom_spike_avg = np . nanmean ( mask2 , axis = 2 ) incom_spike_avg = np . nan_to_num ( incom_spike_avg , nan = 0 ) incom_spike_std = np . nanstd ( mask2 , axis = 2 ) incom_spike_std = np . nan_to_num ( incom_spike_std , nan = 0 ) pre_spike_avg = np . copy ( self . array_stats [ \"spike_avg\" ]) pre_spike_std = np . copy ( self . array_stats [ \"spike_std\" ]) pre_spike_cnt = np . copy ( self . array_stats [ \"spike_cnt\" ]) new_spike_cnt = pre_spike_cnt + incom_spike_cnt new_spike_cnt [ new_spike_cnt == 0 ] = np . nan self . array_stats [ \"spike_avg\" ] = np . nan_to_num (( pre_spike_cnt * pre_spike_avg + incom_spike_cnt * incom_spike_avg ) / ( new_spike_cnt ), nan = 0 ) self . array_stats [ \"spike_std\" ] = np . sqrt ( np . nan_to_num (( pre_spike_cnt * ( pre_spike_std ** 2 + ( pre_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 ) + incom_spike_cnt * ( incom_spike_std ** 2 + ( incom_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 )) / ( new_spike_cnt ), nan = 0 )) self . array_stats [ \"spike_cnt\" ] = np . nan_to_num ( new_spike_cnt , nan = 0 ) # AX2) Determine the Time of Each Sample total_time = N * 0.05 # Sampling rate 1/0.05 ms self . array_stats [ \"times\" ] = np . linspace ( 0 , total_time , N ) self . array_stats [ \"array spike rate times\" ] . append ( total_time / 1000 ) self . array_stats [ \"array spike rate\" ] . append ( np . sum ( incom_spike_avg ))","title":"update_array_stats()"},{"location":"analysis/","text":"","title":"Analysis"},{"location":"changelog/","text":"5.12.2022 Reverted to colored circles for array map, color bar correctly linked with it Hover over array map gives the correct values Created spike rate plot Spike rate based on average incoming spike count in each data chunk Developed four new GUI panes: New session preferences: initial settings to start analyzing datarun streamlined way of choosing to load offline/realtime data set spike threshold value from the beginning of session choose file directory on startup Individual Channel Analysis: for looking at plots for individual channels Convenient lookup of channels by number/row/col Electrode List Analysis: for displaying numerical data of electrodes in a sorted list GUI preferences: for persistent settings for the GUI not affected by datarun Set up github + github pages","title":"Change Log"},{"location":"changelog/#5122022","text":"Reverted to colored circles for array map, color bar correctly linked with it Hover over array map gives the correct values Created spike rate plot Spike rate based on average incoming spike count in each data chunk Developed four new GUI panes: New session preferences: initial settings to start analyzing datarun streamlined way of choosing to load offline/realtime data set spike threshold value from the beginning of session choose file directory on startup Individual Channel Analysis: for looking at plots for individual channels Convenient lookup of channels by number/row/col Electrode List Analysis: for displaying numerical data of electrodes in a sorted list GUI preferences: for persistent settings for the GUI not affected by datarun Set up github + github pages","title":"5.12.2022"},{"location":"data-loading/","text":"","title":"Data Loading"},{"location":"data/","text":"","title":"Data"},{"location":"filters/","text":"Filters applyFilterAuto ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterAuto ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" samFreq = 20e3 * 1.0 passband = [ 250 , 4000 ] stopband = [ 5 , 6000 ] max_loss_passband = 3 min_loss_stopband = 30 order , normal_cutoff = signal . buttord ( passband , stopband , max_loss_passband , min_loss_stopband , fs = samFreq ) b , a = signal . butter ( order , normal_cutoff , btype = 'bandpass' , fs = samFreq ) print ( 'Order = ' + str ( order )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterFastBandpass ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterFastBandpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , analog = False ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterFasterBandpass ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterFasterBandpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq sos1 = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , output = 'sos' ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . sosfiltfilt ( sos1 , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterH0bandpass ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterH0bandpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 5 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) print ( 'Order = ' + str ( 5 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterHierlemann ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterHierlemann ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" BP_LOW_CUTOFF = 100.0 NUM_TAPS = 75 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( TAPS , [ a ], dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterHighpass ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterHighpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff = 250 / nyq b , a = signal . butter ( 5 , [ cutoff ], btype = \"highpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterLitke ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterLitke ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 2000 / nyq b , a = signal . butter ( 2 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterModHierlemann ( channel_data , dataFilt ) Parameters: Name Type Description Default channel_data required dataFilt required Source code in app/src/data/filters.py def applyFilterModHierlemann ( channel_data , dataFilt ): \"\"\" Args: channel_data: dataFilt: Returns: \"\"\" BP_LOW_CUTOFF = 250.0 BP_HIGH_CUTOFF = 4000.0 NUM_TAPS = 100 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , BP_HIGH_CUTOFF ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 dataFilt = signal . filtfilt ( TAPS , [ a ], channel_data ) return dataFilt applyFilterToAllData ( dataAll , numChan , chMap , filtType = 'modHierlemann' ) Parameters: Name Type Description Default dataAll required numChan required chMap required filtType 'modHierlemann' Source code in app/src/data/filters.py def applyFilterToAllData ( dataAll , numChan , chMap , filtType = 'modHierlemann' ): \"\"\" Args: dataAll: numChan: chMap: filtType: Returns: \"\"\" # Future update: only calculate for channels recorded not all dataFilt = np . zeros (( np . shape ( dataAll ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemann ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'modHierlemann' : dataFilt = applyFilterModHierlemann ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'highpass' : dataFilt = applyFilterHighpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'hObandpass' : dataFilt = applyFilterH0bandpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'auto' : dataFilt = applyFilterAuto ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'fastBandpass' : dataFilt = applyFilterFastBandpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'fasterBandpass' : dataFilt = applyFilterFasterBandpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Litke' : dataFilt = applyFilterLitke ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'none' : dataFilt = np . copy ( dataAll ) else : dataFilt = np . copy ( dataAll ) print ( 'Filter not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) return dataFilt applyFilterToChannelData ( channel_data , filtType = 'Hierlemann' ) Parameters: Name Type Description Default channel_data required filtType 'Hierlemann' Source code in app/src/data/filters.py def applyFilterToChannelData ( channel_data , filtType = 'Hierlemann' ): \"\"\" Args: channel_data: filtType: Returns: \"\"\" dataFilt = np . zeros (( np . shape ( channel_data ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemann ( channel_data , dataFilt ) elif filtType == 'modHierlemann' : dataFilt = applyFilterModHierlemann ( channel_data , dataFilt ) elif filtType == 'highpass' : dataFilt = applyFilterHighpass ( channel_data , dataFilt ) elif filtType == 'hObandpass' : dataFilt = applyFilterH0bandpass ( channel_data , dataFilt ) elif filtType == 'auto' : dataFilt = applyFilterAuto ( channel_data , dataFilt ) elif filtType == 'fastBandpass' : dataFilt = applyFilterFastBandpass ( channel_data , dataFilt ) elif filtType == 'fasterBandpass' : dataFilt = applyFilterFasterBandpass ( channel_data , dataFilt ) elif filtType == 'Litke' : dataFilt = applyFilterLitke ( channel_data , dataFilt ) elif filtType == 'none' : dataFilt = np . copy ( channel_data ) else : dataFilt = np . copy ( channel_data ) print ( 'Filter not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) return dataFilt","title":"Filters"},{"location":"filters/#filters","text":"","title":"Filters"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterAuto","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterAuto ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" samFreq = 20e3 * 1.0 passband = [ 250 , 4000 ] stopband = [ 5 , 6000 ] max_loss_passband = 3 min_loss_stopband = 30 order , normal_cutoff = signal . buttord ( passband , stopband , max_loss_passband , min_loss_stopband , fs = samFreq ) b , a = signal . butter ( order , normal_cutoff , btype = 'bandpass' , fs = samFreq ) print ( 'Order = ' + str ( order )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterAuto()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterFastBandpass","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterFastBandpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , analog = False ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterFastBandpass()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterFasterBandpass","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterFasterBandpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq sos1 = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , output = 'sos' ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . sosfiltfilt ( sos1 , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterFasterBandpass()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterH0bandpass","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterH0bandpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 5 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) print ( 'Order = ' + str ( 5 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterH0bandpass()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterHierlemann","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterHierlemann ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" BP_LOW_CUTOFF = 100.0 NUM_TAPS = 75 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( TAPS , [ a ], dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterHierlemann()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterHighpass","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterHighpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff = 250 / nyq b , a = signal . butter ( 5 , [ cutoff ], btype = \"highpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterHighpass()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterLitke","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterLitke ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 2000 / nyq b , a = signal . butter ( 2 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterLitke()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterModHierlemann","text":"Parameters: Name Type Description Default channel_data required dataFilt required Source code in app/src/data/filters.py def applyFilterModHierlemann ( channel_data , dataFilt ): \"\"\" Args: channel_data: dataFilt: Returns: \"\"\" BP_LOW_CUTOFF = 250.0 BP_HIGH_CUTOFF = 4000.0 NUM_TAPS = 100 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , BP_HIGH_CUTOFF ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 dataFilt = signal . filtfilt ( TAPS , [ a ], channel_data ) return dataFilt","title":"applyFilterModHierlemann()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterToAllData","text":"Parameters: Name Type Description Default dataAll required numChan required chMap required filtType 'modHierlemann' Source code in app/src/data/filters.py def applyFilterToAllData ( dataAll , numChan , chMap , filtType = 'modHierlemann' ): \"\"\" Args: dataAll: numChan: chMap: filtType: Returns: \"\"\" # Future update: only calculate for channels recorded not all dataFilt = np . zeros (( np . shape ( dataAll ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemann ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'modHierlemann' : dataFilt = applyFilterModHierlemann ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'highpass' : dataFilt = applyFilterHighpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'hObandpass' : dataFilt = applyFilterH0bandpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'auto' : dataFilt = applyFilterAuto ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'fastBandpass' : dataFilt = applyFilterFastBandpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'fasterBandpass' : dataFilt = applyFilterFasterBandpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Litke' : dataFilt = applyFilterLitke ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'none' : dataFilt = np . copy ( dataAll ) else : dataFilt = np . copy ( dataAll ) print ( 'Filter not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) return dataFilt","title":"applyFilterToAllData()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterToChannelData","text":"Parameters: Name Type Description Default channel_data required filtType 'Hierlemann' Source code in app/src/data/filters.py def applyFilterToChannelData ( channel_data , filtType = 'Hierlemann' ): \"\"\" Args: channel_data: filtType: Returns: \"\"\" dataFilt = np . zeros (( np . shape ( channel_data ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemann ( channel_data , dataFilt ) elif filtType == 'modHierlemann' : dataFilt = applyFilterModHierlemann ( channel_data , dataFilt ) elif filtType == 'highpass' : dataFilt = applyFilterHighpass ( channel_data , dataFilt ) elif filtType == 'hObandpass' : dataFilt = applyFilterH0bandpass ( channel_data , dataFilt ) elif filtType == 'auto' : dataFilt = applyFilterAuto ( channel_data , dataFilt ) elif filtType == 'fastBandpass' : dataFilt = applyFilterFastBandpass ( channel_data , dataFilt ) elif filtType == 'fasterBandpass' : dataFilt = applyFilterFasterBandpass ( channel_data , dataFilt ) elif filtType == 'Litke' : dataFilt = applyFilterLitke ( channel_data , dataFilt ) elif filtType == 'none' : dataFilt = np . copy ( channel_data ) else : dataFilt = np . copy ( channel_data ) print ( 'Filter not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) return dataFilt","title":"applyFilterToChannelData()"},{"location":"getting-started/","text":"Conda Environment - dc1_vis.yml Contains all the packages needed to run visualizations Development - Important Files dc1DataVis/run.py Startup file dc1DataVis/src/gui/gui_base.py Basis for the entire GUI. Every other script links to this file! If unsure what a file does, check where it is loaded in relation to this file. Development - GUI stuff dc1DataVis/src/gui/*.ui All of these files were made and can be viewed using software called Qt Designer. These files layout out the structure for every GUI panel. Associated .py files with the same filename generate from these .ui files and are convenient to know how to reference different pyqtgraph elements. dc1DataVis/src/gui/gui_charts_helper.py Code to setup every analysis chart Development - data processing dc1DataVis/src/data/DC1DataContainer.py this class is instantiated in gui_base and basically holds all the possible data that is loaded up during the session runtime dc1DataVis/src/data/data_loading.py misc functions related to loading .MAT / .NPZ files dc1DataVis/src/data/preprocessing.py contains functions that sorts out the relevant channels that are being recorded at any one time dc1DataVis/src/data/filters.py self explanatory","title":"Getting Started"},{"location":"getting-started/#conda-environment-dc1_visyml","text":"Contains all the packages needed to run visualizations","title":"Conda Environment - dc1_vis.yml"},{"location":"getting-started/#development-important-files","text":"","title":"Development - Important Files"},{"location":"getting-started/#dc1datavisrunpy","text":"Startup file","title":"dc1DataVis/run.py"},{"location":"getting-started/#dc1datavissrcguigui_basepy","text":"Basis for the entire GUI. Every other script links to this file! If unsure what a file does, check where it is loaded in relation to this file.","title":"dc1DataVis/src/gui/gui_base.py"},{"location":"getting-started/#development-gui-stuff","text":"","title":"Development - GUI stuff"},{"location":"getting-started/#dc1datavissrcguiui","text":"All of these files were made and can be viewed using software called Qt Designer. These files layout out the structure for every GUI panel. Associated .py files with the same filename generate from these .ui files and are convenient to know how to reference different pyqtgraph elements.","title":"dc1DataVis/src/gui/*.ui"},{"location":"getting-started/#dc1datavissrcguigui_charts_helperpy","text":"Code to setup every analysis chart","title":"dc1DataVis/src/gui/gui_charts_helper.py"},{"location":"getting-started/#development-data-processing","text":"","title":"Development - data processing"},{"location":"getting-started/#dc1datavissrcdatadc1datacontainerpy","text":"this class is instantiated in gui_base and basically holds all the possible data that is loaded up during the session runtime","title":"dc1DataVis/src/data/DC1DataContainer.py"},{"location":"getting-started/#dc1datavissrcdatadata_loadingpy","text":"misc functions related to loading .MAT / .NPZ files","title":"dc1DataVis/src/data/data_loading.py"},{"location":"getting-started/#dc1datavissrcdatapreprocessingpy","text":"contains functions that sorts out the relevant channels that are being recorded at any one time","title":"dc1DataVis/src/data/preprocessing.py"},{"location":"getting-started/#dc1datavissrcdatafilterspy","text":"self explanatory","title":"dc1DataVis/src/data/filters.py"},{"location":"gui-base/","text":"GUI Base Class Huy Nguyen (2022) Contains the base app framework for loading up the GUI. Note: To regenerate gui_layout.py, in terminal do pyuic5 layout.ui -o gui_layout.py MainWindow ( QMainWindow , Ui_mainWindow ) Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. Source code in app/src/gui/gui_base.py class MainWindow ( QtWidgets . QMainWindow , Ui_mainWindow ): \"\"\" Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. \"\"\" # MODES mode_profiling = True mode_multithreading = True first_time_plotting = True is_dark_mode = False # Program State settings = {} loading_dict = {} LoadedData = None # Raw data stream from chip, only double/triple/etc. counts removed profile_data = None charts , chart_update_function_mapping = None , None external_windows = [] # Misc p = None center_row , center_col = 16 , 16 # for Mini Map arrayMap_colorbar = None def __init__ ( self , * args , ** kwargs ): super ( MainWindow , self ) . __init__ ( * args , ** kwargs ) self . charts = { \"arrayMap\" : None , \"miniMap\" : None , \"spikeRatePlot\" : None , \"noiseHistogram\" : None , \"channelTraceVerticalLayout\" : None , \"channelTrace1\" : None , \"channelTrace2\" : None , \"channelTrace3\" : None , \"channelTrace4\" : None } self . chart_update_function_mapping = { \"arrayMap\" : self . updateArrayMapPlot , \"miniMap\" : self . updateMiniMapPlot , \"spikeRatePlot\" : self . updateSpikeRatePlot , \"noiseHistogram\" : self . updateNoiseHistogramPlot , \"channelTrace1\" : self . updateChannelTracePlot , \"channelTrace2\" : self . updateChannelTracePlot , \"channelTrace3\" : self . updateChannelTracePlot , \"channelTrace4\" : self . updateChannelTracePlot } if self . mode_profiling : self . profile_data = { 'appendRawData' : [], 'filterData' : [], 'calculateArrayStats' : [], 'arrayMap' : [], 'channelTrace' : [], 'noiseHistogram' : [], 'spikeRatePlot' : [], 'miniMap' : [], 'channelTrace1' : [], 'channelTrace2' : [], 'channelTrace3' : [], 'channelTrace4' : [] } if self . mode_multithreading : print ( 'GUI is multithreading' ) def setSettings ( self , settings ): self . settings = settings def setupLayout ( self ): print ( \"Session settings: \" + str ( self . settings )) # Load layout based on QtDesigner .ui file if self . settings [ \"visStyle\" ] == \"Default\" : uic . loadUi ( \"./src/gui/default_vis.ui\" , self ) self . charts [ \"arrayMap\" ] = self . arrayMap setupArrayMap ( self . charts [ \"arrayMap\" ]) self . charts [ \"arrayMapHover\" ] = HoverRegion ( self . charts [ \"arrayMap\" ], self . showArrayLocOnStatusBar , self . setMiniMapLoc ) self . charts [ \"miniMap\" ] = self . miniMap setupMiniMapPlot ( self . charts [ \"miniMap\" ]) self . charts [ \"spikeRatePlot\" ] = self . spikeRatePlot setupSpikeRatePlot ( self . charts [ \"spikeRatePlot\" ]) self . charts [ \"noiseHistogram\" ] = self . noiseHistogram setupNoiseHistogram ( self . charts [ \"noiseHistogram\" ]) self . charts [ \"channelTraceVerticalLayout\" ] = self . channelTraceVerticalLayout self . charts [ \"channelTrace1\" ] = self . channelTrace1 self . charts [ \"channelTrace2\" ] = self . channelTrace2 self . charts [ \"channelTrace3\" ] = self . channelTrace3 self . charts [ \"channelTrace4\" ] = self . channelTrace4 setupSpikeTrace ( self . channelTrace1 , self . channelTrace2 , self . channelTrace3 , self . channelTrace4 ) elif self . settings [ \"visStyle\" ] == \"Spike Search\" : uic . loadUi ( \"./src/gui/spikefinding_vis.ui\" , self ) self . charts [ \"ResetButton\" ] = self . ResetButton self . charts [ \"nextFigButton\" ] = self . nextFigButton self . charts [ \"yScaleButton\" ] = self . yScaleButton self . charts [ \"backButton\" ] = self . BackButton self . charts [ \"nextButton\" ] = self . Next self . charts [ \"atTimeWindowButton\" ] = self . atTimeWindowButton self . charts [ \"spikeTraces\" ] = [[], [], [], [], [], []] for i in range ( 1 , 7 ): for j in range ( 1 , 7 ): chart_name = \"r\" + str ( i ) + \"c\" + str ( j ) self . charts [ chart_name ] = eval ( \"self.\" + chart_name ) setupOneSpikeTrace ( self . charts [ chart_name ]) elif self . settings [ \"visStyle\" ] == \"Noise\" : uic . loadUi ( \"./src/gui/noise_check_vis.ui\" , self ) self . charts [ \"arrayMap\" ] = self . arrayMap setupArrayMap ( self . charts [ \"arrayMap\" ]) self . charts [ \"arrayMapHover\" ] = HoverRegion ( self . charts [ \"arrayMap\" ], self . showArrayLocOnStatusBar , self . setMiniMapLoc ) self . charts [ \"noiseHistogram\" ] = self . noiseHistogramPlot setupNoiseHistogram ( self . charts [ \"noiseHistogram\" ]) self . charts [ \"noiseMatrixPlot\" ] = self . noiseMatrixPlot self . charts [ \"channelTraceVerticalLayout\" ] = self . channelTraceLayout self . charts [ \"channelTrace1\" ] = self . channelTrace1 self . charts [ \"channelTrace2\" ] = self . channelTrace2 self . charts [ \"channelTrace3\" ] = self . channelTrace3 self . charts [ \"channelTrace4\" ] = self . channelTrace4 setupSpikeTrace ( self . channelTrace1 , self . channelTrace2 , self . channelTrace3 , self . channelTrace4 ) else : sys . exit () print ( \"else\" ) self . setupInteractivity () # just sets background to white TODO make this cleaner self . toggleDarkMode () self . toggleDarkMode () def showArrayLocOnStatusBar ( self , x , y ): int_x = int ( x ) int_y = int ( y ) if - 1 <= int_x < 31 and - 1 <= int_y < 31 : self . statusBar () . showMessage ( \"Array Map Spike Average @ \" + str ( int_y ) + \", \" + str ( int_x ) + \": \" + str ( self . LoadedData . array_stats [ 'spike_avg' ][ int_y + 1 ][ int_x + 1 ]) ) def setMiniMapLoc ( self , x , y ): print ( \"setMiniMapLoc\" ) print ( x , y ) self . center_row = int ( x ) if self . center_row < 6 : self . center_row = 6 elif self . center_row > 26 : self . center_row = 26 if self . center_col < 4 : self . center_col = 4 elif self . center_col > 29 : self . center_col = 29 self . center_col = int ( y ) self . updateMiniMapPlot () def setupInteractivity ( self ): self . LoadedData = DC1DataContainer () # class for holding and manipulating data print ( \"setupinteractivity\" , self . settings [ \"spikeThreshold\" ]) self . LoadedData . setSpikeThreshold ( self . settings [ \"spikeThreshold\" ]) # Set up PyQt multithreading self . threadpool = QThreadPool () print ( \"Multithreading with maximum %d threads\" % self . threadpool . maxThreadCount ()) # >>>> MENU BAR <<<<< # TODO hook up interactivity for all menu bar buttons # >> FILE BUTTON self . action_npz . triggered . connect ( self . onActionLoadNPZ ) self . action_mat . triggered . connect ( self . onActionLoadMAT ) self . actionUpdateSession . triggered . connect ( self . onLoadRealtimeStream ) self . actionIndividualChannelInfo . triggered . connect ( self . viewNewIndividalChannelInformation ) self . actionListElectrodesInfo . triggered . connect ( self . viewChannelListInformation ) self . actionAnalysisParameters . triggered . connect ( self . viewGUIPreferences ) def viewNewIndividalChannelInformation ( self ): from ..gui.gui_individualchannel import IndividualChannelInformation new_window = IndividualChannelInformation () new_window . label = QLabel ( \"Individual Channel Analysis\" ) new_window . setSessionParent ( self ) new_window . show () new_window . exec () self . external_windows . append ( new_window ) def viewChannelListInformation ( self ): from ..gui.gui_electrodelist import ElectrodeListInformation new_window = ElectrodeListInformation () new_window . label = QLabel ( \"Electrode List Analysis\" ) new_window . setSessionParent ( self ) new_window . show () new_window . exec () self . external_windows . append ( new_window ) def viewGUIPreferences ( self ): from ..gui.gui_sessionparameters import GUIPreferences new_window = GUIPreferences () new_window . label = QLabel ( \"GUI Preferences\" ) new_window . show () new_window . exec () self . external_windows . append ( new_window ) def toggleDarkMode ( self ): self . is_dark_mode = not self . is_dark_mode if self . is_dark_mode is True : color = 'k' else : color = 'w' for chart in self . charts . keys (): chart_type = type ( self . charts [ chart ]) if str ( chart_type ) == \"<class 'pyqtgraph.widgets.PlotWidget.PlotWidget'>\" : self . charts [ chart ] . setBackground ( color ) \"\"\" ======================= MULTITHREADING PROGRESS FUNCS ======================= \"\"\" def progress_fn ( self , n ): print ( \" %d%% done\" % n ) def print_output ( self , s ): print ( s ) def thread_complete ( self ): print ( \"THREAD COMPLETE!\" ) \"\"\" ======================= MENU BAR // FILE... ======================= \"\"\" def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path def loadSession ( self ): if self . settings [ \"path\" ] == \"\" : raise ValueError ( \"Path is not specified!\" ) if self . settings [ 'realTime' ] == \"Yes, load first .mat chunk\" : self . onLoadRealtimeStream ( load_from_beginning = True ) elif self . settings [ 'realTime' ] == \"Yes, load latest .mat chunk\" : self . onLoadRealtimeStream ( load_from_beginning = False ) elif self . settings [ 'realTime' ] == \"No, load raw .mat file\" : #TODO parallelize self . onLoadRealTimeStraet ( load_from_beginning = True ) elif self . settings [ 'realTime' ] == \"No, load pre-processed .npz file\" : #TODO self . onActionLoadNPZ () elif self . settings [ 'realTime' ] == \"No, load filtered .npz file\" : #TODO self . onActionLoadNPZ () else : raise ValueError ( \"this should not be possible\" ) # (1) Yes, load first .mat chunk & (2) Yes, load latest .mat chunk def onLoadRealtimeStream ( self , load_from_beginning = True ): self . loading_dict = initDataLoading ( self . settings [ \"path\" ]) # TODO parallelize loading already saved .mat files load_realtime_worker = Worker ( self . realtimeLoading , self . settings [ \"path\" ], self . loading_dict , load_from_beginning ) load_realtime_worker . signals . progress . connect ( self . updateStatusBar ) load_realtime_worker . signals . gui_callback . connect ( self . updateGUIWithNewData ) self . threadpool . start ( load_realtime_worker ) # TODO (3) No, load raw .mat file # parallelize this faster # TODO (4) No, load pre-processed .npz file def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) self . loading_dict [ \"path\" ] = path data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData () # TODO (5) No, load filtered .npz file # callback from progress signal def updateStatusBar ( self , message ): self . statusBar () . showMessage ( message ) # Continuously Check for New Data def realtimeLoading ( self , path , loadingDict , load_from_beginning , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] if load_from_beginning : last_file_idx = 0 else : last_file_idx = loadingDict [ \"num_of_buf\" ] - 2 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'appendRawData' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filterData' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculateArrayStats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit () def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict ) def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = self . settings [ \"filter\" ]) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData () def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" print ( \"Update GUI with new data()\" ) self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession for window in self . external_windows : window . update () for chart in self . charts . keys (): chart_type = type ( self . charts [ chart ]) if str ( chart_type ) == \"<class 'pyqtgraph.widgets.PlotWidget.PlotWidget'>\" : start = time . time () self . chart_update_function_mapping [ chart ]() end = time . time () self . profile_data [ chart ] . append ( end - start ) if self . mode_profiling : self . printProfilingData () def printProfilingData ( self ): print ( \"------------------------------\" ) print ( \"Current profiling statistics:\" ) for key in self . profile_data . keys (): avg_time = np . round ( np . mean ( self . profile_data [ key ]), 3 ) print ( key , avg_time ) print ( \"------------------------------\" ) def updateArrayMapPlot ( self ): self . charts [ \"arrayMap\" ] . clear () if self . first_time_plotting is False : colors = self . LoadedData . array_stats [ 'spike_avg' ] data = colors . T # for old pixel-based data max_dot = 100 # AX1) Size by Number of Samples spike_cnt = self . LoadedData . array_stats [ 'spike_cnt' ] scale1 = ( max_dot - 15 ) / ( np . max ( spike_cnt ) - np . min ( spike_cnt [ spike_cnt != 0 ])) b_add = max_dot - ( np . max ( spike_cnt ) * scale1 ) size = np . round ( spike_cnt * scale1 + b_add ) size [ size < 15 ] = 10 # TODO fix saturation point else : data = np . fromfunction ( lambda i , j : ( 1 + 0.01 * np . sin ( i )) * ( i ) ** 1 + ( j ) ** 1 , ( 32 , 32 )) data = data * ( 1 + 0.001 * np . random . random ( data . shape )) cm = pg . colormap . get ( 'CET-L9' ) image = pg . ImageItem ( data ) self . charts [ \"arrayMap\" ] . addItem ( image ) # bound the LinearRegionItem to the plotted data self . charts [ \"arrayMapHover\" ] . region . setClipItem ( image ) if self . arrayMap_colorbar is None : self . arrayMap_colorbar = self . charts [ \"arrayMap\" ] . addColorBar ( image , colorMap = cm , values = ( 0 , 150 )) #values=(0, np.max(data))) self . arrayMap_colorbar . sigLevelsChanged . connect ( self . colorBarLevelsChanged ) else : self . arrayMap_colorbar . setImageItem ( image ) #self.charts[\"arrayMap\"]_colorbar.setLevels((0, np.max(data))) # Set pxMode=False to allow spots to transform with the view scatter = pg . ScatterPlotItem ( pxMode = False ) # creating empty list for spots spots = [] # color modulated by amplitude cmap = plt . cm . get_cmap ( \"jet\" ) for i in range ( 32 ): for j in range ( 32 ): # creating spot position which get updated after each iteration # of color which also get updated if self . first_time_plotting is True : spot_dic = { 'pos' : ( i , j ), 'size' : 0 , 'pen' : { 'color' : 'w' , 'width' : 1 }, 'brush' : pg . intColor ( 1 , 100 )} else : color_map = self . arrayMap_colorbar . colorMap () levels = self . arrayMap_colorbar . levels () value = colors [ i , j ] if value < levels [ 0 ]: value = levels [ 0 ] elif value > levels [ 1 ]: value = levels [ 1 ] adjusted_value = ( value - levels [ 0 ]) / ( levels [ 1 ] - levels [ 0 ]) color_indicator = color_map . map ( adjusted_value ) spot_dic = { 'pos' : ( j , i ), 'size' : size [ i , j ] / 60 , 'pen' : { 'color' : 'w' , 'width' : size [ i , j ] / 60 }, 'brush' : pg . mkColor ( color_indicator )} # TODO fix coloring # used to be 'brush': pg.intColor(color_indicator, 100) # adding spot_dic in the list of spots spots . append ( spot_dic ) self . first_time_plotting = False self . charts [ \"arrayMap\" ] . clear () scatter . addPoints ( spots ) # adding spots to the scatter plot self . charts [ \"arrayMap\" ] . addItem ( scatter ) # adding scatter plot to the plot window def colorBarLevelsChanged ( self ): self . charts [ \"arrayMap\" ] . clear () colors = self . LoadedData . array_stats [ 'spike_avg' ] data = colors . T # for old pixel-based data max_dot = 100 # AX1) Size by Number of Samples spike_cnt = self . LoadedData . array_stats [ 'spike_cnt' ] scale1 = ( max_dot - 15 ) / ( np . max ( spike_cnt ) - np . min ( spike_cnt [ spike_cnt != 0 ])) b_add = max_dot - ( np . max ( spike_cnt ) * scale1 ) size = np . round ( spike_cnt * scale1 + b_add ) size [ size < 15 ] = 10 # TODO fix saturation point # Set pxMode=False to allow spots to transform with the view scatter = pg . ScatterPlotItem ( pxMode = False ) # creating empty list for spots spots = [] # color modulated by amplitude cmap = plt . cm . get_cmap ( \"jet\" ) for i in range ( 32 ): for j in range ( 32 ): # creating spot position which get updated after each iteration # of color which also get updated if self . first_time_plotting is True : spot_dic = { 'pos' : ( i , j ), 'size' : random . random () * 0.5 + 0.5 , 'pen' : { 'color' : 'w' , 'width' : 2 }, 'brush' : pg . intColor ( i * 10 + j , 100 )} else : color_map = self . arrayMap_colorbar . colorMap () levels = self . arrayMap_colorbar . levels () value = colors [ i , j ] if value < levels [ 0 ]: value = levels [ 0 ] elif value > levels [ 1 ]: value = levels [ 1 ] adjusted_value = ( value - levels [ 0 ]) / ( levels [ 1 ] - levels [ 0 ]) color_indicator = color_map . map ( adjusted_value ) spot_dic = { 'pos' : ( j , i ), 'size' : size [ i , j ] / 60 , 'pen' : { 'color' : 'w' , 'width' : size [ i , j ] / 60 }, 'brush' : pg . mkColor ( color_indicator )} # TODO fix coloring # used to be 'brush': pg.intColor(color_indicator, 100) # adding spot_dic in the list of spots spots . append ( spot_dic ) self . charts [ \"arrayMap\" ] . clear () scatter . addPoints ( spots ) # adding spots to the scatter plot self . charts [ \"arrayMap\" ] . addItem ( scatter ) # adding scatter plot to the plot window def updateChannelTracePlot ( self ): trace_plots = [ self . channelTrace1 , self . channelTrace2 , self . channelTrace3 , self . channelTrace4 ] len_data = len ( self . LoadedData . filtered_data ) # Generate subplots for m , plt in enumerate ( trace_plots ): chan_idx = len_data + ( m - 4 ) x = self . LoadedData . filtered_data [ chan_idx ][ 'times' ] y = self . LoadedData . filtered_data [ chan_idx ][ 'data' ] plt . clear () plt . plot ( x , y , pen = 'b' ) plt . setLabel ( 'left' , '#' + str ( self . LoadedData . filtered_data [ chan_idx ][ 'channel_idx' ])) plt . enableAutoRange ( axis = 'y' ) plt . setAutoVisible ( y = True ) def updateSpikeRatePlot ( self ): self . charts [ \"spikeRatePlot\" ] . clear () vals = self . LoadedData . array_stats [ 'noise_std' ] vals = vals [ np . nonzero ( vals )] # get nonzero vals because zeros have not had noise calculation done yet y , x = np . histogram ( vals , bins = np . linspace ( 0 , 20 , 40 )) curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . charts [ \"spikeRatePlot\" ] . addItem ( curve ) def updateNoiseHistogramPlot ( self ): self . charts [ \"noiseHistogram\" ] . clear () if self . LoadedData is not None : avg_spike_rate_times = self . LoadedData . array_stats [ \"array spike rate times\" ] x = np . cumsum ( avg_spike_rate_times ) y = self . LoadedData . array_stats [ \"array spike rate\" ] line_plot = self . charts [ \"noiseHistogram\" ] . plot ( x , y , pen = 'b' , symbol = 'o' , symbolPen = 'b' , symbolBrush = 0.2 ) def updateMiniMapPlot ( self ): self . charts [ \"miniMap\" ] . clear () print ( 'update minimap plot:' , self . center_row , self . center_col ) for row in range ( self . center_row - 4 , self . center_row + 4 ): for col in range ( self . center_col - 2 , self . center_col + 2 ): print ( 'r' , row , 'c' , col ) spike_indicator_base = pg . QtGui . QGraphicsRectItem ( row * 5 , col * 5 , 4 , 0.2 ) spike_indicator_base . setPen ( pg . mkPen (( 0 , 0 , 0 , 100 ))) spike_indicator_base . setBrush ( pg . mkBrush (( 50 , 50 , 200 ))) elec_idx = str ( map2idx ( col , row )) spike_indicator_text = pg . TextItem ( elec_idx , 'k' , anchor = ( 0 , 0 )) spike_indicator_text . setPos ( row * 5 , col * 5 ) spike_indicator_text . setParentItem ( spike_indicator_base ) #times = [0, 1, 3, 5, 10, 11, 14] if np . random . random () > 0.5 : times = np . random . randint ( 0 , 20 , ( 3 ,), dtype = 'int64' ) for i in times : spike_indicator = pg . QtGui . QGraphicsRectItem ( row * 5 + i / 5 , col * 5 , 0.1 , 1.5 ) spike_indicator . setPen ( pg . mkPen (( 0 , 0 , 0 , 100 ))) spike_indicator . setBrush ( pg . mkBrush (( 50 , 50 , 200 ))) spike_indicator . setParentItem ( spike_indicator_base ) self . charts [ \"miniMap\" ] . addItem ( spike_indicator ) self . charts [ \"miniMap\" ] . addItem ( spike_indicator_base ) self . charts [ \"miniMap\" ] . addItem ( spike_indicator_text ) getDataPath ( self , file_type ) Parameters: Name Type Description Default file_type str required Source code in app/src/gui/gui_base.py def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path loadDataFromFileMat ( self , path , loadingDict ) Parameters: Name Type Description Default path required loadingDict required Source code in app/src/gui/gui_base.py def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = self . settings [ \"filter\" ]) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData () onActionLoadMAT ( self ) Source code in app/src/gui/gui_base.py def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict ) onActionLoadNPZ ( self ) Source code in app/src/gui/gui_base.py def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) self . loading_dict [ \"path\" ] = path data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData () realtimeLoading ( self , path , loadingDict , load_from_beginning , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ) Parameters: Name Type Description Default path required loadingDict required progress_callback required gui_callback required dataIdentifierString 'gmem1' Source code in app/src/gui/gui_base.py def realtimeLoading ( self , path , loadingDict , load_from_beginning , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] if load_from_beginning : last_file_idx = 0 else : last_file_idx = loadingDict [ \"num_of_buf\" ] - 2 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'appendRawData' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filterData' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculateArrayStats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit () updateGUIWithNewData ( self ) Source code in app/src/gui/gui_base.py def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" print ( \"Update GUI with new data()\" ) self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession for window in self . external_windows : window . update () for chart in self . charts . keys (): chart_type = type ( self . charts [ chart ]) if str ( chart_type ) == \"<class 'pyqtgraph.widgets.PlotWidget.PlotWidget'>\" : start = time . time () self . chart_update_function_mapping [ chart ]() end = time . time () self . profile_data [ chart ] . append ( end - start ) if self . mode_profiling : self . printProfilingData () Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. Source code in app/src/gui/gui_base.py class MainWindow ( QtWidgets . QMainWindow , Ui_mainWindow ): \"\"\" Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. \"\"\" # MODES mode_profiling = True mode_multithreading = True first_time_plotting = True is_dark_mode = False # Program State settings = {} loading_dict = {} LoadedData = None # Raw data stream from chip, only double/triple/etc. counts removed profile_data = None charts , chart_update_function_mapping = None , None external_windows = [] # Misc p = None center_row , center_col = 16 , 16 # for Mini Map arrayMap_colorbar = None def __init__ ( self , * args , ** kwargs ): super ( MainWindow , self ) . __init__ ( * args , ** kwargs ) self . charts = { \"arrayMap\" : None , \"miniMap\" : None , \"spikeRatePlot\" : None , \"noiseHistogram\" : None , \"channelTraceVerticalLayout\" : None , \"channelTrace1\" : None , \"channelTrace2\" : None , \"channelTrace3\" : None , \"channelTrace4\" : None } self . chart_update_function_mapping = { \"arrayMap\" : self . updateArrayMapPlot , \"miniMap\" : self . updateMiniMapPlot , \"spikeRatePlot\" : self . updateSpikeRatePlot , \"noiseHistogram\" : self . updateNoiseHistogramPlot , \"channelTrace1\" : self . updateChannelTracePlot , \"channelTrace2\" : self . updateChannelTracePlot , \"channelTrace3\" : self . updateChannelTracePlot , \"channelTrace4\" : self . updateChannelTracePlot } if self . mode_profiling : self . profile_data = { 'appendRawData' : [], 'filterData' : [], 'calculateArrayStats' : [], 'arrayMap' : [], 'channelTrace' : [], 'noiseHistogram' : [], 'spikeRatePlot' : [], 'miniMap' : [], 'channelTrace1' : [], 'channelTrace2' : [], 'channelTrace3' : [], 'channelTrace4' : [] } if self . mode_multithreading : print ( 'GUI is multithreading' ) def setSettings ( self , settings ): self . settings = settings def setupLayout ( self ): print ( \"Session settings: \" + str ( self . settings )) # Load layout based on QtDesigner .ui file if self . settings [ \"visStyle\" ] == \"Default\" : uic . loadUi ( \"./src/gui/default_vis.ui\" , self ) self . charts [ \"arrayMap\" ] = self . arrayMap setupArrayMap ( self . charts [ \"arrayMap\" ]) self . charts [ \"arrayMapHover\" ] = HoverRegion ( self . charts [ \"arrayMap\" ], self . showArrayLocOnStatusBar , self . setMiniMapLoc ) self . charts [ \"miniMap\" ] = self . miniMap setupMiniMapPlot ( self . charts [ \"miniMap\" ]) self . charts [ \"spikeRatePlot\" ] = self . spikeRatePlot setupSpikeRatePlot ( self . charts [ \"spikeRatePlot\" ]) self . charts [ \"noiseHistogram\" ] = self . noiseHistogram setupNoiseHistogram ( self . charts [ \"noiseHistogram\" ]) self . charts [ \"channelTraceVerticalLayout\" ] = self . channelTraceVerticalLayout self . charts [ \"channelTrace1\" ] = self . channelTrace1 self . charts [ \"channelTrace2\" ] = self . channelTrace2 self . charts [ \"channelTrace3\" ] = self . channelTrace3 self . charts [ \"channelTrace4\" ] = self . channelTrace4 setupSpikeTrace ( self . channelTrace1 , self . channelTrace2 , self . channelTrace3 , self . channelTrace4 ) elif self . settings [ \"visStyle\" ] == \"Spike Search\" : uic . loadUi ( \"./src/gui/spikefinding_vis.ui\" , self ) self . charts [ \"ResetButton\" ] = self . ResetButton self . charts [ \"nextFigButton\" ] = self . nextFigButton self . charts [ \"yScaleButton\" ] = self . yScaleButton self . charts [ \"backButton\" ] = self . BackButton self . charts [ \"nextButton\" ] = self . Next self . charts [ \"atTimeWindowButton\" ] = self . atTimeWindowButton self . charts [ \"spikeTraces\" ] = [[], [], [], [], [], []] for i in range ( 1 , 7 ): for j in range ( 1 , 7 ): chart_name = \"r\" + str ( i ) + \"c\" + str ( j ) self . charts [ chart_name ] = eval ( \"self.\" + chart_name ) setupOneSpikeTrace ( self . charts [ chart_name ]) elif self . settings [ \"visStyle\" ] == \"Noise\" : uic . loadUi ( \"./src/gui/noise_check_vis.ui\" , self ) self . charts [ \"arrayMap\" ] = self . arrayMap setupArrayMap ( self . charts [ \"arrayMap\" ]) self . charts [ \"arrayMapHover\" ] = HoverRegion ( self . charts [ \"arrayMap\" ], self . showArrayLocOnStatusBar , self . setMiniMapLoc ) self . charts [ \"noiseHistogram\" ] = self . noiseHistogramPlot setupNoiseHistogram ( self . charts [ \"noiseHistogram\" ]) self . charts [ \"noiseMatrixPlot\" ] = self . noiseMatrixPlot self . charts [ \"channelTraceVerticalLayout\" ] = self . channelTraceLayout self . charts [ \"channelTrace1\" ] = self . channelTrace1 self . charts [ \"channelTrace2\" ] = self . channelTrace2 self . charts [ \"channelTrace3\" ] = self . channelTrace3 self . charts [ \"channelTrace4\" ] = self . channelTrace4 setupSpikeTrace ( self . channelTrace1 , self . channelTrace2 , self . channelTrace3 , self . channelTrace4 ) else : sys . exit () print ( \"else\" ) self . setupInteractivity () # just sets background to white TODO make this cleaner self . toggleDarkMode () self . toggleDarkMode () def showArrayLocOnStatusBar ( self , x , y ): int_x = int ( x ) int_y = int ( y ) if - 1 <= int_x < 31 and - 1 <= int_y < 31 : self . statusBar () . showMessage ( \"Array Map Spike Average @ \" + str ( int_y ) + \", \" + str ( int_x ) + \": \" + str ( self . LoadedData . array_stats [ 'spike_avg' ][ int_y + 1 ][ int_x + 1 ]) ) def setMiniMapLoc ( self , x , y ): print ( \"setMiniMapLoc\" ) print ( x , y ) self . center_row = int ( x ) if self . center_row < 6 : self . center_row = 6 elif self . center_row > 26 : self . center_row = 26 if self . center_col < 4 : self . center_col = 4 elif self . center_col > 29 : self . center_col = 29 self . center_col = int ( y ) self . updateMiniMapPlot () def setupInteractivity ( self ): self . LoadedData = DC1DataContainer () # class for holding and manipulating data print ( \"setupinteractivity\" , self . settings [ \"spikeThreshold\" ]) self . LoadedData . setSpikeThreshold ( self . settings [ \"spikeThreshold\" ]) # Set up PyQt multithreading self . threadpool = QThreadPool () print ( \"Multithreading with maximum %d threads\" % self . threadpool . maxThreadCount ()) # >>>> MENU BAR <<<<< # TODO hook up interactivity for all menu bar buttons # >> FILE BUTTON self . action_npz . triggered . connect ( self . onActionLoadNPZ ) self . action_mat . triggered . connect ( self . onActionLoadMAT ) self . actionUpdateSession . triggered . connect ( self . onLoadRealtimeStream ) self . actionIndividualChannelInfo . triggered . connect ( self . viewNewIndividalChannelInformation ) self . actionListElectrodesInfo . triggered . connect ( self . viewChannelListInformation ) self . actionAnalysisParameters . triggered . connect ( self . viewGUIPreferences ) def viewNewIndividalChannelInformation ( self ): from ..gui.gui_individualchannel import IndividualChannelInformation new_window = IndividualChannelInformation () new_window . label = QLabel ( \"Individual Channel Analysis\" ) new_window . setSessionParent ( self ) new_window . show () new_window . exec () self . external_windows . append ( new_window ) def viewChannelListInformation ( self ): from ..gui.gui_electrodelist import ElectrodeListInformation new_window = ElectrodeListInformation () new_window . label = QLabel ( \"Electrode List Analysis\" ) new_window . setSessionParent ( self ) new_window . show () new_window . exec () self . external_windows . append ( new_window ) def viewGUIPreferences ( self ): from ..gui.gui_sessionparameters import GUIPreferences new_window = GUIPreferences () new_window . label = QLabel ( \"GUI Preferences\" ) new_window . show () new_window . exec () self . external_windows . append ( new_window ) def toggleDarkMode ( self ): self . is_dark_mode = not self . is_dark_mode if self . is_dark_mode is True : color = 'k' else : color = 'w' for chart in self . charts . keys (): chart_type = type ( self . charts [ chart ]) if str ( chart_type ) == \"<class 'pyqtgraph.widgets.PlotWidget.PlotWidget'>\" : self . charts [ chart ] . setBackground ( color ) \"\"\" ======================= MULTITHREADING PROGRESS FUNCS ======================= \"\"\" def progress_fn ( self , n ): print ( \" %d%% done\" % n ) def print_output ( self , s ): print ( s ) def thread_complete ( self ): print ( \"THREAD COMPLETE!\" ) \"\"\" ======================= MENU BAR // FILE... ======================= \"\"\" def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path def loadSession ( self ): if self . settings [ \"path\" ] == \"\" : raise ValueError ( \"Path is not specified!\" ) if self . settings [ 'realTime' ] == \"Yes, load first .mat chunk\" : self . onLoadRealtimeStream ( load_from_beginning = True ) elif self . settings [ 'realTime' ] == \"Yes, load latest .mat chunk\" : self . onLoadRealtimeStream ( load_from_beginning = False ) elif self . settings [ 'realTime' ] == \"No, load raw .mat file\" : #TODO parallelize self . onLoadRealTimeStraet ( load_from_beginning = True ) elif self . settings [ 'realTime' ] == \"No, load pre-processed .npz file\" : #TODO self . onActionLoadNPZ () elif self . settings [ 'realTime' ] == \"No, load filtered .npz file\" : #TODO self . onActionLoadNPZ () else : raise ValueError ( \"this should not be possible\" ) # (1) Yes, load first .mat chunk & (2) Yes, load latest .mat chunk def onLoadRealtimeStream ( self , load_from_beginning = True ): self . loading_dict = initDataLoading ( self . settings [ \"path\" ]) # TODO parallelize loading already saved .mat files load_realtime_worker = Worker ( self . realtimeLoading , self . settings [ \"path\" ], self . loading_dict , load_from_beginning ) load_realtime_worker . signals . progress . connect ( self . updateStatusBar ) load_realtime_worker . signals . gui_callback . connect ( self . updateGUIWithNewData ) self . threadpool . start ( load_realtime_worker ) # TODO (3) No, load raw .mat file # parallelize this faster # TODO (4) No, load pre-processed .npz file def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) self . loading_dict [ \"path\" ] = path data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData () # TODO (5) No, load filtered .npz file # callback from progress signal def updateStatusBar ( self , message ): self . statusBar () . showMessage ( message ) # Continuously Check for New Data def realtimeLoading ( self , path , loadingDict , load_from_beginning , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] if load_from_beginning : last_file_idx = 0 else : last_file_idx = loadingDict [ \"num_of_buf\" ] - 2 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'appendRawData' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filterData' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculateArrayStats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit () def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict ) def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = self . settings [ \"filter\" ]) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData () def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" print ( \"Update GUI with new data()\" ) self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession for window in self . external_windows : window . update () for chart in self . charts . keys (): chart_type = type ( self . charts [ chart ]) if str ( chart_type ) == \"<class 'pyqtgraph.widgets.PlotWidget.PlotWidget'>\" : start = time . time () self . chart_update_function_mapping [ chart ]() end = time . time () self . profile_data [ chart ] . append ( end - start ) if self . mode_profiling : self . printProfilingData () def printProfilingData ( self ): print ( \"------------------------------\" ) print ( \"Current profiling statistics:\" ) for key in self . profile_data . keys (): avg_time = np . round ( np . mean ( self . profile_data [ key ]), 3 ) print ( key , avg_time ) print ( \"------------------------------\" ) def updateArrayMapPlot ( self ): self . charts [ \"arrayMap\" ] . clear () if self . first_time_plotting is False : colors = self . LoadedData . array_stats [ 'spike_avg' ] data = colors . T # for old pixel-based data max_dot = 100 # AX1) Size by Number of Samples spike_cnt = self . LoadedData . array_stats [ 'spike_cnt' ] scale1 = ( max_dot - 15 ) / ( np . max ( spike_cnt ) - np . min ( spike_cnt [ spike_cnt != 0 ])) b_add = max_dot - ( np . max ( spike_cnt ) * scale1 ) size = np . round ( spike_cnt * scale1 + b_add ) size [ size < 15 ] = 10 # TODO fix saturation point else : data = np . fromfunction ( lambda i , j : ( 1 + 0.01 * np . sin ( i )) * ( i ) ** 1 + ( j ) ** 1 , ( 32 , 32 )) data = data * ( 1 + 0.001 * np . random . random ( data . shape )) cm = pg . colormap . get ( 'CET-L9' ) image = pg . ImageItem ( data ) self . charts [ \"arrayMap\" ] . addItem ( image ) # bound the LinearRegionItem to the plotted data self . charts [ \"arrayMapHover\" ] . region . setClipItem ( image ) if self . arrayMap_colorbar is None : self . arrayMap_colorbar = self . charts [ \"arrayMap\" ] . addColorBar ( image , colorMap = cm , values = ( 0 , 150 )) #values=(0, np.max(data))) self . arrayMap_colorbar . sigLevelsChanged . connect ( self . colorBarLevelsChanged ) else : self . arrayMap_colorbar . setImageItem ( image ) #self.charts[\"arrayMap\"]_colorbar.setLevels((0, np.max(data))) # Set pxMode=False to allow spots to transform with the view scatter = pg . ScatterPlotItem ( pxMode = False ) # creating empty list for spots spots = [] # color modulated by amplitude cmap = plt . cm . get_cmap ( \"jet\" ) for i in range ( 32 ): for j in range ( 32 ): # creating spot position which get updated after each iteration # of color which also get updated if self . first_time_plotting is True : spot_dic = { 'pos' : ( i , j ), 'size' : 0 , 'pen' : { 'color' : 'w' , 'width' : 1 }, 'brush' : pg . intColor ( 1 , 100 )} else : color_map = self . arrayMap_colorbar . colorMap () levels = self . arrayMap_colorbar . levels () value = colors [ i , j ] if value < levels [ 0 ]: value = levels [ 0 ] elif value > levels [ 1 ]: value = levels [ 1 ] adjusted_value = ( value - levels [ 0 ]) / ( levels [ 1 ] - levels [ 0 ]) color_indicator = color_map . map ( adjusted_value ) spot_dic = { 'pos' : ( j , i ), 'size' : size [ i , j ] / 60 , 'pen' : { 'color' : 'w' , 'width' : size [ i , j ] / 60 }, 'brush' : pg . mkColor ( color_indicator )} # TODO fix coloring # used to be 'brush': pg.intColor(color_indicator, 100) # adding spot_dic in the list of spots spots . append ( spot_dic ) self . first_time_plotting = False self . charts [ \"arrayMap\" ] . clear () scatter . addPoints ( spots ) # adding spots to the scatter plot self . charts [ \"arrayMap\" ] . addItem ( scatter ) # adding scatter plot to the plot window def colorBarLevelsChanged ( self ): self . charts [ \"arrayMap\" ] . clear () colors = self . LoadedData . array_stats [ 'spike_avg' ] data = colors . T # for old pixel-based data max_dot = 100 # AX1) Size by Number of Samples spike_cnt = self . LoadedData . array_stats [ 'spike_cnt' ] scale1 = ( max_dot - 15 ) / ( np . max ( spike_cnt ) - np . min ( spike_cnt [ spike_cnt != 0 ])) b_add = max_dot - ( np . max ( spike_cnt ) * scale1 ) size = np . round ( spike_cnt * scale1 + b_add ) size [ size < 15 ] = 10 # TODO fix saturation point # Set pxMode=False to allow spots to transform with the view scatter = pg . ScatterPlotItem ( pxMode = False ) # creating empty list for spots spots = [] # color modulated by amplitude cmap = plt . cm . get_cmap ( \"jet\" ) for i in range ( 32 ): for j in range ( 32 ): # creating spot position which get updated after each iteration # of color which also get updated if self . first_time_plotting is True : spot_dic = { 'pos' : ( i , j ), 'size' : random . random () * 0.5 + 0.5 , 'pen' : { 'color' : 'w' , 'width' : 2 }, 'brush' : pg . intColor ( i * 10 + j , 100 )} else : color_map = self . arrayMap_colorbar . colorMap () levels = self . arrayMap_colorbar . levels () value = colors [ i , j ] if value < levels [ 0 ]: value = levels [ 0 ] elif value > levels [ 1 ]: value = levels [ 1 ] adjusted_value = ( value - levels [ 0 ]) / ( levels [ 1 ] - levels [ 0 ]) color_indicator = color_map . map ( adjusted_value ) spot_dic = { 'pos' : ( j , i ), 'size' : size [ i , j ] / 60 , 'pen' : { 'color' : 'w' , 'width' : size [ i , j ] / 60 }, 'brush' : pg . mkColor ( color_indicator )} # TODO fix coloring # used to be 'brush': pg.intColor(color_indicator, 100) # adding spot_dic in the list of spots spots . append ( spot_dic ) self . charts [ \"arrayMap\" ] . clear () scatter . addPoints ( spots ) # adding spots to the scatter plot self . charts [ \"arrayMap\" ] . addItem ( scatter ) # adding scatter plot to the plot window def updateChannelTracePlot ( self ): trace_plots = [ self . channelTrace1 , self . channelTrace2 , self . channelTrace3 , self . channelTrace4 ] len_data = len ( self . LoadedData . filtered_data ) # Generate subplots for m , plt in enumerate ( trace_plots ): chan_idx = len_data + ( m - 4 ) x = self . LoadedData . filtered_data [ chan_idx ][ 'times' ] y = self . LoadedData . filtered_data [ chan_idx ][ 'data' ] plt . clear () plt . plot ( x , y , pen = 'b' ) plt . setLabel ( 'left' , '#' + str ( self . LoadedData . filtered_data [ chan_idx ][ 'channel_idx' ])) plt . enableAutoRange ( axis = 'y' ) plt . setAutoVisible ( y = True ) def updateSpikeRatePlot ( self ): self . charts [ \"spikeRatePlot\" ] . clear () vals = self . LoadedData . array_stats [ 'noise_std' ] vals = vals [ np . nonzero ( vals )] # get nonzero vals because zeros have not had noise calculation done yet y , x = np . histogram ( vals , bins = np . linspace ( 0 , 20 , 40 )) curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . charts [ \"spikeRatePlot\" ] . addItem ( curve ) def updateNoiseHistogramPlot ( self ): self . charts [ \"noiseHistogram\" ] . clear () if self . LoadedData is not None : avg_spike_rate_times = self . LoadedData . array_stats [ \"array spike rate times\" ] x = np . cumsum ( avg_spike_rate_times ) y = self . LoadedData . array_stats [ \"array spike rate\" ] line_plot = self . charts [ \"noiseHistogram\" ] . plot ( x , y , pen = 'b' , symbol = 'o' , symbolPen = 'b' , symbolBrush = 0.2 ) def updateMiniMapPlot ( self ): self . charts [ \"miniMap\" ] . clear () print ( 'update minimap plot:' , self . center_row , self . center_col ) for row in range ( self . center_row - 4 , self . center_row + 4 ): for col in range ( self . center_col - 2 , self . center_col + 2 ): print ( 'r' , row , 'c' , col ) spike_indicator_base = pg . QtGui . QGraphicsRectItem ( row * 5 , col * 5 , 4 , 0.2 ) spike_indicator_base . setPen ( pg . mkPen (( 0 , 0 , 0 , 100 ))) spike_indicator_base . setBrush ( pg . mkBrush (( 50 , 50 , 200 ))) elec_idx = str ( map2idx ( col , row )) spike_indicator_text = pg . TextItem ( elec_idx , 'k' , anchor = ( 0 , 0 )) spike_indicator_text . setPos ( row * 5 , col * 5 ) spike_indicator_text . setParentItem ( spike_indicator_base ) #times = [0, 1, 3, 5, 10, 11, 14] if np . random . random () > 0.5 : times = np . random . randint ( 0 , 20 , ( 3 ,), dtype = 'int64' ) for i in times : spike_indicator = pg . QtGui . QGraphicsRectItem ( row * 5 + i / 5 , col * 5 , 0.1 , 1.5 ) spike_indicator . setPen ( pg . mkPen (( 0 , 0 , 0 , 100 ))) spike_indicator . setBrush ( pg . mkBrush (( 50 , 50 , 200 ))) spike_indicator . setParentItem ( spike_indicator_base ) self . charts [ \"miniMap\" ] . addItem ( spike_indicator ) self . charts [ \"miniMap\" ] . addItem ( spike_indicator_base ) self . charts [ \"miniMap\" ] . addItem ( spike_indicator_text ) getDataPath ( self , file_type ) Parameters: Name Type Description Default file_type str required Source code in app/src/gui/gui_base.py def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path loadDataFromFileMat ( self , path , loadingDict ) Parameters: Name Type Description Default path required loadingDict required Source code in app/src/gui/gui_base.py def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = self . settings [ \"filter\" ]) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData () onActionLoadMAT ( self ) Source code in app/src/gui/gui_base.py def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict ) onActionLoadNPZ ( self ) Source code in app/src/gui/gui_base.py def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) self . loading_dict [ \"path\" ] = path data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData () realtimeLoading ( self , path , loadingDict , load_from_beginning , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ) Parameters: Name Type Description Default path required loadingDict required progress_callback required gui_callback required dataIdentifierString 'gmem1' Source code in app/src/gui/gui_base.py def realtimeLoading ( self , path , loadingDict , load_from_beginning , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] if load_from_beginning : last_file_idx = 0 else : last_file_idx = loadingDict [ \"num_of_buf\" ] - 2 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'appendRawData' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filterData' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculateArrayStats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit () updateGUIWithNewData ( self ) Source code in app/src/gui/gui_base.py def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" print ( \"Update GUI with new data()\" ) self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession for window in self . external_windows : window . update () for chart in self . charts . keys (): chart_type = type ( self . charts [ chart ]) if str ( chart_type ) == \"<class 'pyqtgraph.widgets.PlotWidget.PlotWidget'>\" : start = time . time () self . chart_update_function_mapping [ chart ]() end = time . time () self . profile_data [ chart ] . append ( end - start ) if self . mode_profiling : self . printProfilingData ()","title":"Base"},{"location":"gui-base/#gui-base-class","text":"Huy Nguyen (2022) Contains the base app framework for loading up the GUI. Note: To regenerate gui_layout.py, in terminal do pyuic5 layout.ui -o gui_layout.py","title":"GUI Base Class"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow","text":"Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. Source code in app/src/gui/gui_base.py class MainWindow ( QtWidgets . QMainWindow , Ui_mainWindow ): \"\"\" Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. \"\"\" # MODES mode_profiling = True mode_multithreading = True first_time_plotting = True is_dark_mode = False # Program State settings = {} loading_dict = {} LoadedData = None # Raw data stream from chip, only double/triple/etc. counts removed profile_data = None charts , chart_update_function_mapping = None , None external_windows = [] # Misc p = None center_row , center_col = 16 , 16 # for Mini Map arrayMap_colorbar = None def __init__ ( self , * args , ** kwargs ): super ( MainWindow , self ) . __init__ ( * args , ** kwargs ) self . charts = { \"arrayMap\" : None , \"miniMap\" : None , \"spikeRatePlot\" : None , \"noiseHistogram\" : None , \"channelTraceVerticalLayout\" : None , \"channelTrace1\" : None , \"channelTrace2\" : None , \"channelTrace3\" : None , \"channelTrace4\" : None } self . chart_update_function_mapping = { \"arrayMap\" : self . updateArrayMapPlot , \"miniMap\" : self . updateMiniMapPlot , \"spikeRatePlot\" : self . updateSpikeRatePlot , \"noiseHistogram\" : self . updateNoiseHistogramPlot , \"channelTrace1\" : self . updateChannelTracePlot , \"channelTrace2\" : self . updateChannelTracePlot , \"channelTrace3\" : self . updateChannelTracePlot , \"channelTrace4\" : self . updateChannelTracePlot } if self . mode_profiling : self . profile_data = { 'appendRawData' : [], 'filterData' : [], 'calculateArrayStats' : [], 'arrayMap' : [], 'channelTrace' : [], 'noiseHistogram' : [], 'spikeRatePlot' : [], 'miniMap' : [], 'channelTrace1' : [], 'channelTrace2' : [], 'channelTrace3' : [], 'channelTrace4' : [] } if self . mode_multithreading : print ( 'GUI is multithreading' ) def setSettings ( self , settings ): self . settings = settings def setupLayout ( self ): print ( \"Session settings: \" + str ( self . settings )) # Load layout based on QtDesigner .ui file if self . settings [ \"visStyle\" ] == \"Default\" : uic . loadUi ( \"./src/gui/default_vis.ui\" , self ) self . charts [ \"arrayMap\" ] = self . arrayMap setupArrayMap ( self . charts [ \"arrayMap\" ]) self . charts [ \"arrayMapHover\" ] = HoverRegion ( self . charts [ \"arrayMap\" ], self . showArrayLocOnStatusBar , self . setMiniMapLoc ) self . charts [ \"miniMap\" ] = self . miniMap setupMiniMapPlot ( self . charts [ \"miniMap\" ]) self . charts [ \"spikeRatePlot\" ] = self . spikeRatePlot setupSpikeRatePlot ( self . charts [ \"spikeRatePlot\" ]) self . charts [ \"noiseHistogram\" ] = self . noiseHistogram setupNoiseHistogram ( self . charts [ \"noiseHistogram\" ]) self . charts [ \"channelTraceVerticalLayout\" ] = self . channelTraceVerticalLayout self . charts [ \"channelTrace1\" ] = self . channelTrace1 self . charts [ \"channelTrace2\" ] = self . channelTrace2 self . charts [ \"channelTrace3\" ] = self . channelTrace3 self . charts [ \"channelTrace4\" ] = self . channelTrace4 setupSpikeTrace ( self . channelTrace1 , self . channelTrace2 , self . channelTrace3 , self . channelTrace4 ) elif self . settings [ \"visStyle\" ] == \"Spike Search\" : uic . loadUi ( \"./src/gui/spikefinding_vis.ui\" , self ) self . charts [ \"ResetButton\" ] = self . ResetButton self . charts [ \"nextFigButton\" ] = self . nextFigButton self . charts [ \"yScaleButton\" ] = self . yScaleButton self . charts [ \"backButton\" ] = self . BackButton self . charts [ \"nextButton\" ] = self . Next self . charts [ \"atTimeWindowButton\" ] = self . atTimeWindowButton self . charts [ \"spikeTraces\" ] = [[], [], [], [], [], []] for i in range ( 1 , 7 ): for j in range ( 1 , 7 ): chart_name = \"r\" + str ( i ) + \"c\" + str ( j ) self . charts [ chart_name ] = eval ( \"self.\" + chart_name ) setupOneSpikeTrace ( self . charts [ chart_name ]) elif self . settings [ \"visStyle\" ] == \"Noise\" : uic . loadUi ( \"./src/gui/noise_check_vis.ui\" , self ) self . charts [ \"arrayMap\" ] = self . arrayMap setupArrayMap ( self . charts [ \"arrayMap\" ]) self . charts [ \"arrayMapHover\" ] = HoverRegion ( self . charts [ \"arrayMap\" ], self . showArrayLocOnStatusBar , self . setMiniMapLoc ) self . charts [ \"noiseHistogram\" ] = self . noiseHistogramPlot setupNoiseHistogram ( self . charts [ \"noiseHistogram\" ]) self . charts [ \"noiseMatrixPlot\" ] = self . noiseMatrixPlot self . charts [ \"channelTraceVerticalLayout\" ] = self . channelTraceLayout self . charts [ \"channelTrace1\" ] = self . channelTrace1 self . charts [ \"channelTrace2\" ] = self . channelTrace2 self . charts [ \"channelTrace3\" ] = self . channelTrace3 self . charts [ \"channelTrace4\" ] = self . channelTrace4 setupSpikeTrace ( self . channelTrace1 , self . channelTrace2 , self . channelTrace3 , self . channelTrace4 ) else : sys . exit () print ( \"else\" ) self . setupInteractivity () # just sets background to white TODO make this cleaner self . toggleDarkMode () self . toggleDarkMode () def showArrayLocOnStatusBar ( self , x , y ): int_x = int ( x ) int_y = int ( y ) if - 1 <= int_x < 31 and - 1 <= int_y < 31 : self . statusBar () . showMessage ( \"Array Map Spike Average @ \" + str ( int_y ) + \", \" + str ( int_x ) + \": \" + str ( self . LoadedData . array_stats [ 'spike_avg' ][ int_y + 1 ][ int_x + 1 ]) ) def setMiniMapLoc ( self , x , y ): print ( \"setMiniMapLoc\" ) print ( x , y ) self . center_row = int ( x ) if self . center_row < 6 : self . center_row = 6 elif self . center_row > 26 : self . center_row = 26 if self . center_col < 4 : self . center_col = 4 elif self . center_col > 29 : self . center_col = 29 self . center_col = int ( y ) self . updateMiniMapPlot () def setupInteractivity ( self ): self . LoadedData = DC1DataContainer () # class for holding and manipulating data print ( \"setupinteractivity\" , self . settings [ \"spikeThreshold\" ]) self . LoadedData . setSpikeThreshold ( self . settings [ \"spikeThreshold\" ]) # Set up PyQt multithreading self . threadpool = QThreadPool () print ( \"Multithreading with maximum %d threads\" % self . threadpool . maxThreadCount ()) # >>>> MENU BAR <<<<< # TODO hook up interactivity for all menu bar buttons # >> FILE BUTTON self . action_npz . triggered . connect ( self . onActionLoadNPZ ) self . action_mat . triggered . connect ( self . onActionLoadMAT ) self . actionUpdateSession . triggered . connect ( self . onLoadRealtimeStream ) self . actionIndividualChannelInfo . triggered . connect ( self . viewNewIndividalChannelInformation ) self . actionListElectrodesInfo . triggered . connect ( self . viewChannelListInformation ) self . actionAnalysisParameters . triggered . connect ( self . viewGUIPreferences ) def viewNewIndividalChannelInformation ( self ): from ..gui.gui_individualchannel import IndividualChannelInformation new_window = IndividualChannelInformation () new_window . label = QLabel ( \"Individual Channel Analysis\" ) new_window . setSessionParent ( self ) new_window . show () new_window . exec () self . external_windows . append ( new_window ) def viewChannelListInformation ( self ): from ..gui.gui_electrodelist import ElectrodeListInformation new_window = ElectrodeListInformation () new_window . label = QLabel ( \"Electrode List Analysis\" ) new_window . setSessionParent ( self ) new_window . show () new_window . exec () self . external_windows . append ( new_window ) def viewGUIPreferences ( self ): from ..gui.gui_sessionparameters import GUIPreferences new_window = GUIPreferences () new_window . label = QLabel ( \"GUI Preferences\" ) new_window . show () new_window . exec () self . external_windows . append ( new_window ) def toggleDarkMode ( self ): self . is_dark_mode = not self . is_dark_mode if self . is_dark_mode is True : color = 'k' else : color = 'w' for chart in self . charts . keys (): chart_type = type ( self . charts [ chart ]) if str ( chart_type ) == \"<class 'pyqtgraph.widgets.PlotWidget.PlotWidget'>\" : self . charts [ chart ] . setBackground ( color ) \"\"\" ======================= MULTITHREADING PROGRESS FUNCS ======================= \"\"\" def progress_fn ( self , n ): print ( \" %d%% done\" % n ) def print_output ( self , s ): print ( s ) def thread_complete ( self ): print ( \"THREAD COMPLETE!\" ) \"\"\" ======================= MENU BAR // FILE... ======================= \"\"\" def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path def loadSession ( self ): if self . settings [ \"path\" ] == \"\" : raise ValueError ( \"Path is not specified!\" ) if self . settings [ 'realTime' ] == \"Yes, load first .mat chunk\" : self . onLoadRealtimeStream ( load_from_beginning = True ) elif self . settings [ 'realTime' ] == \"Yes, load latest .mat chunk\" : self . onLoadRealtimeStream ( load_from_beginning = False ) elif self . settings [ 'realTime' ] == \"No, load raw .mat file\" : #TODO parallelize self . onLoadRealTimeStraet ( load_from_beginning = True ) elif self . settings [ 'realTime' ] == \"No, load pre-processed .npz file\" : #TODO self . onActionLoadNPZ () elif self . settings [ 'realTime' ] == \"No, load filtered .npz file\" : #TODO self . onActionLoadNPZ () else : raise ValueError ( \"this should not be possible\" ) # (1) Yes, load first .mat chunk & (2) Yes, load latest .mat chunk def onLoadRealtimeStream ( self , load_from_beginning = True ): self . loading_dict = initDataLoading ( self . settings [ \"path\" ]) # TODO parallelize loading already saved .mat files load_realtime_worker = Worker ( self . realtimeLoading , self . settings [ \"path\" ], self . loading_dict , load_from_beginning ) load_realtime_worker . signals . progress . connect ( self . updateStatusBar ) load_realtime_worker . signals . gui_callback . connect ( self . updateGUIWithNewData ) self . threadpool . start ( load_realtime_worker ) # TODO (3) No, load raw .mat file # parallelize this faster # TODO (4) No, load pre-processed .npz file def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) self . loading_dict [ \"path\" ] = path data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData () # TODO (5) No, load filtered .npz file # callback from progress signal def updateStatusBar ( self , message ): self . statusBar () . showMessage ( message ) # Continuously Check for New Data def realtimeLoading ( self , path , loadingDict , load_from_beginning , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] if load_from_beginning : last_file_idx = 0 else : last_file_idx = loadingDict [ \"num_of_buf\" ] - 2 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'appendRawData' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filterData' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculateArrayStats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit () def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict ) def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = self . settings [ \"filter\" ]) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData () def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" print ( \"Update GUI with new data()\" ) self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession for window in self . external_windows : window . update () for chart in self . charts . keys (): chart_type = type ( self . charts [ chart ]) if str ( chart_type ) == \"<class 'pyqtgraph.widgets.PlotWidget.PlotWidget'>\" : start = time . time () self . chart_update_function_mapping [ chart ]() end = time . time () self . profile_data [ chart ] . append ( end - start ) if self . mode_profiling : self . printProfilingData () def printProfilingData ( self ): print ( \"------------------------------\" ) print ( \"Current profiling statistics:\" ) for key in self . profile_data . keys (): avg_time = np . round ( np . mean ( self . profile_data [ key ]), 3 ) print ( key , avg_time ) print ( \"------------------------------\" ) def updateArrayMapPlot ( self ): self . charts [ \"arrayMap\" ] . clear () if self . first_time_plotting is False : colors = self . LoadedData . array_stats [ 'spike_avg' ] data = colors . T # for old pixel-based data max_dot = 100 # AX1) Size by Number of Samples spike_cnt = self . LoadedData . array_stats [ 'spike_cnt' ] scale1 = ( max_dot - 15 ) / ( np . max ( spike_cnt ) - np . min ( spike_cnt [ spike_cnt != 0 ])) b_add = max_dot - ( np . max ( spike_cnt ) * scale1 ) size = np . round ( spike_cnt * scale1 + b_add ) size [ size < 15 ] = 10 # TODO fix saturation point else : data = np . fromfunction ( lambda i , j : ( 1 + 0.01 * np . sin ( i )) * ( i ) ** 1 + ( j ) ** 1 , ( 32 , 32 )) data = data * ( 1 + 0.001 * np . random . random ( data . shape )) cm = pg . colormap . get ( 'CET-L9' ) image = pg . ImageItem ( data ) self . charts [ \"arrayMap\" ] . addItem ( image ) # bound the LinearRegionItem to the plotted data self . charts [ \"arrayMapHover\" ] . region . setClipItem ( image ) if self . arrayMap_colorbar is None : self . arrayMap_colorbar = self . charts [ \"arrayMap\" ] . addColorBar ( image , colorMap = cm , values = ( 0 , 150 )) #values=(0, np.max(data))) self . arrayMap_colorbar . sigLevelsChanged . connect ( self . colorBarLevelsChanged ) else : self . arrayMap_colorbar . setImageItem ( image ) #self.charts[\"arrayMap\"]_colorbar.setLevels((0, np.max(data))) # Set pxMode=False to allow spots to transform with the view scatter = pg . ScatterPlotItem ( pxMode = False ) # creating empty list for spots spots = [] # color modulated by amplitude cmap = plt . cm . get_cmap ( \"jet\" ) for i in range ( 32 ): for j in range ( 32 ): # creating spot position which get updated after each iteration # of color which also get updated if self . first_time_plotting is True : spot_dic = { 'pos' : ( i , j ), 'size' : 0 , 'pen' : { 'color' : 'w' , 'width' : 1 }, 'brush' : pg . intColor ( 1 , 100 )} else : color_map = self . arrayMap_colorbar . colorMap () levels = self . arrayMap_colorbar . levels () value = colors [ i , j ] if value < levels [ 0 ]: value = levels [ 0 ] elif value > levels [ 1 ]: value = levels [ 1 ] adjusted_value = ( value - levels [ 0 ]) / ( levels [ 1 ] - levels [ 0 ]) color_indicator = color_map . map ( adjusted_value ) spot_dic = { 'pos' : ( j , i ), 'size' : size [ i , j ] / 60 , 'pen' : { 'color' : 'w' , 'width' : size [ i , j ] / 60 }, 'brush' : pg . mkColor ( color_indicator )} # TODO fix coloring # used to be 'brush': pg.intColor(color_indicator, 100) # adding spot_dic in the list of spots spots . append ( spot_dic ) self . first_time_plotting = False self . charts [ \"arrayMap\" ] . clear () scatter . addPoints ( spots ) # adding spots to the scatter plot self . charts [ \"arrayMap\" ] . addItem ( scatter ) # adding scatter plot to the plot window def colorBarLevelsChanged ( self ): self . charts [ \"arrayMap\" ] . clear () colors = self . LoadedData . array_stats [ 'spike_avg' ] data = colors . T # for old pixel-based data max_dot = 100 # AX1) Size by Number of Samples spike_cnt = self . LoadedData . array_stats [ 'spike_cnt' ] scale1 = ( max_dot - 15 ) / ( np . max ( spike_cnt ) - np . min ( spike_cnt [ spike_cnt != 0 ])) b_add = max_dot - ( np . max ( spike_cnt ) * scale1 ) size = np . round ( spike_cnt * scale1 + b_add ) size [ size < 15 ] = 10 # TODO fix saturation point # Set pxMode=False to allow spots to transform with the view scatter = pg . ScatterPlotItem ( pxMode = False ) # creating empty list for spots spots = [] # color modulated by amplitude cmap = plt . cm . get_cmap ( \"jet\" ) for i in range ( 32 ): for j in range ( 32 ): # creating spot position which get updated after each iteration # of color which also get updated if self . first_time_plotting is True : spot_dic = { 'pos' : ( i , j ), 'size' : random . random () * 0.5 + 0.5 , 'pen' : { 'color' : 'w' , 'width' : 2 }, 'brush' : pg . intColor ( i * 10 + j , 100 )} else : color_map = self . arrayMap_colorbar . colorMap () levels = self . arrayMap_colorbar . levels () value = colors [ i , j ] if value < levels [ 0 ]: value = levels [ 0 ] elif value > levels [ 1 ]: value = levels [ 1 ] adjusted_value = ( value - levels [ 0 ]) / ( levels [ 1 ] - levels [ 0 ]) color_indicator = color_map . map ( adjusted_value ) spot_dic = { 'pos' : ( j , i ), 'size' : size [ i , j ] / 60 , 'pen' : { 'color' : 'w' , 'width' : size [ i , j ] / 60 }, 'brush' : pg . mkColor ( color_indicator )} # TODO fix coloring # used to be 'brush': pg.intColor(color_indicator, 100) # adding spot_dic in the list of spots spots . append ( spot_dic ) self . charts [ \"arrayMap\" ] . clear () scatter . addPoints ( spots ) # adding spots to the scatter plot self . charts [ \"arrayMap\" ] . addItem ( scatter ) # adding scatter plot to the plot window def updateChannelTracePlot ( self ): trace_plots = [ self . channelTrace1 , self . channelTrace2 , self . channelTrace3 , self . channelTrace4 ] len_data = len ( self . LoadedData . filtered_data ) # Generate subplots for m , plt in enumerate ( trace_plots ): chan_idx = len_data + ( m - 4 ) x = self . LoadedData . filtered_data [ chan_idx ][ 'times' ] y = self . LoadedData . filtered_data [ chan_idx ][ 'data' ] plt . clear () plt . plot ( x , y , pen = 'b' ) plt . setLabel ( 'left' , '#' + str ( self . LoadedData . filtered_data [ chan_idx ][ 'channel_idx' ])) plt . enableAutoRange ( axis = 'y' ) plt . setAutoVisible ( y = True ) def updateSpikeRatePlot ( self ): self . charts [ \"spikeRatePlot\" ] . clear () vals = self . LoadedData . array_stats [ 'noise_std' ] vals = vals [ np . nonzero ( vals )] # get nonzero vals because zeros have not had noise calculation done yet y , x = np . histogram ( vals , bins = np . linspace ( 0 , 20 , 40 )) curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . charts [ \"spikeRatePlot\" ] . addItem ( curve ) def updateNoiseHistogramPlot ( self ): self . charts [ \"noiseHistogram\" ] . clear () if self . LoadedData is not None : avg_spike_rate_times = self . LoadedData . array_stats [ \"array spike rate times\" ] x = np . cumsum ( avg_spike_rate_times ) y = self . LoadedData . array_stats [ \"array spike rate\" ] line_plot = self . charts [ \"noiseHistogram\" ] . plot ( x , y , pen = 'b' , symbol = 'o' , symbolPen = 'b' , symbolBrush = 0.2 ) def updateMiniMapPlot ( self ): self . charts [ \"miniMap\" ] . clear () print ( 'update minimap plot:' , self . center_row , self . center_col ) for row in range ( self . center_row - 4 , self . center_row + 4 ): for col in range ( self . center_col - 2 , self . center_col + 2 ): print ( 'r' , row , 'c' , col ) spike_indicator_base = pg . QtGui . QGraphicsRectItem ( row * 5 , col * 5 , 4 , 0.2 ) spike_indicator_base . setPen ( pg . mkPen (( 0 , 0 , 0 , 100 ))) spike_indicator_base . setBrush ( pg . mkBrush (( 50 , 50 , 200 ))) elec_idx = str ( map2idx ( col , row )) spike_indicator_text = pg . TextItem ( elec_idx , 'k' , anchor = ( 0 , 0 )) spike_indicator_text . setPos ( row * 5 , col * 5 ) spike_indicator_text . setParentItem ( spike_indicator_base ) #times = [0, 1, 3, 5, 10, 11, 14] if np . random . random () > 0.5 : times = np . random . randint ( 0 , 20 , ( 3 ,), dtype = 'int64' ) for i in times : spike_indicator = pg . QtGui . QGraphicsRectItem ( row * 5 + i / 5 , col * 5 , 0.1 , 1.5 ) spike_indicator . setPen ( pg . mkPen (( 0 , 0 , 0 , 100 ))) spike_indicator . setBrush ( pg . mkBrush (( 50 , 50 , 200 ))) spike_indicator . setParentItem ( spike_indicator_base ) self . charts [ \"miniMap\" ] . addItem ( spike_indicator ) self . charts [ \"miniMap\" ] . addItem ( spike_indicator_base ) self . charts [ \"miniMap\" ] . addItem ( spike_indicator_text )","title":"MainWindow"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.getDataPath","text":"Parameters: Name Type Description Default file_type str required Source code in app/src/gui/gui_base.py def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path","title":"getDataPath()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.loadDataFromFileMat","text":"Parameters: Name Type Description Default path required loadingDict required Source code in app/src/gui/gui_base.py def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = self . settings [ \"filter\" ]) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData ()","title":"loadDataFromFileMat()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.onActionLoadMAT","text":"Source code in app/src/gui/gui_base.py def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict )","title":"onActionLoadMAT()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.onActionLoadNPZ","text":"Source code in app/src/gui/gui_base.py def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) self . loading_dict [ \"path\" ] = path data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData ()","title":"onActionLoadNPZ()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.realtimeLoading","text":"Parameters: Name Type Description Default path required loadingDict required progress_callback required gui_callback required dataIdentifierString 'gmem1' Source code in app/src/gui/gui_base.py def realtimeLoading ( self , path , loadingDict , load_from_beginning , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] if load_from_beginning : last_file_idx = 0 else : last_file_idx = loadingDict [ \"num_of_buf\" ] - 2 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'appendRawData' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filterData' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculateArrayStats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit ()","title":"realtimeLoading()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.updateGUIWithNewData","text":"Source code in app/src/gui/gui_base.py def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" print ( \"Update GUI with new data()\" ) self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession for window in self . external_windows : window . update () for chart in self . charts . keys (): chart_type = type ( self . charts [ chart ]) if str ( chart_type ) == \"<class 'pyqtgraph.widgets.PlotWidget.PlotWidget'>\" : start = time . time () self . chart_update_function_mapping [ chart ]() end = time . time () self . profile_data [ chart ] . append ( end - start ) if self . mode_profiling : self . printProfilingData () Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. Source code in app/src/gui/gui_base.py class MainWindow ( QtWidgets . QMainWindow , Ui_mainWindow ): \"\"\" Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. \"\"\" # MODES mode_profiling = True mode_multithreading = True first_time_plotting = True is_dark_mode = False # Program State settings = {} loading_dict = {} LoadedData = None # Raw data stream from chip, only double/triple/etc. counts removed profile_data = None charts , chart_update_function_mapping = None , None external_windows = [] # Misc p = None center_row , center_col = 16 , 16 # for Mini Map arrayMap_colorbar = None def __init__ ( self , * args , ** kwargs ): super ( MainWindow , self ) . __init__ ( * args , ** kwargs ) self . charts = { \"arrayMap\" : None , \"miniMap\" : None , \"spikeRatePlot\" : None , \"noiseHistogram\" : None , \"channelTraceVerticalLayout\" : None , \"channelTrace1\" : None , \"channelTrace2\" : None , \"channelTrace3\" : None , \"channelTrace4\" : None } self . chart_update_function_mapping = { \"arrayMap\" : self . updateArrayMapPlot , \"miniMap\" : self . updateMiniMapPlot , \"spikeRatePlot\" : self . updateSpikeRatePlot , \"noiseHistogram\" : self . updateNoiseHistogramPlot , \"channelTrace1\" : self . updateChannelTracePlot , \"channelTrace2\" : self . updateChannelTracePlot , \"channelTrace3\" : self . updateChannelTracePlot , \"channelTrace4\" : self . updateChannelTracePlot } if self . mode_profiling : self . profile_data = { 'appendRawData' : [], 'filterData' : [], 'calculateArrayStats' : [], 'arrayMap' : [], 'channelTrace' : [], 'noiseHistogram' : [], 'spikeRatePlot' : [], 'miniMap' : [], 'channelTrace1' : [], 'channelTrace2' : [], 'channelTrace3' : [], 'channelTrace4' : [] } if self . mode_multithreading : print ( 'GUI is multithreading' ) def setSettings ( self , settings ): self . settings = settings def setupLayout ( self ): print ( \"Session settings: \" + str ( self . settings )) # Load layout based on QtDesigner .ui file if self . settings [ \"visStyle\" ] == \"Default\" : uic . loadUi ( \"./src/gui/default_vis.ui\" , self ) self . charts [ \"arrayMap\" ] = self . arrayMap setupArrayMap ( self . charts [ \"arrayMap\" ]) self . charts [ \"arrayMapHover\" ] = HoverRegion ( self . charts [ \"arrayMap\" ], self . showArrayLocOnStatusBar , self . setMiniMapLoc ) self . charts [ \"miniMap\" ] = self . miniMap setupMiniMapPlot ( self . charts [ \"miniMap\" ]) self . charts [ \"spikeRatePlot\" ] = self . spikeRatePlot setupSpikeRatePlot ( self . charts [ \"spikeRatePlot\" ]) self . charts [ \"noiseHistogram\" ] = self . noiseHistogram setupNoiseHistogram ( self . charts [ \"noiseHistogram\" ]) self . charts [ \"channelTraceVerticalLayout\" ] = self . channelTraceVerticalLayout self . charts [ \"channelTrace1\" ] = self . channelTrace1 self . charts [ \"channelTrace2\" ] = self . channelTrace2 self . charts [ \"channelTrace3\" ] = self . channelTrace3 self . charts [ \"channelTrace4\" ] = self . channelTrace4 setupSpikeTrace ( self . channelTrace1 , self . channelTrace2 , self . channelTrace3 , self . channelTrace4 ) elif self . settings [ \"visStyle\" ] == \"Spike Search\" : uic . loadUi ( \"./src/gui/spikefinding_vis.ui\" , self ) self . charts [ \"ResetButton\" ] = self . ResetButton self . charts [ \"nextFigButton\" ] = self . nextFigButton self . charts [ \"yScaleButton\" ] = self . yScaleButton self . charts [ \"backButton\" ] = self . BackButton self . charts [ \"nextButton\" ] = self . Next self . charts [ \"atTimeWindowButton\" ] = self . atTimeWindowButton self . charts [ \"spikeTraces\" ] = [[], [], [], [], [], []] for i in range ( 1 , 7 ): for j in range ( 1 , 7 ): chart_name = \"r\" + str ( i ) + \"c\" + str ( j ) self . charts [ chart_name ] = eval ( \"self.\" + chart_name ) setupOneSpikeTrace ( self . charts [ chart_name ]) elif self . settings [ \"visStyle\" ] == \"Noise\" : uic . loadUi ( \"./src/gui/noise_check_vis.ui\" , self ) self . charts [ \"arrayMap\" ] = self . arrayMap setupArrayMap ( self . charts [ \"arrayMap\" ]) self . charts [ \"arrayMapHover\" ] = HoverRegion ( self . charts [ \"arrayMap\" ], self . showArrayLocOnStatusBar , self . setMiniMapLoc ) self . charts [ \"noiseHistogram\" ] = self . noiseHistogramPlot setupNoiseHistogram ( self . charts [ \"noiseHistogram\" ]) self . charts [ \"noiseMatrixPlot\" ] = self . noiseMatrixPlot self . charts [ \"channelTraceVerticalLayout\" ] = self . channelTraceLayout self . charts [ \"channelTrace1\" ] = self . channelTrace1 self . charts [ \"channelTrace2\" ] = self . channelTrace2 self . charts [ \"channelTrace3\" ] = self . channelTrace3 self . charts [ \"channelTrace4\" ] = self . channelTrace4 setupSpikeTrace ( self . channelTrace1 , self . channelTrace2 , self . channelTrace3 , self . channelTrace4 ) else : sys . exit () print ( \"else\" ) self . setupInteractivity () # just sets background to white TODO make this cleaner self . toggleDarkMode () self . toggleDarkMode () def showArrayLocOnStatusBar ( self , x , y ): int_x = int ( x ) int_y = int ( y ) if - 1 <= int_x < 31 and - 1 <= int_y < 31 : self . statusBar () . showMessage ( \"Array Map Spike Average @ \" + str ( int_y ) + \", \" + str ( int_x ) + \": \" + str ( self . LoadedData . array_stats [ 'spike_avg' ][ int_y + 1 ][ int_x + 1 ]) ) def setMiniMapLoc ( self , x , y ): print ( \"setMiniMapLoc\" ) print ( x , y ) self . center_row = int ( x ) if self . center_row < 6 : self . center_row = 6 elif self . center_row > 26 : self . center_row = 26 if self . center_col < 4 : self . center_col = 4 elif self . center_col > 29 : self . center_col = 29 self . center_col = int ( y ) self . updateMiniMapPlot () def setupInteractivity ( self ): self . LoadedData = DC1DataContainer () # class for holding and manipulating data print ( \"setupinteractivity\" , self . settings [ \"spikeThreshold\" ]) self . LoadedData . setSpikeThreshold ( self . settings [ \"spikeThreshold\" ]) # Set up PyQt multithreading self . threadpool = QThreadPool () print ( \"Multithreading with maximum %d threads\" % self . threadpool . maxThreadCount ()) # >>>> MENU BAR <<<<< # TODO hook up interactivity for all menu bar buttons # >> FILE BUTTON self . action_npz . triggered . connect ( self . onActionLoadNPZ ) self . action_mat . triggered . connect ( self . onActionLoadMAT ) self . actionUpdateSession . triggered . connect ( self . onLoadRealtimeStream ) self . actionIndividualChannelInfo . triggered . connect ( self . viewNewIndividalChannelInformation ) self . actionListElectrodesInfo . triggered . connect ( self . viewChannelListInformation ) self . actionAnalysisParameters . triggered . connect ( self . viewGUIPreferences ) def viewNewIndividalChannelInformation ( self ): from ..gui.gui_individualchannel import IndividualChannelInformation new_window = IndividualChannelInformation () new_window . label = QLabel ( \"Individual Channel Analysis\" ) new_window . setSessionParent ( self ) new_window . show () new_window . exec () self . external_windows . append ( new_window ) def viewChannelListInformation ( self ): from ..gui.gui_electrodelist import ElectrodeListInformation new_window = ElectrodeListInformation () new_window . label = QLabel ( \"Electrode List Analysis\" ) new_window . setSessionParent ( self ) new_window . show () new_window . exec () self . external_windows . append ( new_window ) def viewGUIPreferences ( self ): from ..gui.gui_sessionparameters import GUIPreferences new_window = GUIPreferences () new_window . label = QLabel ( \"GUI Preferences\" ) new_window . show () new_window . exec () self . external_windows . append ( new_window ) def toggleDarkMode ( self ): self . is_dark_mode = not self . is_dark_mode if self . is_dark_mode is True : color = 'k' else : color = 'w' for chart in self . charts . keys (): chart_type = type ( self . charts [ chart ]) if str ( chart_type ) == \"<class 'pyqtgraph.widgets.PlotWidget.PlotWidget'>\" : self . charts [ chart ] . setBackground ( color ) \"\"\" ======================= MULTITHREADING PROGRESS FUNCS ======================= \"\"\" def progress_fn ( self , n ): print ( \" %d%% done\" % n ) def print_output ( self , s ): print ( s ) def thread_complete ( self ): print ( \"THREAD COMPLETE!\" ) \"\"\" ======================= MENU BAR // FILE... ======================= \"\"\" def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path def loadSession ( self ): if self . settings [ \"path\" ] == \"\" : raise ValueError ( \"Path is not specified!\" ) if self . settings [ 'realTime' ] == \"Yes, load first .mat chunk\" : self . onLoadRealtimeStream ( load_from_beginning = True ) elif self . settings [ 'realTime' ] == \"Yes, load latest .mat chunk\" : self . onLoadRealtimeStream ( load_from_beginning = False ) elif self . settings [ 'realTime' ] == \"No, load raw .mat file\" : #TODO parallelize self . onLoadRealTimeStraet ( load_from_beginning = True ) elif self . settings [ 'realTime' ] == \"No, load pre-processed .npz file\" : #TODO self . onActionLoadNPZ () elif self . settings [ 'realTime' ] == \"No, load filtered .npz file\" : #TODO self . onActionLoadNPZ () else : raise ValueError ( \"this should not be possible\" ) # (1) Yes, load first .mat chunk & (2) Yes, load latest .mat chunk def onLoadRealtimeStream ( self , load_from_beginning = True ): self . loading_dict = initDataLoading ( self . settings [ \"path\" ]) # TODO parallelize loading already saved .mat files load_realtime_worker = Worker ( self . realtimeLoading , self . settings [ \"path\" ], self . loading_dict , load_from_beginning ) load_realtime_worker . signals . progress . connect ( self . updateStatusBar ) load_realtime_worker . signals . gui_callback . connect ( self . updateGUIWithNewData ) self . threadpool . start ( load_realtime_worker ) # TODO (3) No, load raw .mat file # parallelize this faster # TODO (4) No, load pre-processed .npz file def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) self . loading_dict [ \"path\" ] = path data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData () # TODO (5) No, load filtered .npz file # callback from progress signal def updateStatusBar ( self , message ): self . statusBar () . showMessage ( message ) # Continuously Check for New Data def realtimeLoading ( self , path , loadingDict , load_from_beginning , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] if load_from_beginning : last_file_idx = 0 else : last_file_idx = loadingDict [ \"num_of_buf\" ] - 2 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'appendRawData' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filterData' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculateArrayStats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit () def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict ) def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = self . settings [ \"filter\" ]) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData () def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" print ( \"Update GUI with new data()\" ) self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession for window in self . external_windows : window . update () for chart in self . charts . keys (): chart_type = type ( self . charts [ chart ]) if str ( chart_type ) == \"<class 'pyqtgraph.widgets.PlotWidget.PlotWidget'>\" : start = time . time () self . chart_update_function_mapping [ chart ]() end = time . time () self . profile_data [ chart ] . append ( end - start ) if self . mode_profiling : self . printProfilingData () def printProfilingData ( self ): print ( \"------------------------------\" ) print ( \"Current profiling statistics:\" ) for key in self . profile_data . keys (): avg_time = np . round ( np . mean ( self . profile_data [ key ]), 3 ) print ( key , avg_time ) print ( \"------------------------------\" ) def updateArrayMapPlot ( self ): self . charts [ \"arrayMap\" ] . clear () if self . first_time_plotting is False : colors = self . LoadedData . array_stats [ 'spike_avg' ] data = colors . T # for old pixel-based data max_dot = 100 # AX1) Size by Number of Samples spike_cnt = self . LoadedData . array_stats [ 'spike_cnt' ] scale1 = ( max_dot - 15 ) / ( np . max ( spike_cnt ) - np . min ( spike_cnt [ spike_cnt != 0 ])) b_add = max_dot - ( np . max ( spike_cnt ) * scale1 ) size = np . round ( spike_cnt * scale1 + b_add ) size [ size < 15 ] = 10 # TODO fix saturation point else : data = np . fromfunction ( lambda i , j : ( 1 + 0.01 * np . sin ( i )) * ( i ) ** 1 + ( j ) ** 1 , ( 32 , 32 )) data = data * ( 1 + 0.001 * np . random . random ( data . shape )) cm = pg . colormap . get ( 'CET-L9' ) image = pg . ImageItem ( data ) self . charts [ \"arrayMap\" ] . addItem ( image ) # bound the LinearRegionItem to the plotted data self . charts [ \"arrayMapHover\" ] . region . setClipItem ( image ) if self . arrayMap_colorbar is None : self . arrayMap_colorbar = self . charts [ \"arrayMap\" ] . addColorBar ( image , colorMap = cm , values = ( 0 , 150 )) #values=(0, np.max(data))) self . arrayMap_colorbar . sigLevelsChanged . connect ( self . colorBarLevelsChanged ) else : self . arrayMap_colorbar . setImageItem ( image ) #self.charts[\"arrayMap\"]_colorbar.setLevels((0, np.max(data))) # Set pxMode=False to allow spots to transform with the view scatter = pg . ScatterPlotItem ( pxMode = False ) # creating empty list for spots spots = [] # color modulated by amplitude cmap = plt . cm . get_cmap ( \"jet\" ) for i in range ( 32 ): for j in range ( 32 ): # creating spot position which get updated after each iteration # of color which also get updated if self . first_time_plotting is True : spot_dic = { 'pos' : ( i , j ), 'size' : 0 , 'pen' : { 'color' : 'w' , 'width' : 1 }, 'brush' : pg . intColor ( 1 , 100 )} else : color_map = self . arrayMap_colorbar . colorMap () levels = self . arrayMap_colorbar . levels () value = colors [ i , j ] if value < levels [ 0 ]: value = levels [ 0 ] elif value > levels [ 1 ]: value = levels [ 1 ] adjusted_value = ( value - levels [ 0 ]) / ( levels [ 1 ] - levels [ 0 ]) color_indicator = color_map . map ( adjusted_value ) spot_dic = { 'pos' : ( j , i ), 'size' : size [ i , j ] / 60 , 'pen' : { 'color' : 'w' , 'width' : size [ i , j ] / 60 }, 'brush' : pg . mkColor ( color_indicator )} # TODO fix coloring # used to be 'brush': pg.intColor(color_indicator, 100) # adding spot_dic in the list of spots spots . append ( spot_dic ) self . first_time_plotting = False self . charts [ \"arrayMap\" ] . clear () scatter . addPoints ( spots ) # adding spots to the scatter plot self . charts [ \"arrayMap\" ] . addItem ( scatter ) # adding scatter plot to the plot window def colorBarLevelsChanged ( self ): self . charts [ \"arrayMap\" ] . clear () colors = self . LoadedData . array_stats [ 'spike_avg' ] data = colors . T # for old pixel-based data max_dot = 100 # AX1) Size by Number of Samples spike_cnt = self . LoadedData . array_stats [ 'spike_cnt' ] scale1 = ( max_dot - 15 ) / ( np . max ( spike_cnt ) - np . min ( spike_cnt [ spike_cnt != 0 ])) b_add = max_dot - ( np . max ( spike_cnt ) * scale1 ) size = np . round ( spike_cnt * scale1 + b_add ) size [ size < 15 ] = 10 # TODO fix saturation point # Set pxMode=False to allow spots to transform with the view scatter = pg . ScatterPlotItem ( pxMode = False ) # creating empty list for spots spots = [] # color modulated by amplitude cmap = plt . cm . get_cmap ( \"jet\" ) for i in range ( 32 ): for j in range ( 32 ): # creating spot position which get updated after each iteration # of color which also get updated if self . first_time_plotting is True : spot_dic = { 'pos' : ( i , j ), 'size' : random . random () * 0.5 + 0.5 , 'pen' : { 'color' : 'w' , 'width' : 2 }, 'brush' : pg . intColor ( i * 10 + j , 100 )} else : color_map = self . arrayMap_colorbar . colorMap () levels = self . arrayMap_colorbar . levels () value = colors [ i , j ] if value < levels [ 0 ]: value = levels [ 0 ] elif value > levels [ 1 ]: value = levels [ 1 ] adjusted_value = ( value - levels [ 0 ]) / ( levels [ 1 ] - levels [ 0 ]) color_indicator = color_map . map ( adjusted_value ) spot_dic = { 'pos' : ( j , i ), 'size' : size [ i , j ] / 60 , 'pen' : { 'color' : 'w' , 'width' : size [ i , j ] / 60 }, 'brush' : pg . mkColor ( color_indicator )} # TODO fix coloring # used to be 'brush': pg.intColor(color_indicator, 100) # adding spot_dic in the list of spots spots . append ( spot_dic ) self . charts [ \"arrayMap\" ] . clear () scatter . addPoints ( spots ) # adding spots to the scatter plot self . charts [ \"arrayMap\" ] . addItem ( scatter ) # adding scatter plot to the plot window def updateChannelTracePlot ( self ): trace_plots = [ self . channelTrace1 , self . channelTrace2 , self . channelTrace3 , self . channelTrace4 ] len_data = len ( self . LoadedData . filtered_data ) # Generate subplots for m , plt in enumerate ( trace_plots ): chan_idx = len_data + ( m - 4 ) x = self . LoadedData . filtered_data [ chan_idx ][ 'times' ] y = self . LoadedData . filtered_data [ chan_idx ][ 'data' ] plt . clear () plt . plot ( x , y , pen = 'b' ) plt . setLabel ( 'left' , '#' + str ( self . LoadedData . filtered_data [ chan_idx ][ 'channel_idx' ])) plt . enableAutoRange ( axis = 'y' ) plt . setAutoVisible ( y = True ) def updateSpikeRatePlot ( self ): self . charts [ \"spikeRatePlot\" ] . clear () vals = self . LoadedData . array_stats [ 'noise_std' ] vals = vals [ np . nonzero ( vals )] # get nonzero vals because zeros have not had noise calculation done yet y , x = np . histogram ( vals , bins = np . linspace ( 0 , 20 , 40 )) curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . charts [ \"spikeRatePlot\" ] . addItem ( curve ) def updateNoiseHistogramPlot ( self ): self . charts [ \"noiseHistogram\" ] . clear () if self . LoadedData is not None : avg_spike_rate_times = self . LoadedData . array_stats [ \"array spike rate times\" ] x = np . cumsum ( avg_spike_rate_times ) y = self . LoadedData . array_stats [ \"array spike rate\" ] line_plot = self . charts [ \"noiseHistogram\" ] . plot ( x , y , pen = 'b' , symbol = 'o' , symbolPen = 'b' , symbolBrush = 0.2 ) def updateMiniMapPlot ( self ): self . charts [ \"miniMap\" ] . clear () print ( 'update minimap plot:' , self . center_row , self . center_col ) for row in range ( self . center_row - 4 , self . center_row + 4 ): for col in range ( self . center_col - 2 , self . center_col + 2 ): print ( 'r' , row , 'c' , col ) spike_indicator_base = pg . QtGui . QGraphicsRectItem ( row * 5 , col * 5 , 4 , 0.2 ) spike_indicator_base . setPen ( pg . mkPen (( 0 , 0 , 0 , 100 ))) spike_indicator_base . setBrush ( pg . mkBrush (( 50 , 50 , 200 ))) elec_idx = str ( map2idx ( col , row )) spike_indicator_text = pg . TextItem ( elec_idx , 'k' , anchor = ( 0 , 0 )) spike_indicator_text . setPos ( row * 5 , col * 5 ) spike_indicator_text . setParentItem ( spike_indicator_base ) #times = [0, 1, 3, 5, 10, 11, 14] if np . random . random () > 0.5 : times = np . random . randint ( 0 , 20 , ( 3 ,), dtype = 'int64' ) for i in times : spike_indicator = pg . QtGui . QGraphicsRectItem ( row * 5 + i / 5 , col * 5 , 0.1 , 1.5 ) spike_indicator . setPen ( pg . mkPen (( 0 , 0 , 0 , 100 ))) spike_indicator . setBrush ( pg . mkBrush (( 50 , 50 , 200 ))) spike_indicator . setParentItem ( spike_indicator_base ) self . charts [ \"miniMap\" ] . addItem ( spike_indicator ) self . charts [ \"miniMap\" ] . addItem ( spike_indicator_base ) self . charts [ \"miniMap\" ] . addItem ( spike_indicator_text )","title":"updateGUIWithNewData()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.getDataPath","text":"Parameters: Name Type Description Default file_type str required Source code in app/src/gui/gui_base.py def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path","title":"getDataPath()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.loadDataFromFileMat","text":"Parameters: Name Type Description Default path required loadingDict required Source code in app/src/gui/gui_base.py def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = self . settings [ \"filter\" ]) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData ()","title":"loadDataFromFileMat()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.onActionLoadMAT","text":"Source code in app/src/gui/gui_base.py def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict )","title":"onActionLoadMAT()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.onActionLoadNPZ","text":"Source code in app/src/gui/gui_base.py def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) self . loading_dict [ \"path\" ] = path data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData ()","title":"onActionLoadNPZ()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.realtimeLoading","text":"Parameters: Name Type Description Default path required loadingDict required progress_callback required gui_callback required dataIdentifierString 'gmem1' Source code in app/src/gui/gui_base.py def realtimeLoading ( self , path , loadingDict , load_from_beginning , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] if load_from_beginning : last_file_idx = 0 else : last_file_idx = loadingDict [ \"num_of_buf\" ] - 2 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'appendRawData' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filterData' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculateArrayStats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit ()","title":"realtimeLoading()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.updateGUIWithNewData","text":"Source code in app/src/gui/gui_base.py def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" print ( \"Update GUI with new data()\" ) self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession for window in self . external_windows : window . update () for chart in self . charts . keys (): chart_type = type ( self . charts [ chart ]) if str ( chart_type ) == \"<class 'pyqtgraph.widgets.PlotWidget.PlotWidget'>\" : start = time . time () self . chart_update_function_mapping [ chart ]() end = time . time () self . profile_data [ chart ] . append ( end - start ) if self . mode_profiling : self . printProfilingData ()","title":"updateGUIWithNewData()"},{"location":"gui-interactivity/","text":"","title":"Interactivity"},{"location":"gui-layout/","text":"","title":"Layout"},{"location":"gui/","text":"","title":"Gui"},{"location":"preprocessing/","text":"Data Preprocessing @authors Maddy Hays, Huy Nguyen (2022) identify_relevant_channels ( raw_data ) Only n number of channels can be recorded at a given time due to bandwidth concerns--the rest are shut off. For given data recorded at during a certain window, find which channels were recorded. Parameters: Name Type Description Default raw_data_all unprocessed data in a given time window (num_channels_X x num_channels_Y x time_len) required Returns: Type Description num_channels number of channels that were found to have been recorded for given data channel_map: list of channels that were recorded, i.e. nonzero (x/y_coords, num_channels) channel_id: list of channels that were recorded, but identified by a single numerical ID start_idx: @param raw_data: all the raw data loaded thus far from files Source code in app/src/data/preprocessing.py def identify_relevant_channels ( raw_data : np . array ): \"\"\" Only n number of channels can be recorded at a given time due to bandwidth concerns--the rest are shut off. For given data recorded at during a certain window, find which channels were recorded. Args: raw_data_all: unprocessed data in a given time window (num_channels_X x num_channels_Y x time_len) Returns: num_channels: number of channels that were found to have been recorded for given data channel_map: list of channels that were recorded, i.e. nonzero (x/y_coords, num_channels) channel_id: list of channels that were recorded, but identified by a single numerical ID start_idx: @param raw_data: all the raw data loaded thus far from files \"\"\" # This bit takes the longest. ~ 30 sec for whole array 4 channel recording num_samples = np . count_nonzero ( raw_data , axis = 2 ) num_channels = np . count_nonzero ( num_samples ) # Map and Identify recorded channels find_coords = np . nonzero ( num_samples ) channel_map = np . array ( find_coords ) channel_id = np . zeros ( num_channels ) start_idx = np . zeros ( num_channels ) for k in range ( 0 , num_channels ): channel_id [ k ] = map2idx ( channel_map [ 0 , k ], channel_map [ 1 , k ]) start_idx [ k ] = ( raw_data [ channel_map [ 0 , k ], channel_map [ 1 , k ], :] != 0 ) . argmax ( axis = 0 ) recorded_channels = np . stack (( channel_id , start_idx ), axis = 1 ) . astype ( int ) #return recorded_channels return num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels idx2map ( ch_idx ) Given a channel index, return the channel's row and col Parameters: Name Type Description Default ch_idx int single numerical index for array (up to 1024) required Returns: Type Description channel row and channel index Source code in app/src/data/preprocessing.py def idx2map ( ch_idx : int ): \"\"\" Given a channel index, return the channel's row and col Args: ch_idx: single numerical index for array (up to 1024) Returns: channel row and channel index \"\"\" if ch_idx > 1023 or ch_idx < 0 : print ( 'Chan num out of range' ) else : ch_row = int ( ch_idx / 32 ) ch_col = int ( ch_idx - ch_row * 32 ) return ch_row , ch_col map2idx ( ch_row , ch_col ) Given a channel's row and col, return channel's index Parameters: Name Type Description Default ch_row int row index of channel in array (up to 32) required ch_col int column index of channel in array (up to 32) required Returns: numerical index of array Source code in app/src/data/preprocessing.py def map2idx ( ch_row : int , ch_col : int ): \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx","title":"Preprocessing"},{"location":"preprocessing/#data-preprocessing","text":"@authors Maddy Hays, Huy Nguyen (2022)","title":"Data Preprocessing"},{"location":"preprocessing/#dc1DataVis.app.src.data.preprocessing.identify_relevant_channels","text":"Only n number of channels can be recorded at a given time due to bandwidth concerns--the rest are shut off. For given data recorded at during a certain window, find which channels were recorded. Parameters: Name Type Description Default raw_data_all unprocessed data in a given time window (num_channels_X x num_channels_Y x time_len) required Returns: Type Description num_channels number of channels that were found to have been recorded for given data channel_map: list of channels that were recorded, i.e. nonzero (x/y_coords, num_channels) channel_id: list of channels that were recorded, but identified by a single numerical ID start_idx: @param raw_data: all the raw data loaded thus far from files Source code in app/src/data/preprocessing.py def identify_relevant_channels ( raw_data : np . array ): \"\"\" Only n number of channels can be recorded at a given time due to bandwidth concerns--the rest are shut off. For given data recorded at during a certain window, find which channels were recorded. Args: raw_data_all: unprocessed data in a given time window (num_channels_X x num_channels_Y x time_len) Returns: num_channels: number of channels that were found to have been recorded for given data channel_map: list of channels that were recorded, i.e. nonzero (x/y_coords, num_channels) channel_id: list of channels that were recorded, but identified by a single numerical ID start_idx: @param raw_data: all the raw data loaded thus far from files \"\"\" # This bit takes the longest. ~ 30 sec for whole array 4 channel recording num_samples = np . count_nonzero ( raw_data , axis = 2 ) num_channels = np . count_nonzero ( num_samples ) # Map and Identify recorded channels find_coords = np . nonzero ( num_samples ) channel_map = np . array ( find_coords ) channel_id = np . zeros ( num_channels ) start_idx = np . zeros ( num_channels ) for k in range ( 0 , num_channels ): channel_id [ k ] = map2idx ( channel_map [ 0 , k ], channel_map [ 1 , k ]) start_idx [ k ] = ( raw_data [ channel_map [ 0 , k ], channel_map [ 1 , k ], :] != 0 ) . argmax ( axis = 0 ) recorded_channels = np . stack (( channel_id , start_idx ), axis = 1 ) . astype ( int ) #return recorded_channels return num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels","title":"identify_relevant_channels()"},{"location":"preprocessing/#dc1DataVis.app.src.data.preprocessing.idx2map","text":"Given a channel index, return the channel's row and col Parameters: Name Type Description Default ch_idx int single numerical index for array (up to 1024) required Returns: Type Description channel row and channel index Source code in app/src/data/preprocessing.py def idx2map ( ch_idx : int ): \"\"\" Given a channel index, return the channel's row and col Args: ch_idx: single numerical index for array (up to 1024) Returns: channel row and channel index \"\"\" if ch_idx > 1023 or ch_idx < 0 : print ( 'Chan num out of range' ) else : ch_row = int ( ch_idx / 32 ) ch_col = int ( ch_idx - ch_row * 32 ) return ch_row , ch_col","title":"idx2map()"},{"location":"preprocessing/#dc1DataVis.app.src.data.preprocessing.map2idx","text":"Given a channel's row and col, return channel's index Parameters: Name Type Description Default ch_row int row index of channel in array (up to 32) required ch_col int column index of channel in array (up to 32) required Returns: numerical index of array Source code in app/src/data/preprocessing.py def map2idx ( ch_row : int , ch_col : int ): \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx","title":"map2idx()"},{"location":"todo/","text":"Wk of May 15-21, 2022 Huy Setup Litke Mini Map Visualizaton Create skeleton GUI for noise, spike finding plot layouts Package everything into a working app using PyInstaller Check for robustness against variable recordings Write more documentation, delete unusued vars/files John setup development environment start on individual channel + list of channels analysis windows","title":"To Dos"},{"location":"todo/#wk-of-may-15-21-2022","text":"","title":"Wk of May 15-21, 2022"},{"location":"todo/#huy","text":"Setup Litke Mini Map Visualizaton Create skeleton GUI for noise, spike finding plot layouts Package everything into a working app using PyInstaller Check for robustness against variable recordings Write more documentation, delete unusued vars/files","title":"Huy"},{"location":"todo/#john","text":"setup development environment start on individual channel + list of channels analysis windows","title":"John"},{"location":"vis_graphs/","text":"","title":"viz_graphs"}]}