{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DC 1 Visualization This is the main project page for the DC1 visualization tool, created by Huy Nguyen and Maddy Hays.","title":"Introduction"},{"location":"#dc-1-visualization","text":"This is the main project page for the DC1 visualization tool, created by Huy Nguyen and Maddy Hays.","title":"DC 1 Visualization"},{"location":"DC1DataContainer/","text":"DC1 Data Container DC1DataContainer Container for holding all different types of data. Source code in app/src/data/DC1DataContainer.py class DC1DataContainer (): \"\"\" Container for holding all different types of data. \"\"\" # raw_data --> recorded_data --> filtered_data # raw_data: data loader from .mat files raw_data , counts , times = None , None , None count_track , time_track = None , None container_length = None # recorded_data: nonzero data # each element in recorded_data is data for one channel recorded recorded_data = [] count_track_processed , time_track_processed = None , None # filtered_data: recorded_data gone through a filter # each element in filtered_data is filtered data for one channel filtered_data = [] # array_statistics: overall array stats array_stats = { \"size\" : np . zeros (( 32 , 32 , 0 )), # For each dot, size by # of samples \"num_sam\" : np . zeros (( 32 , 32 , 1 )), # Temp variable to allow sample counting \"colors\" : np . zeros (( 32 , 32 , 0 )), # For each dot, color by avg amplitude \"avg_val\" : np . zeros (( 32 , 32 , 1 )), # Temp variable for calculating average amplitude \"noise_mean\" : np . zeros (( 32 , 32 )), \"noise_std\" : np . zeros (( 32 , 32 )), \"noise_cnt\" : np . zeros (( 32 , 32 )), \"spike_avg\" : np . zeros (( 32 , 32 )), \"spike_std\" : np . zeros (( 32 , 32 )), \"spike_cnt\" : np . zeros (( 32 , 32 )), \"size\" : None , \"times\" : None } # TODO combine with identity_relevant_channels def __init__ ( self ): self . time_track = 0 self . count_track = 0 self . count_track_processed = 0 self . time_track_processed = 0 self . raw_data = np . zeros (( 32 , 32 , 1000 )) self . counts = np . zeros (( 32 , 32 , 1000 )) self . times = np . zeros (( 1000 ,)) self . container_length = 1000 def extend_data_containers ( self , mode = 'double' ): \"\"\"Change data containers dynamically to accommodate longer time windows of data Args: mode: how to expand data containers Returns: Nothing \"\"\" if mode == 'double' : padding_data = np . zeros ( self . raw_data . shape ) padding_cnt = np . zeros ( self . counts . shape ) padding_times = np . zeros ( self . times . shape ) self . raw_data = np . concatenate (( self . raw_data , padding_data ), axis = 2 ) self . counts = np . concatenate (( self . counts , padding_cnt ), axis = 2 ) self . times = np . concatenate (( self . times , padding_times )) self . container_length *= 2 def append_raw_data ( self , data_real , cnt_real , N , sampling_period = 0.05 ): \"\"\" appends raw data in buffer to end of data container, append nonzero data to recorded_data Args: data_real: cnt_real: N: sampling_period: Returns: \"\"\" while self . raw_data . shape [ 2 ] < self . count_track + N : self . extend_data_containers () self . raw_data [:, :, self . count_track : self . count_track + N ] = data_real [:, :, : N ] self . counts [:, :, self . count_track : self . count_track + N ] = cnt_real [:, :, : N ] # Determine time estimate and sample counts for the total combined buffers # =============================== # (note this does not take into account communication delays - hence an estimate) end_time = N * sampling_period # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms # For the first buffer, we assume the first sample comes in at time 0 if self . time_track == 0 : new_times = np . linspace ( 0 , end_time , N + 1 ) self . times [ 0 : len ( new_times )] = new_times # For buffers after the first, we place these values directly after the previous buffer else : new_times = np . linspace ( self . time_track , self . time_track + end_time , N ) self . times [ self . count_track : self . count_track + N ] = new_times # identify relevant, nonzero channels, and then append only this data into recorded_data num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels = identify_relevant_channels ( data_real ) for i in range ( recorded_channels . shape [ 0 ]): channel_idx = int ( recorded_channels [ i ][ 0 ]) start_idx = recorded_channels [ i ][ 0 ] x , y = idx2map ( channel_idx ) channel_data = { 'channel_idx' : channel_idx , 'start_idx' : int ( self . count_track + start_idx ), # start_idx is based only on buffer, so need to add time from previous buffers 'data' : data_real [ x , y , start_idx : N ], # TODO make this accurate 'times' : self . times [ self . count_track + start_idx : self . count_track + N ] } self . recorded_data . append ( channel_data ) self . time_track += end_time self . count_track += N # TODO this shouldn't call update_filtered_data -> should be async, and threaded def update_filtered_data ( self , num_threads = 4 , filtType = 'modHierlemann' ): # subtract recorded_data by filtered_data len_recorded_data = len ( self . recorded_data ) len_filtered_data = len ( self . filtered_data ) # TODO parallelize filtering if len_filtered_data < len_recorded_data : while len_filtered_data < len_recorded_data : to_filter_idx = len_filtered_data to_filter_data = self . recorded_data [ to_filter_idx ][ 'data' ] filtered_data = applyFilterToChannelData ( to_filter_data , filtType = filtType ) filtered_data = { 'channel_idx' : self . recorded_data [ to_filter_idx ][ 'channel_idx' ], 'start_idx' : self . recorded_data [ to_filter_idx ][ 'start_idx' ], # start_idx is based only on buffer, so need to add time from previous buffers 'data' : filtered_data , # TODO make this accurate 'times' : self . recorded_data [ to_filter_idx ][ 'times' ] } self . filtered_data . append ( filtered_data ) len_filtered_data += 1 def update_array_stats ( self , data_real , N ): \"\"\" Args: data_real: N: Returns: \"\"\" # AX1,AX3,AX4) Sample Counting (Note: Appends are an artifact from previous real time codes) self . array_stats [ 'num_sam' ][:, :, 0 ] = np . count_nonzero ( data_real , axis = 2 ) incom_cnt = self . array_stats [ 'num_sam' ][:, :, 0 ] # AX2) Time Domain Electrodes to Plot fig_rows = np . count_nonzero ( self . array_stats [ 'num_sam' ]) if fig_rows == 0 : fig_rows = 1 if fig_rows > 4 : fig_rows = 4 fig_elec = np . zeros (( fig_rows , 2 )) fig_ind = np . argsort ( self . array_stats [ 'num_sam' ] . flatten ())[ - fig_rows :] fig_elec [:, 0 ] = ( fig_ind [:] / 32 ) . astype ( int ) fig_elec [:, 1 ] = fig_ind [:] - ( fig_elec [:, 0 ] * 32 ) fig_elec = fig_elec . astype ( int ) # AX1,AX3,AX4) Finding average ADC of samples per electrode mask = np . copy ( data_real ) mask [ mask == 0 ] = np . nan self . array_stats [ 'avg_val' ][:, :, 0 ] = np . nanmean ( mask , axis = 2 ) avg_val = np . nan_to_num ( self . array_stats [ 'avg_val' ], nan = 0 ) incom_mean = avg_val [:, :, 0 ] # AX3,AX4) Finding standard deviation ADC of samples per electrode incom_std = np . nanstd ( mask , axis = 2 ) incom_std = np . nan_to_num ( incom_std , nan = 0 ) # AX3,AX4) Building standard deviation of samples per electrode as buffers come in pre_mean = np . copy ( self . array_stats [ \"noise_mean\" ]) pre_std = np . copy ( self . array_stats [ \"noise_std\" ]) pre_cnt = np . copy ( self . array_stats [ \"noise_cnt\" ]) cnt_div = pre_cnt + incom_cnt cnt_div [ cnt_div == 0 ] = np . nan self . array_stats [ \"noise_mean\" ] = np . nan_to_num (( pre_cnt * pre_mean + incom_cnt * incom_mean ) / ( cnt_div ), nan = 0 ) self . array_stats [ \"noise_std\" ] = np . sqrt ( np . nan_to_num (( pre_cnt * ( pre_std ** 2 + ( pre_mean - self . array_stats [ \"noise_mean\" ]) ** 2 ) + incom_cnt * ( incom_std ** 2 + ( incom_mean - self . array_stats [ \"noise_mean\" ]) ** 2 )) / ( cnt_div ), nan = 0 )) self . array_stats [ \"noise_cnt\" ] = np . nan_to_num ( pre_cnt + incom_cnt , nan = 0 ) # NEW AX1) chan_cnt = np . count_nonzero ( self . array_stats [ 'num_sam' ]) chan_elec = np . zeros (( chan_cnt , 2 )) chan_ind = np . argsort ( self . array_stats [ 'num_sam' ] . flatten ())[ - chan_cnt :] chan_elec [:, 0 ] = ( chan_ind [:] / 32 ) . astype ( int ) chan_elec [:, 1 ] = chan_ind [:] - ( chan_elec [:, 0 ] * 32 ) chan_elec = chan_elec . astype ( int ) incom_spike_cnt = np . zeros (( 32 , 32 )) incom_spike_avg = np . zeros (( 32 , 32 )) incom_spike_std = np . zeros (( 32 , 32 )) mask2 = np . copy ( data_real ) for x in range ( len ( chan_ind )): self . array_stats [ \"noise_std\" ] = self . array_stats [ \"noise_std\" ] incom_spike_cnt [ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] = np . count_nonzero ( mask [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] >= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + spike_t * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]) mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] <= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + spike_t * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]] = np . nan incom_spike_avg = np . nanmean ( mask2 , axis = 2 ) incom_spike_avg = np . nan_to_num ( incom_spike_avg , nan = 0 ) incom_spike_std = np . nanstd ( mask2 , axis = 2 ) incom_spike_std = np . nan_to_num ( incom_spike_std , nan = 0 ) pre_spike_avg = np . copy ( self . array_stats [ \"spike_avg\" ]) pre_spike_std = np . copy ( self . array_stats [ \"spike_std\" ]) pre_spike_cnt = np . copy ( self . array_stats [ \"spike_cnt\" ]) new_spike_cnt = pre_spike_cnt + incom_spike_cnt new_spike_cnt [ new_spike_cnt == 0 ] = np . nan self . array_stats [ \"spike_avg\" ] = np . nan_to_num (( pre_spike_cnt * pre_spike_avg + incom_spike_cnt * incom_spike_avg ) / ( new_spike_cnt ), nan = 0 ) self . array_stats [ \"spike_std\" ] = np . sqrt ( np . nan_to_num (( pre_spike_cnt * ( pre_spike_std ** 2 + ( pre_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 ) + incom_spike_cnt * ( incom_spike_std ** 2 + ( incom_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 )) / ( new_spike_cnt ), nan = 0 )) self . array_stats [ \"spike_cnt\" ] = np . nan_to_num ( new_spike_cnt , nan = 0 ) # AX1) Colors by Average Electrode Amplitude self . array_stats [ \"colors\" ] = np . copy ( self . array_stats [ \"spike_avg\" ]) # AX1) Size by Number of Samples scale1 = ( max_dot - 15 ) / ( np . max ( self . array_stats [ \"spike_cnt\" ]) - np . min ( self . array_stats [ \"spike_cnt\" ][ self . array_stats [ \"spike_cnt\" ] != 0 ])) b_add = max_dot - ( np . max ( self . array_stats [ \"spike_cnt\" ]) * scale1 ) self . array_stats [ \"size\" ] = np . round ( self . array_stats [ \"spike_cnt\" ] * scale1 + b_add ) self . array_stats [ \"size\" ][ self . array_stats [ \"size\" ] < 15 ] = 10 # max_sam = np.max(num_sam[:,:,0]) # min_sam = np.min(num_sam[num_sam!=0]) # if max_sam == min_sam: # min_sam = 0 # scale = (max_dot - 15) / (max_sam - min_sam) # b_add = max_dot - (max_sam*scale) # size = np.append(size,np.round(num_sam*scale+b_add),axis=2) # size[size<15] = 10 # AX2) Determine the Time of Each Sample total_time = N * 0.05 # Sampling rate 1/0.05 ms self . array_stats [ \"times\" ] = np . linspace ( 0 , total_time , N ) append_raw_data ( self , data_real , cnt_real , N , sampling_period = 0.05 ) appends raw data in buffer to end of data container, append nonzero data to recorded_data Parameters: Name Type Description Default data_real required cnt_real required N required sampling_period 0.05 Source code in app/src/data/DC1DataContainer.py def append_raw_data ( self , data_real , cnt_real , N , sampling_period = 0.05 ): \"\"\" appends raw data in buffer to end of data container, append nonzero data to recorded_data Args: data_real: cnt_real: N: sampling_period: Returns: \"\"\" while self . raw_data . shape [ 2 ] < self . count_track + N : self . extend_data_containers () self . raw_data [:, :, self . count_track : self . count_track + N ] = data_real [:, :, : N ] self . counts [:, :, self . count_track : self . count_track + N ] = cnt_real [:, :, : N ] # Determine time estimate and sample counts for the total combined buffers # =============================== # (note this does not take into account communication delays - hence an estimate) end_time = N * sampling_period # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms # For the first buffer, we assume the first sample comes in at time 0 if self . time_track == 0 : new_times = np . linspace ( 0 , end_time , N + 1 ) self . times [ 0 : len ( new_times )] = new_times # For buffers after the first, we place these values directly after the previous buffer else : new_times = np . linspace ( self . time_track , self . time_track + end_time , N ) self . times [ self . count_track : self . count_track + N ] = new_times # identify relevant, nonzero channels, and then append only this data into recorded_data num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels = identify_relevant_channels ( data_real ) for i in range ( recorded_channels . shape [ 0 ]): channel_idx = int ( recorded_channels [ i ][ 0 ]) start_idx = recorded_channels [ i ][ 0 ] x , y = idx2map ( channel_idx ) channel_data = { 'channel_idx' : channel_idx , 'start_idx' : int ( self . count_track + start_idx ), # start_idx is based only on buffer, so need to add time from previous buffers 'data' : data_real [ x , y , start_idx : N ], # TODO make this accurate 'times' : self . times [ self . count_track + start_idx : self . count_track + N ] } self . recorded_data . append ( channel_data ) self . time_track += end_time self . count_track += N extend_data_containers ( self , mode = 'double' ) Change data containers dynamically to accommodate longer time windows of data Parameters: Name Type Description Default mode how to expand data containers 'double' Returns: Type Description Nothing Source code in app/src/data/DC1DataContainer.py def extend_data_containers ( self , mode = 'double' ): \"\"\"Change data containers dynamically to accommodate longer time windows of data Args: mode: how to expand data containers Returns: Nothing \"\"\" if mode == 'double' : padding_data = np . zeros ( self . raw_data . shape ) padding_cnt = np . zeros ( self . counts . shape ) padding_times = np . zeros ( self . times . shape ) self . raw_data = np . concatenate (( self . raw_data , padding_data ), axis = 2 ) self . counts = np . concatenate (( self . counts , padding_cnt ), axis = 2 ) self . times = np . concatenate (( self . times , padding_times )) self . container_length *= 2 update_array_stats ( self , data_real , N ) Parameters: Name Type Description Default data_real required N required Source code in app/src/data/DC1DataContainer.py def update_array_stats ( self , data_real , N ): \"\"\" Args: data_real: N: Returns: \"\"\" # AX1,AX3,AX4) Sample Counting (Note: Appends are an artifact from previous real time codes) self . array_stats [ 'num_sam' ][:, :, 0 ] = np . count_nonzero ( data_real , axis = 2 ) incom_cnt = self . array_stats [ 'num_sam' ][:, :, 0 ] # AX2) Time Domain Electrodes to Plot fig_rows = np . count_nonzero ( self . array_stats [ 'num_sam' ]) if fig_rows == 0 : fig_rows = 1 if fig_rows > 4 : fig_rows = 4 fig_elec = np . zeros (( fig_rows , 2 )) fig_ind = np . argsort ( self . array_stats [ 'num_sam' ] . flatten ())[ - fig_rows :] fig_elec [:, 0 ] = ( fig_ind [:] / 32 ) . astype ( int ) fig_elec [:, 1 ] = fig_ind [:] - ( fig_elec [:, 0 ] * 32 ) fig_elec = fig_elec . astype ( int ) # AX1,AX3,AX4) Finding average ADC of samples per electrode mask = np . copy ( data_real ) mask [ mask == 0 ] = np . nan self . array_stats [ 'avg_val' ][:, :, 0 ] = np . nanmean ( mask , axis = 2 ) avg_val = np . nan_to_num ( self . array_stats [ 'avg_val' ], nan = 0 ) incom_mean = avg_val [:, :, 0 ] # AX3,AX4) Finding standard deviation ADC of samples per electrode incom_std = np . nanstd ( mask , axis = 2 ) incom_std = np . nan_to_num ( incom_std , nan = 0 ) # AX3,AX4) Building standard deviation of samples per electrode as buffers come in pre_mean = np . copy ( self . array_stats [ \"noise_mean\" ]) pre_std = np . copy ( self . array_stats [ \"noise_std\" ]) pre_cnt = np . copy ( self . array_stats [ \"noise_cnt\" ]) cnt_div = pre_cnt + incom_cnt cnt_div [ cnt_div == 0 ] = np . nan self . array_stats [ \"noise_mean\" ] = np . nan_to_num (( pre_cnt * pre_mean + incom_cnt * incom_mean ) / ( cnt_div ), nan = 0 ) self . array_stats [ \"noise_std\" ] = np . sqrt ( np . nan_to_num (( pre_cnt * ( pre_std ** 2 + ( pre_mean - self . array_stats [ \"noise_mean\" ]) ** 2 ) + incom_cnt * ( incom_std ** 2 + ( incom_mean - self . array_stats [ \"noise_mean\" ]) ** 2 )) / ( cnt_div ), nan = 0 )) self . array_stats [ \"noise_cnt\" ] = np . nan_to_num ( pre_cnt + incom_cnt , nan = 0 ) # NEW AX1) chan_cnt = np . count_nonzero ( self . array_stats [ 'num_sam' ]) chan_elec = np . zeros (( chan_cnt , 2 )) chan_ind = np . argsort ( self . array_stats [ 'num_sam' ] . flatten ())[ - chan_cnt :] chan_elec [:, 0 ] = ( chan_ind [:] / 32 ) . astype ( int ) chan_elec [:, 1 ] = chan_ind [:] - ( chan_elec [:, 0 ] * 32 ) chan_elec = chan_elec . astype ( int ) incom_spike_cnt = np . zeros (( 32 , 32 )) incom_spike_avg = np . zeros (( 32 , 32 )) incom_spike_std = np . zeros (( 32 , 32 )) mask2 = np . copy ( data_real ) for x in range ( len ( chan_ind )): self . array_stats [ \"noise_std\" ] = self . array_stats [ \"noise_std\" ] incom_spike_cnt [ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] = np . count_nonzero ( mask [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] >= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + spike_t * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]) mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] <= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + spike_t * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]] = np . nan incom_spike_avg = np . nanmean ( mask2 , axis = 2 ) incom_spike_avg = np . nan_to_num ( incom_spike_avg , nan = 0 ) incom_spike_std = np . nanstd ( mask2 , axis = 2 ) incom_spike_std = np . nan_to_num ( incom_spike_std , nan = 0 ) pre_spike_avg = np . copy ( self . array_stats [ \"spike_avg\" ]) pre_spike_std = np . copy ( self . array_stats [ \"spike_std\" ]) pre_spike_cnt = np . copy ( self . array_stats [ \"spike_cnt\" ]) new_spike_cnt = pre_spike_cnt + incom_spike_cnt new_spike_cnt [ new_spike_cnt == 0 ] = np . nan self . array_stats [ \"spike_avg\" ] = np . nan_to_num (( pre_spike_cnt * pre_spike_avg + incom_spike_cnt * incom_spike_avg ) / ( new_spike_cnt ), nan = 0 ) self . array_stats [ \"spike_std\" ] = np . sqrt ( np . nan_to_num (( pre_spike_cnt * ( pre_spike_std ** 2 + ( pre_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 ) + incom_spike_cnt * ( incom_spike_std ** 2 + ( incom_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 )) / ( new_spike_cnt ), nan = 0 )) self . array_stats [ \"spike_cnt\" ] = np . nan_to_num ( new_spike_cnt , nan = 0 ) # AX1) Colors by Average Electrode Amplitude self . array_stats [ \"colors\" ] = np . copy ( self . array_stats [ \"spike_avg\" ]) # AX1) Size by Number of Samples scale1 = ( max_dot - 15 ) / ( np . max ( self . array_stats [ \"spike_cnt\" ]) - np . min ( self . array_stats [ \"spike_cnt\" ][ self . array_stats [ \"spike_cnt\" ] != 0 ])) b_add = max_dot - ( np . max ( self . array_stats [ \"spike_cnt\" ]) * scale1 ) self . array_stats [ \"size\" ] = np . round ( self . array_stats [ \"spike_cnt\" ] * scale1 + b_add ) self . array_stats [ \"size\" ][ self . array_stats [ \"size\" ] < 15 ] = 10 # max_sam = np.max(num_sam[:,:,0]) # min_sam = np.min(num_sam[num_sam!=0]) # if max_sam == min_sam: # min_sam = 0 # scale = (max_dot - 15) / (max_sam - min_sam) # b_add = max_dot - (max_sam*scale) # size = np.append(size,np.round(num_sam*scale+b_add),axis=2) # size[size<15] = 10 # AX2) Determine the Time of Each Sample total_time = N * 0.05 # Sampling rate 1/0.05 ms self . array_stats [ \"times\" ] = np . linspace ( 0 , total_time , N )","title":"Data Container"},{"location":"DC1DataContainer/#dc1-data-container","text":"","title":"DC1 Data Container"},{"location":"DC1DataContainer/#dc1DataVis.app.src.data.DC1DataContainer.DC1DataContainer","text":"Container for holding all different types of data. Source code in app/src/data/DC1DataContainer.py class DC1DataContainer (): \"\"\" Container for holding all different types of data. \"\"\" # raw_data --> recorded_data --> filtered_data # raw_data: data loader from .mat files raw_data , counts , times = None , None , None count_track , time_track = None , None container_length = None # recorded_data: nonzero data # each element in recorded_data is data for one channel recorded recorded_data = [] count_track_processed , time_track_processed = None , None # filtered_data: recorded_data gone through a filter # each element in filtered_data is filtered data for one channel filtered_data = [] # array_statistics: overall array stats array_stats = { \"size\" : np . zeros (( 32 , 32 , 0 )), # For each dot, size by # of samples \"num_sam\" : np . zeros (( 32 , 32 , 1 )), # Temp variable to allow sample counting \"colors\" : np . zeros (( 32 , 32 , 0 )), # For each dot, color by avg amplitude \"avg_val\" : np . zeros (( 32 , 32 , 1 )), # Temp variable for calculating average amplitude \"noise_mean\" : np . zeros (( 32 , 32 )), \"noise_std\" : np . zeros (( 32 , 32 )), \"noise_cnt\" : np . zeros (( 32 , 32 )), \"spike_avg\" : np . zeros (( 32 , 32 )), \"spike_std\" : np . zeros (( 32 , 32 )), \"spike_cnt\" : np . zeros (( 32 , 32 )), \"size\" : None , \"times\" : None } # TODO combine with identity_relevant_channels def __init__ ( self ): self . time_track = 0 self . count_track = 0 self . count_track_processed = 0 self . time_track_processed = 0 self . raw_data = np . zeros (( 32 , 32 , 1000 )) self . counts = np . zeros (( 32 , 32 , 1000 )) self . times = np . zeros (( 1000 ,)) self . container_length = 1000 def extend_data_containers ( self , mode = 'double' ): \"\"\"Change data containers dynamically to accommodate longer time windows of data Args: mode: how to expand data containers Returns: Nothing \"\"\" if mode == 'double' : padding_data = np . zeros ( self . raw_data . shape ) padding_cnt = np . zeros ( self . counts . shape ) padding_times = np . zeros ( self . times . shape ) self . raw_data = np . concatenate (( self . raw_data , padding_data ), axis = 2 ) self . counts = np . concatenate (( self . counts , padding_cnt ), axis = 2 ) self . times = np . concatenate (( self . times , padding_times )) self . container_length *= 2 def append_raw_data ( self , data_real , cnt_real , N , sampling_period = 0.05 ): \"\"\" appends raw data in buffer to end of data container, append nonzero data to recorded_data Args: data_real: cnt_real: N: sampling_period: Returns: \"\"\" while self . raw_data . shape [ 2 ] < self . count_track + N : self . extend_data_containers () self . raw_data [:, :, self . count_track : self . count_track + N ] = data_real [:, :, : N ] self . counts [:, :, self . count_track : self . count_track + N ] = cnt_real [:, :, : N ] # Determine time estimate and sample counts for the total combined buffers # =============================== # (note this does not take into account communication delays - hence an estimate) end_time = N * sampling_period # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms # For the first buffer, we assume the first sample comes in at time 0 if self . time_track == 0 : new_times = np . linspace ( 0 , end_time , N + 1 ) self . times [ 0 : len ( new_times )] = new_times # For buffers after the first, we place these values directly after the previous buffer else : new_times = np . linspace ( self . time_track , self . time_track + end_time , N ) self . times [ self . count_track : self . count_track + N ] = new_times # identify relevant, nonzero channels, and then append only this data into recorded_data num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels = identify_relevant_channels ( data_real ) for i in range ( recorded_channels . shape [ 0 ]): channel_idx = int ( recorded_channels [ i ][ 0 ]) start_idx = recorded_channels [ i ][ 0 ] x , y = idx2map ( channel_idx ) channel_data = { 'channel_idx' : channel_idx , 'start_idx' : int ( self . count_track + start_idx ), # start_idx is based only on buffer, so need to add time from previous buffers 'data' : data_real [ x , y , start_idx : N ], # TODO make this accurate 'times' : self . times [ self . count_track + start_idx : self . count_track + N ] } self . recorded_data . append ( channel_data ) self . time_track += end_time self . count_track += N # TODO this shouldn't call update_filtered_data -> should be async, and threaded def update_filtered_data ( self , num_threads = 4 , filtType = 'modHierlemann' ): # subtract recorded_data by filtered_data len_recorded_data = len ( self . recorded_data ) len_filtered_data = len ( self . filtered_data ) # TODO parallelize filtering if len_filtered_data < len_recorded_data : while len_filtered_data < len_recorded_data : to_filter_idx = len_filtered_data to_filter_data = self . recorded_data [ to_filter_idx ][ 'data' ] filtered_data = applyFilterToChannelData ( to_filter_data , filtType = filtType ) filtered_data = { 'channel_idx' : self . recorded_data [ to_filter_idx ][ 'channel_idx' ], 'start_idx' : self . recorded_data [ to_filter_idx ][ 'start_idx' ], # start_idx is based only on buffer, so need to add time from previous buffers 'data' : filtered_data , # TODO make this accurate 'times' : self . recorded_data [ to_filter_idx ][ 'times' ] } self . filtered_data . append ( filtered_data ) len_filtered_data += 1 def update_array_stats ( self , data_real , N ): \"\"\" Args: data_real: N: Returns: \"\"\" # AX1,AX3,AX4) Sample Counting (Note: Appends are an artifact from previous real time codes) self . array_stats [ 'num_sam' ][:, :, 0 ] = np . count_nonzero ( data_real , axis = 2 ) incom_cnt = self . array_stats [ 'num_sam' ][:, :, 0 ] # AX2) Time Domain Electrodes to Plot fig_rows = np . count_nonzero ( self . array_stats [ 'num_sam' ]) if fig_rows == 0 : fig_rows = 1 if fig_rows > 4 : fig_rows = 4 fig_elec = np . zeros (( fig_rows , 2 )) fig_ind = np . argsort ( self . array_stats [ 'num_sam' ] . flatten ())[ - fig_rows :] fig_elec [:, 0 ] = ( fig_ind [:] / 32 ) . astype ( int ) fig_elec [:, 1 ] = fig_ind [:] - ( fig_elec [:, 0 ] * 32 ) fig_elec = fig_elec . astype ( int ) # AX1,AX3,AX4) Finding average ADC of samples per electrode mask = np . copy ( data_real ) mask [ mask == 0 ] = np . nan self . array_stats [ 'avg_val' ][:, :, 0 ] = np . nanmean ( mask , axis = 2 ) avg_val = np . nan_to_num ( self . array_stats [ 'avg_val' ], nan = 0 ) incom_mean = avg_val [:, :, 0 ] # AX3,AX4) Finding standard deviation ADC of samples per electrode incom_std = np . nanstd ( mask , axis = 2 ) incom_std = np . nan_to_num ( incom_std , nan = 0 ) # AX3,AX4) Building standard deviation of samples per electrode as buffers come in pre_mean = np . copy ( self . array_stats [ \"noise_mean\" ]) pre_std = np . copy ( self . array_stats [ \"noise_std\" ]) pre_cnt = np . copy ( self . array_stats [ \"noise_cnt\" ]) cnt_div = pre_cnt + incom_cnt cnt_div [ cnt_div == 0 ] = np . nan self . array_stats [ \"noise_mean\" ] = np . nan_to_num (( pre_cnt * pre_mean + incom_cnt * incom_mean ) / ( cnt_div ), nan = 0 ) self . array_stats [ \"noise_std\" ] = np . sqrt ( np . nan_to_num (( pre_cnt * ( pre_std ** 2 + ( pre_mean - self . array_stats [ \"noise_mean\" ]) ** 2 ) + incom_cnt * ( incom_std ** 2 + ( incom_mean - self . array_stats [ \"noise_mean\" ]) ** 2 )) / ( cnt_div ), nan = 0 )) self . array_stats [ \"noise_cnt\" ] = np . nan_to_num ( pre_cnt + incom_cnt , nan = 0 ) # NEW AX1) chan_cnt = np . count_nonzero ( self . array_stats [ 'num_sam' ]) chan_elec = np . zeros (( chan_cnt , 2 )) chan_ind = np . argsort ( self . array_stats [ 'num_sam' ] . flatten ())[ - chan_cnt :] chan_elec [:, 0 ] = ( chan_ind [:] / 32 ) . astype ( int ) chan_elec [:, 1 ] = chan_ind [:] - ( chan_elec [:, 0 ] * 32 ) chan_elec = chan_elec . astype ( int ) incom_spike_cnt = np . zeros (( 32 , 32 )) incom_spike_avg = np . zeros (( 32 , 32 )) incom_spike_std = np . zeros (( 32 , 32 )) mask2 = np . copy ( data_real ) for x in range ( len ( chan_ind )): self . array_stats [ \"noise_std\" ] = self . array_stats [ \"noise_std\" ] incom_spike_cnt [ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] = np . count_nonzero ( mask [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] >= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + spike_t * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]) mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] <= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + spike_t * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]] = np . nan incom_spike_avg = np . nanmean ( mask2 , axis = 2 ) incom_spike_avg = np . nan_to_num ( incom_spike_avg , nan = 0 ) incom_spike_std = np . nanstd ( mask2 , axis = 2 ) incom_spike_std = np . nan_to_num ( incom_spike_std , nan = 0 ) pre_spike_avg = np . copy ( self . array_stats [ \"spike_avg\" ]) pre_spike_std = np . copy ( self . array_stats [ \"spike_std\" ]) pre_spike_cnt = np . copy ( self . array_stats [ \"spike_cnt\" ]) new_spike_cnt = pre_spike_cnt + incom_spike_cnt new_spike_cnt [ new_spike_cnt == 0 ] = np . nan self . array_stats [ \"spike_avg\" ] = np . nan_to_num (( pre_spike_cnt * pre_spike_avg + incom_spike_cnt * incom_spike_avg ) / ( new_spike_cnt ), nan = 0 ) self . array_stats [ \"spike_std\" ] = np . sqrt ( np . nan_to_num (( pre_spike_cnt * ( pre_spike_std ** 2 + ( pre_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 ) + incom_spike_cnt * ( incom_spike_std ** 2 + ( incom_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 )) / ( new_spike_cnt ), nan = 0 )) self . array_stats [ \"spike_cnt\" ] = np . nan_to_num ( new_spike_cnt , nan = 0 ) # AX1) Colors by Average Electrode Amplitude self . array_stats [ \"colors\" ] = np . copy ( self . array_stats [ \"spike_avg\" ]) # AX1) Size by Number of Samples scale1 = ( max_dot - 15 ) / ( np . max ( self . array_stats [ \"spike_cnt\" ]) - np . min ( self . array_stats [ \"spike_cnt\" ][ self . array_stats [ \"spike_cnt\" ] != 0 ])) b_add = max_dot - ( np . max ( self . array_stats [ \"spike_cnt\" ]) * scale1 ) self . array_stats [ \"size\" ] = np . round ( self . array_stats [ \"spike_cnt\" ] * scale1 + b_add ) self . array_stats [ \"size\" ][ self . array_stats [ \"size\" ] < 15 ] = 10 # max_sam = np.max(num_sam[:,:,0]) # min_sam = np.min(num_sam[num_sam!=0]) # if max_sam == min_sam: # min_sam = 0 # scale = (max_dot - 15) / (max_sam - min_sam) # b_add = max_dot - (max_sam*scale) # size = np.append(size,np.round(num_sam*scale+b_add),axis=2) # size[size<15] = 10 # AX2) Determine the Time of Each Sample total_time = N * 0.05 # Sampling rate 1/0.05 ms self . array_stats [ \"times\" ] = np . linspace ( 0 , total_time , N )","title":"DC1DataContainer"},{"location":"DC1DataContainer/#dc1DataVis.app.src.data.DC1DataContainer.DC1DataContainer.append_raw_data","text":"appends raw data in buffer to end of data container, append nonzero data to recorded_data Parameters: Name Type Description Default data_real required cnt_real required N required sampling_period 0.05 Source code in app/src/data/DC1DataContainer.py def append_raw_data ( self , data_real , cnt_real , N , sampling_period = 0.05 ): \"\"\" appends raw data in buffer to end of data container, append nonzero data to recorded_data Args: data_real: cnt_real: N: sampling_period: Returns: \"\"\" while self . raw_data . shape [ 2 ] < self . count_track + N : self . extend_data_containers () self . raw_data [:, :, self . count_track : self . count_track + N ] = data_real [:, :, : N ] self . counts [:, :, self . count_track : self . count_track + N ] = cnt_real [:, :, : N ] # Determine time estimate and sample counts for the total combined buffers # =============================== # (note this does not take into account communication delays - hence an estimate) end_time = N * sampling_period # 20kHz sampling rate, means time_recording (ms) = num_sam*0.05ms # For the first buffer, we assume the first sample comes in at time 0 if self . time_track == 0 : new_times = np . linspace ( 0 , end_time , N + 1 ) self . times [ 0 : len ( new_times )] = new_times # For buffers after the first, we place these values directly after the previous buffer else : new_times = np . linspace ( self . time_track , self . time_track + end_time , N ) self . times [ self . count_track : self . count_track + N ] = new_times # identify relevant, nonzero channels, and then append only this data into recorded_data num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels = identify_relevant_channels ( data_real ) for i in range ( recorded_channels . shape [ 0 ]): channel_idx = int ( recorded_channels [ i ][ 0 ]) start_idx = recorded_channels [ i ][ 0 ] x , y = idx2map ( channel_idx ) channel_data = { 'channel_idx' : channel_idx , 'start_idx' : int ( self . count_track + start_idx ), # start_idx is based only on buffer, so need to add time from previous buffers 'data' : data_real [ x , y , start_idx : N ], # TODO make this accurate 'times' : self . times [ self . count_track + start_idx : self . count_track + N ] } self . recorded_data . append ( channel_data ) self . time_track += end_time self . count_track += N","title":"append_raw_data()"},{"location":"DC1DataContainer/#dc1DataVis.app.src.data.DC1DataContainer.DC1DataContainer.extend_data_containers","text":"Change data containers dynamically to accommodate longer time windows of data Parameters: Name Type Description Default mode how to expand data containers 'double' Returns: Type Description Nothing Source code in app/src/data/DC1DataContainer.py def extend_data_containers ( self , mode = 'double' ): \"\"\"Change data containers dynamically to accommodate longer time windows of data Args: mode: how to expand data containers Returns: Nothing \"\"\" if mode == 'double' : padding_data = np . zeros ( self . raw_data . shape ) padding_cnt = np . zeros ( self . counts . shape ) padding_times = np . zeros ( self . times . shape ) self . raw_data = np . concatenate (( self . raw_data , padding_data ), axis = 2 ) self . counts = np . concatenate (( self . counts , padding_cnt ), axis = 2 ) self . times = np . concatenate (( self . times , padding_times )) self . container_length *= 2","title":"extend_data_containers()"},{"location":"DC1DataContainer/#dc1DataVis.app.src.data.DC1DataContainer.DC1DataContainer.update_array_stats","text":"Parameters: Name Type Description Default data_real required N required Source code in app/src/data/DC1DataContainer.py def update_array_stats ( self , data_real , N ): \"\"\" Args: data_real: N: Returns: \"\"\" # AX1,AX3,AX4) Sample Counting (Note: Appends are an artifact from previous real time codes) self . array_stats [ 'num_sam' ][:, :, 0 ] = np . count_nonzero ( data_real , axis = 2 ) incom_cnt = self . array_stats [ 'num_sam' ][:, :, 0 ] # AX2) Time Domain Electrodes to Plot fig_rows = np . count_nonzero ( self . array_stats [ 'num_sam' ]) if fig_rows == 0 : fig_rows = 1 if fig_rows > 4 : fig_rows = 4 fig_elec = np . zeros (( fig_rows , 2 )) fig_ind = np . argsort ( self . array_stats [ 'num_sam' ] . flatten ())[ - fig_rows :] fig_elec [:, 0 ] = ( fig_ind [:] / 32 ) . astype ( int ) fig_elec [:, 1 ] = fig_ind [:] - ( fig_elec [:, 0 ] * 32 ) fig_elec = fig_elec . astype ( int ) # AX1,AX3,AX4) Finding average ADC of samples per electrode mask = np . copy ( data_real ) mask [ mask == 0 ] = np . nan self . array_stats [ 'avg_val' ][:, :, 0 ] = np . nanmean ( mask , axis = 2 ) avg_val = np . nan_to_num ( self . array_stats [ 'avg_val' ], nan = 0 ) incom_mean = avg_val [:, :, 0 ] # AX3,AX4) Finding standard deviation ADC of samples per electrode incom_std = np . nanstd ( mask , axis = 2 ) incom_std = np . nan_to_num ( incom_std , nan = 0 ) # AX3,AX4) Building standard deviation of samples per electrode as buffers come in pre_mean = np . copy ( self . array_stats [ \"noise_mean\" ]) pre_std = np . copy ( self . array_stats [ \"noise_std\" ]) pre_cnt = np . copy ( self . array_stats [ \"noise_cnt\" ]) cnt_div = pre_cnt + incom_cnt cnt_div [ cnt_div == 0 ] = np . nan self . array_stats [ \"noise_mean\" ] = np . nan_to_num (( pre_cnt * pre_mean + incom_cnt * incom_mean ) / ( cnt_div ), nan = 0 ) self . array_stats [ \"noise_std\" ] = np . sqrt ( np . nan_to_num (( pre_cnt * ( pre_std ** 2 + ( pre_mean - self . array_stats [ \"noise_mean\" ]) ** 2 ) + incom_cnt * ( incom_std ** 2 + ( incom_mean - self . array_stats [ \"noise_mean\" ]) ** 2 )) / ( cnt_div ), nan = 0 )) self . array_stats [ \"noise_cnt\" ] = np . nan_to_num ( pre_cnt + incom_cnt , nan = 0 ) # NEW AX1) chan_cnt = np . count_nonzero ( self . array_stats [ 'num_sam' ]) chan_elec = np . zeros (( chan_cnt , 2 )) chan_ind = np . argsort ( self . array_stats [ 'num_sam' ] . flatten ())[ - chan_cnt :] chan_elec [:, 0 ] = ( chan_ind [:] / 32 ) . astype ( int ) chan_elec [:, 1 ] = chan_ind [:] - ( chan_elec [:, 0 ] * 32 ) chan_elec = chan_elec . astype ( int ) incom_spike_cnt = np . zeros (( 32 , 32 )) incom_spike_avg = np . zeros (( 32 , 32 )) incom_spike_std = np . zeros (( 32 , 32 )) mask2 = np . copy ( data_real ) for x in range ( len ( chan_ind )): self . array_stats [ \"noise_std\" ] = self . array_stats [ \"noise_std\" ] incom_spike_cnt [ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] = np . count_nonzero ( mask [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] >= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + spike_t * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]) mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], mask2 [ chan_elec [ x , 0 ], chan_elec [ x , 1 ], :] <= self . array_stats [ \"noise_mean\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]] + spike_t * self . array_stats [ \"noise_std\" ][ chan_elec [ x , 0 ], chan_elec [ x , 1 ]]] = np . nan incom_spike_avg = np . nanmean ( mask2 , axis = 2 ) incom_spike_avg = np . nan_to_num ( incom_spike_avg , nan = 0 ) incom_spike_std = np . nanstd ( mask2 , axis = 2 ) incom_spike_std = np . nan_to_num ( incom_spike_std , nan = 0 ) pre_spike_avg = np . copy ( self . array_stats [ \"spike_avg\" ]) pre_spike_std = np . copy ( self . array_stats [ \"spike_std\" ]) pre_spike_cnt = np . copy ( self . array_stats [ \"spike_cnt\" ]) new_spike_cnt = pre_spike_cnt + incom_spike_cnt new_spike_cnt [ new_spike_cnt == 0 ] = np . nan self . array_stats [ \"spike_avg\" ] = np . nan_to_num (( pre_spike_cnt * pre_spike_avg + incom_spike_cnt * incom_spike_avg ) / ( new_spike_cnt ), nan = 0 ) self . array_stats [ \"spike_std\" ] = np . sqrt ( np . nan_to_num (( pre_spike_cnt * ( pre_spike_std ** 2 + ( pre_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 ) + incom_spike_cnt * ( incom_spike_std ** 2 + ( incom_spike_avg - self . array_stats [ \"spike_avg\" ]) ** 2 )) / ( new_spike_cnt ), nan = 0 )) self . array_stats [ \"spike_cnt\" ] = np . nan_to_num ( new_spike_cnt , nan = 0 ) # AX1) Colors by Average Electrode Amplitude self . array_stats [ \"colors\" ] = np . copy ( self . array_stats [ \"spike_avg\" ]) # AX1) Size by Number of Samples scale1 = ( max_dot - 15 ) / ( np . max ( self . array_stats [ \"spike_cnt\" ]) - np . min ( self . array_stats [ \"spike_cnt\" ][ self . array_stats [ \"spike_cnt\" ] != 0 ])) b_add = max_dot - ( np . max ( self . array_stats [ \"spike_cnt\" ]) * scale1 ) self . array_stats [ \"size\" ] = np . round ( self . array_stats [ \"spike_cnt\" ] * scale1 + b_add ) self . array_stats [ \"size\" ][ self . array_stats [ \"size\" ] < 15 ] = 10 # max_sam = np.max(num_sam[:,:,0]) # min_sam = np.min(num_sam[num_sam!=0]) # if max_sam == min_sam: # min_sam = 0 # scale = (max_dot - 15) / (max_sam - min_sam) # b_add = max_dot - (max_sam*scale) # size = np.append(size,np.round(num_sam*scale+b_add),axis=2) # size[size<15] = 10 # AX2) Determine the Time of Each Sample total_time = N * 0.05 # Sampling rate 1/0.05 ms self . array_stats [ \"times\" ] = np . linspace ( 0 , total_time , N )","title":"update_array_stats()"},{"location":"analysis/","text":"","title":"Analysis"},{"location":"data-loading/","text":"","title":"Data Loading"},{"location":"data/","text":"","title":"Data"},{"location":"filters/","text":"Filters applyFilterAuto ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterAuto ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" samFreq = 20e3 * 1.0 passband = [ 250 , 4000 ] stopband = [ 5 , 6000 ] max_loss_passband = 3 min_loss_stopband = 30 order , normal_cutoff = signal . buttord ( passband , stopband , max_loss_passband , min_loss_stopband , fs = samFreq ) b , a = signal . butter ( order , normal_cutoff , btype = 'bandpass' , fs = samFreq ) print ( 'Order = ' + str ( order )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterFastBandpass ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterFastBandpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , analog = False ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterFasterBandpass ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterFasterBandpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq sos1 = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , output = 'sos' ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . sosfiltfilt ( sos1 , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterH0bandpass ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterH0bandpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 5 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) print ( 'Order = ' + str ( 5 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterHierlemann ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterHierlemann ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" BP_LOW_CUTOFF = 100.0 NUM_TAPS = 75 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( TAPS , [ a ], dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterHighpass ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterHighpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff = 250 / nyq b , a = signal . butter ( 5 , [ cutoff ], btype = \"highpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterLitke ( dataAll , dataFilt , numChan , chMap ) Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterLitke ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 2000 / nyq b , a = signal . butter ( 2 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt applyFilterModHierlemann ( channel_data , dataFilt ) Parameters: Name Type Description Default channel_data required dataFilt required Source code in app/src/data/filters.py def applyFilterModHierlemann ( channel_data , dataFilt ): \"\"\" Args: channel_data: dataFilt: Returns: \"\"\" BP_LOW_CUTOFF = 250.0 BP_HIGH_CUTOFF = 4000.0 NUM_TAPS = 100 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , BP_HIGH_CUTOFF ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 dataFilt = signal . filtfilt ( TAPS , [ a ], channel_data ) return dataFilt applyFilterToAllData ( dataAll , numChan , chMap , filtType = 'modHierlemann' ) Parameters: Name Type Description Default dataAll required numChan required chMap required filtType 'modHierlemann' Source code in app/src/data/filters.py def applyFilterToAllData ( dataAll , numChan , chMap , filtType = 'modHierlemann' ): \"\"\" Args: dataAll: numChan: chMap: filtType: Returns: \"\"\" # Future update: only calculate for channels recorded not all dataFilt = np . zeros (( np . shape ( dataAll ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemann ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'modHierlemann' : dataFilt = applyFilterModHierlemann ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'highpass' : dataFilt = applyFilterHighpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'hObandpass' : dataFilt = applyFilterH0bandpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'auto' : dataFilt = applyFilterAuto ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'fastBandpass' : dataFilt = applyFilterFastBandpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'fasterBandpass' : dataFilt = applyFilterFasterBandpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Litke' : dataFilt = applyFilterLitke ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'none' : dataFilt = np . copy ( dataAll ) else : dataFilt = np . copy ( dataAll ) print ( 'Filter not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) return dataFilt applyFilterToChannelData ( channel_data , filtType = 'Hierlemann' ) Parameters: Name Type Description Default channel_data required filtType 'Hierlemann' Source code in app/src/data/filters.py def applyFilterToChannelData ( channel_data , filtType = 'Hierlemann' ): \"\"\" Args: channel_data: filtType: Returns: \"\"\" dataFilt = np . zeros (( np . shape ( channel_data ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemann ( channel_data , dataFilt ) elif filtType == 'modHierlemann' : dataFilt = applyFilterModHierlemann ( channel_data , dataFilt ) elif filtType == 'highpass' : dataFilt = applyFilterHighpass ( channel_data , dataFilt ) elif filtType == 'hObandpass' : dataFilt = applyFilterH0bandpass ( channel_data , dataFilt ) elif filtType == 'auto' : dataFilt = applyFilterAuto ( channel_data , dataFilt ) elif filtType == 'fastBandpass' : dataFilt = applyFilterFastBandpass ( channel_data , dataFilt ) elif filtType == 'fasterBandpass' : dataFilt = applyFilterFasterBandpass ( channel_data , dataFilt ) elif filtType == 'Litke' : dataFilt = applyFilterLitke ( channel_data , dataFilt ) elif filtType == 'none' : dataFilt = np . copy ( channel_data ) else : dataFilt = np . copy ( channel_data ) print ( 'Filter not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) return dataFilt","title":"Filters"},{"location":"filters/#filters","text":"","title":"Filters"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterAuto","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterAuto ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" samFreq = 20e3 * 1.0 passband = [ 250 , 4000 ] stopband = [ 5 , 6000 ] max_loss_passband = 3 min_loss_stopband = 30 order , normal_cutoff = signal . buttord ( passband , stopband , max_loss_passband , min_loss_stopband , fs = samFreq ) b , a = signal . butter ( order , normal_cutoff , btype = 'bandpass' , fs = samFreq ) print ( 'Order = ' + str ( order )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterAuto()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterFastBandpass","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterFastBandpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , analog = False ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterFastBandpass()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterFasterBandpass","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterFasterBandpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq sos1 = signal . butter ( 1 , [ cutoff1 , cutoff2 ], btype = 'bandpass' , output = 'sos' ) print ( 'Order = ' + str ( 1 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . sosfiltfilt ( sos1 , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterFasterBandpass()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterH0bandpass","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterH0bandpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 4000 / nyq b , a = signal . butter ( 5 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) print ( 'Order = ' + str ( 5 )) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterH0bandpass()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterHierlemann","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterHierlemann ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" BP_LOW_CUTOFF = 100.0 NUM_TAPS = 75 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( TAPS , [ a ], dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterHierlemann()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterHighpass","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterHighpass ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff = 250 / nyq b , a = signal . butter ( 5 , [ cutoff ], btype = \"highpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterHighpass()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterLitke","text":"Parameters: Name Type Description Default dataAll required dataFilt required numChan required chMap required Source code in app/src/data/filters.py def applyFilterLitke ( dataAll , dataFilt , numChan , chMap ): \"\"\" Args: dataAll: dataFilt: numChan: chMap: Returns: \"\"\" nyq = 0.5 * ( 20e3 * 1.0 ) cutoff1 = 250 / nyq cutoff2 = 2000 / nyq b , a = signal . butter ( 2 , [ cutoff1 , cutoff2 ], btype = \"bandpass\" , analog = False ) for k in range ( 0 , numChan ): start = time . time () dataFilt [ chMap [ 0 , k ], chMap [ 1 , k ], :] = signal . filtfilt ( b , a , dataAll [ chMap [ 0 , k ], chMap [ 1 , k ], :]) end = time . time () text1 = 'Estimated Time Remaining: ' + str . format ( ' {0:.2f} ' , ( end - start ) * ( numChan - k ) / 60 ) + ' min' text2 = str ( k + 1 ) + '/' + str ( numChan ) + ' Channels Filtered' print ( text1 + ' ' + text2 , end = \" \\r \" ) return dataFilt","title":"applyFilterLitke()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterModHierlemann","text":"Parameters: Name Type Description Default channel_data required dataFilt required Source code in app/src/data/filters.py def applyFilterModHierlemann ( channel_data , dataFilt ): \"\"\" Args: channel_data: dataFilt: Returns: \"\"\" BP_LOW_CUTOFF = 250.0 BP_HIGH_CUTOFF = 4000.0 NUM_TAPS = 100 TAPS = signal . firwin ( NUM_TAPS , [ BP_LOW_CUTOFF , BP_HIGH_CUTOFF ], pass_zero = False , fs = 20e3 * 1.0 ) a = 1 dataFilt = signal . filtfilt ( TAPS , [ a ], channel_data ) return dataFilt","title":"applyFilterModHierlemann()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterToAllData","text":"Parameters: Name Type Description Default dataAll required numChan required chMap required filtType 'modHierlemann' Source code in app/src/data/filters.py def applyFilterToAllData ( dataAll , numChan , chMap , filtType = 'modHierlemann' ): \"\"\" Args: dataAll: numChan: chMap: filtType: Returns: \"\"\" # Future update: only calculate for channels recorded not all dataFilt = np . zeros (( np . shape ( dataAll ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemann ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'modHierlemann' : dataFilt = applyFilterModHierlemann ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'highpass' : dataFilt = applyFilterHighpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'hObandpass' : dataFilt = applyFilterH0bandpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'auto' : dataFilt = applyFilterAuto ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'fastBandpass' : dataFilt = applyFilterFastBandpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'fasterBandpass' : dataFilt = applyFilterFasterBandpass ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'Litke' : dataFilt = applyFilterLitke ( dataAll , dataFilt , numChan , chMap ) elif filtType == 'none' : dataFilt = np . copy ( dataAll ) else : dataFilt = np . copy ( dataAll ) print ( 'Filter not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) return dataFilt","title":"applyFilterToAllData()"},{"location":"filters/#dc1DataVis.app.src.data.filters.applyFilterToChannelData","text":"Parameters: Name Type Description Default channel_data required filtType 'Hierlemann' Source code in app/src/data/filters.py def applyFilterToChannelData ( channel_data , filtType = 'Hierlemann' ): \"\"\" Args: channel_data: filtType: Returns: \"\"\" dataFilt = np . zeros (( np . shape ( channel_data ))) if filtType == 'Hierlemann' : dataFilt = applyFilterHierlemann ( channel_data , dataFilt ) elif filtType == 'modHierlemann' : dataFilt = applyFilterModHierlemann ( channel_data , dataFilt ) elif filtType == 'highpass' : dataFilt = applyFilterHighpass ( channel_data , dataFilt ) elif filtType == 'hObandpass' : dataFilt = applyFilterH0bandpass ( channel_data , dataFilt ) elif filtType == 'auto' : dataFilt = applyFilterAuto ( channel_data , dataFilt ) elif filtType == 'fastBandpass' : dataFilt = applyFilterFastBandpass ( channel_data , dataFilt ) elif filtType == 'fasterBandpass' : dataFilt = applyFilterFasterBandpass ( channel_data , dataFilt ) elif filtType == 'Litke' : dataFilt = applyFilterLitke ( channel_data , dataFilt ) elif filtType == 'none' : dataFilt = np . copy ( channel_data ) else : dataFilt = np . copy ( channel_data ) print ( 'Filter not recognized. Options include Hierlemann, highpass, bandpass, Litke or none' ) return dataFilt","title":"applyFilterToChannelData()"},{"location":"getting-started/","text":"","title":"Getting Started"},{"location":"gui-base/","text":"GUI Base Class Huy Nguyen (2022) Contains the base app framework for loading up the GUI. Note: To regenerate gui_layout.py, in terminal do pyuic5 layout.ui -o gui_layout.py MainWindow ( QMainWindow ) Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. Source code in app/src/gui/gui_base.py class MainWindow ( QtWidgets . QMainWindow ): \"\"\" Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. \"\"\" # MODES mode_profiling = True mode_multithreading = True first_time_plotting = True # GUI GRAPHS win1 , win2 , win3 , win4 = None , None , None , None # ==== DATA PARAMETERS ==== graph_params = None # ==== DATA CONTAINERS ==== # Raw data stream from chip, only double/triple/etc. counts removed LoadedData = None # TODO reconsolidate into new data containers data = None dataAll , cntAll , times = None , None , None numChan , chMap , chId , startIdx , findCoors = None , None , None , None , None filtered_data = None loading_dict = None p = None window_update_counter = 0 profile_data = None bar1 = None bar2 = None #crosshair region = None vLine , hLine = None , None vb = None proxy = None def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) # ====================== # DEBUGGING (tests + profiling) # ===================== self . graph_params = PyqtGraphParams ({}) if self . mode_profiling : print ( 'GUI is in profiling mode' ) self . profile_data = { 'append raw data' : [], 'filter data' : [], 'calculate array stats' : [], 'array map' : [], 'spike trace' : [], 'noise histogram' : [], 'spike rate' : [] } if self . mode_multithreading : print ( 'GUI is multithreading' ) # ===================== # FRONT END (GUI layout + design) # ===================== # Load layout based on QtDesigner .ui file uic . loadUi ( \"./src/gui/layout.ui\" , self ) # TODO make window system more flexible+modular # top left window = Array Map self . win1 = self . arrayMap self . win1 . setBackground ( 'w' ) self . win1 . showGrid ( x = True , y = True , alpha = 0 ) self . win1 . setXRange ( - 10 , 40 , padding = 0 ) self . win1 . setAspectLocked () self . win1 . setLimits ( xMin =- 10 , xMax = 45 , yMin =- 5 , yMax = 37 ) self . win1 . setLabel ( 'top' , \"Spike Amplitude\" ) self . win1 . setLabel ( 'left' , \"Electrode No. (vertical)\" ) self . win1 . setLabel ( 'bottom' , \"Electrode No. (horizontal)\" ) # top right = Trace Search self . win2 = self . traceplot_verticalLayout self . traceplot_1 . setBackground ( 'w' ) self . traceplot_2 . setBackground ( 'w' ) self . traceplot_3 . setBackground ( 'w' ) self . traceplot_4 . setBackground ( 'w' ) self . traceplot_1 . setLabel ( 'left' , \"# XXX\" ) self . traceplot_2 . setLabel ( 'left' , \"# XXX\" ) self . traceplot_3 . setLabel ( 'left' , \"# XXX\" ) self . traceplot_4 . setLabel ( 'left' , \"# XXX\" ) # bottom left = Spike Rate Plot self . win3 = self . spikeRatePlot self . win3 . setLabel ( 'top' , \"Noise\" ) self . win3 . setLabel ( 'left' , \"Count\" ) self . win3 . setLabel ( 'bottom' , \"Standard Dev\" ) self . win3 . setLimits ( xMin = 0 , yMin = 0 ) self . win3 . setBackground ( 'w' ) # bottom right window = Array Map self . win4 = self . miniMapWidget self . win4 . setBackground ( 'w' ) self . win4 . showGrid ( x = True , y = True , alpha = 0 ) self . win4 . setXRange ( - 10 , 40 , padding = 0 ) self . win4 . setAspectLocked () self . win4 . setLimits ( xMin =- 10 , xMax = 45 , yMin =- 5 , yMax = 37 ) self . win4 . setLabel ( 'top' , \"Spike Cnt\" ) self . win4 . setLabel ( 'left' , \"Electrode No. (vertical)\" ) self . win4 . setLabel ( 'bottom' , \"Electrode No. (horizontal)\" ) # init debug plot ## make interesting distribution of values vals = np . hstack ([ np . random . normal ( size = 500 ), np . random . normal ( size = 260 , loc = 4 )]) ## compute standard histogram y , x = np . histogram ( vals , bins = np . linspace ( - 3 , 8 , 40 )) ## notice that len(x) == len(y)+1 ## We are required to use stepMode=True so that PlotCurveItem will interpret this data correctly. curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . win3 . addItem ( curve ) # bottom right - Spike Rate Plot // MiniMap Widget -> in development # ====================== # BACKEND (multithreading + interactivity) # ===================== self . LoadedData = DC1DataContainer () # class for holding and manipulating data # Set up PyQt multithreading self . threadpool = QThreadPool () print ( \"Multithreading with maximum %d threads\" % self . threadpool . maxThreadCount ()) # >>>> MENU BAR <<<<< # TODO hook up interactivity for all menu bar buttons # >> FILE BUTTON self . action_npz . triggered . connect ( self . onActionLoadNPZ ) self . action_mat . triggered . connect ( self . onActionLoadMAT ) self . actionNew_session . triggered . connect ( self . onLoadRealtimeStream ) self . action_save_npz . triggered . connect ( self . plot ) self . action_save_mat . triggered . connect ( self . plot ) #hack no longer needed - self.windowTitleChanged.connect(self.newOfflineDataSession) # >> EDIT BUTTON # >> VIEW BUTTON # >> WINDOW BUTTON # >> SETTINGS BUTTON # >> HELP BUTTON # plot 1 - hover self . region = pg . LinearRegionItem () self . region . setZValue ( 10 ) # Add the LinearRegionItem to the ViewBox, but tell the ViewBox to exclude this # item when doing auto-range calculations. self . win1 . addItem ( self . region , ignoreBounds = True ) self . win1 . sigRangeChanged . connect ( self . updateRegion ) self . region . setRegion ([ - 10 , 50 ]) self . region . sigRegionChanged . connect ( self . update ) # cross hair self . vLine = pg . InfiniteLine ( angle = 90 , movable = False ) self . hLine = pg . InfiniteLine ( angle = 0 , movable = False ) self . win1 . addItem ( self . vLine , ignoreBounds = True ) self . win1 . addItem ( self . hLine , ignoreBounds = True ) self . vb = self . win1 . plotItem . vb self . proxy = pg . SignalProxy ( self . win1 . scene () . sigMouseMoved , rateLimit = 60 , slot = self . mouseMoved ) self . update_win1 () self . update_win4 () # END __INIT__ FUNCTION # ===================== # for crosshairs def update ( self ): self . region . setZValue ( 10 ) minX , maxX = self . region . getRegion () self . win1 . setXRange ( - 10 , 40 , padding = 0 ) def updateRegion ( self , window , viewRange ): rgn = viewRange [ 0 ] self . region . setRegion ( rgn ) def mouseMoved ( self , evt ): print ( \"mouseMoved\" ) pos = evt [ 0 ] ## using signal proxy turns original arguments into a tuple if self . win1 . sceneBoundingRect () . contains ( pos ): mousePoint = self . vb . mapSceneToView ( pos ) index = int ( mousePoint . x ()) if index > 0 and index < 100 : int_x = int ( mousePoint . x ()) int_y = int ( mousePoint . y ()) self . statusBar () . showMessage ( str ( int_x ) + \", \" + str ( int_y ) + \": \" + str ( self . LoadedData . array_stats [ 'spike_avg' ][ int_x ][ int_y ] ) ) self . vLine . setPos ( mousePoint . x ()) self . hLine . setPos ( mousePoint . y ()) \"\"\" ======================= MULTITHREADING PROGRESS FUNCS ======================= \"\"\" def progress_fn ( self , n ): print ( \" %d%% done\" % n ) def print_output ( self , s ): print ( s ) def thread_complete ( self ): print ( \"THREAD COMPLETE!\" ) \"\"\" ======================= MENU BAR // FILE... ======================= \"\"\" def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path def onLoadRealtimeStream ( self ): \"\"\" Returns: \"\"\" path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) self . loading_dict = initDataLoading ( path ) # TODO parallelize loading already saved .mat files load_realtime_worker = Worker ( self . realtimeLoading , path , self . loading_dict ) load_realtime_worker . signals . progress . connect ( self . updateStatusBar ) load_realtime_worker . signals . gui_callback . connect ( self . updateGUIWithNewData ) self . threadpool . start ( load_realtime_worker ) # callback from progress signal def updateStatusBar ( self , message ): self . statusBar () . showMessage ( message ) # Continuously Check for New Data def realtimeLoading ( self , path , loadingDict , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] last_file_idx = 0 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'append raw data' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filter data' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculate array stats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit () def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData () def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) #worker.signals.finished.connect(self.thread_complete) #worker.signals.progress.connect(self.progress_fn) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict ) def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = 'modHierlemann' ) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData () def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession print ( \"GUI Counter: \" , self . window_update_counter ) start = time . time () self . update_win1 () end = time . time () if self . mode_profiling : self . profile_data [ 'array map' ] . append ( end - start ) start = time . time () self . update_win2 () end = time . time () if self . mode_profiling : self . profile_data [ 'spike trace' ] . append ( end - start ) start = time . time () self . update_win3 () end = time . time () if self . mode_profiling : self . profile_data [ 'noise histogram' ] . append ( end - start ) self . update_win4 () if self . mode_profiling : print ( \"Current profiling statistics:\" ) for key in self . profile_data . keys (): avg_time = np . round ( np . mean ( self . profile_data [ key ]), 3 ) print ( key , avg_time ) print ( \"\" ) def update_win1 ( self ): self . win1 . clear () # prepare demonstration data: if self . first_time_plotting is False : colors = self . LoadedData . array_stats [ 'spike_avg' ] data = colors . T else : data = np . fromfunction ( lambda i , j : ( 1 + 0.3 * np . sin ( i )) * ( i ) ** 2 + ( j ) ** 2 , ( 32 , 32 )) data = data * ( 1 + 0.2 * np . random . random ( data . shape )) # Example: False color image with interactive level adjustment #self.first_time_plotting = False cm = pg . colormap . get ( 'CET-D1' ) image = pg . ImageItem ( data ) self . win1 . clear () self . win1 . addItem ( image ) # bound the LinearRegionItem to the plotted data self . region . setClipItem ( image ) # TODO fix color limits self . win1 . addColorBar ( image , colorMap = cm , values = ( 0 , np . max ( data ))) def update_win2 ( self ): trace_plots = [ self . traceplot_1 , self . traceplot_2 , self . traceplot_3 , self . traceplot_4 ] len_data = len ( self . LoadedData . filtered_data ) # Generate subplots for m , plt in enumerate ( trace_plots ): chan_idx = len_data + ( m - 4 ) x = self . LoadedData . filtered_data [ chan_idx ][ 'times' ] y = self . LoadedData . filtered_data [ chan_idx ][ 'data' ] plt . clear () plt . plot ( x , y , pen = 'b' ) plt . setLabel ( 'left' , '#' + str ( self . LoadedData . filtered_data [ chan_idx ][ 'channel_idx' ])) plt . enableAutoRange ( axis = 'y' ) plt . setAutoVisible ( y = True ) def update_win3 ( self ): self . win3 . clear () vals = self . LoadedData . array_stats [ 'noise_std' ] vals = vals [ np . nonzero ( vals )] # get nonzero vals because zeros have not had noise calculation done yet y , x = np . histogram ( vals , bins = np . linspace ( 0 , 20 , 40 )) curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . win3 . addItem ( curve ) def update_win4 ( self ): self . win4 . clear () # prepare demonstration data: if self . first_time_plotting is False : spike_cnt = self . LoadedData . array_stats [ 'spike_cnt' ] # AX1) Size by Number of Samples scale1 = ( max_dot - 15 ) / ( np . max ( spike_cnt ) - np . min ( spike_cnt [ spike_cnt != 0 ])) b_add = max_dot - ( np . max ( spike_cnt ) * scale1 ) size = np . round ( spike_cnt * scale1 + b_add ) size [ size < 15 ] = 10 data = spike_cnt . T else : data = np . fromfunction ( lambda i , j : ( 1 + 0.3 * np . sin ( i )) * ( i ) ** 2 + ( j ) ** 2 , ( 32 , 32 )) data = data * ( 1 + 0.2 * np . random . random ( data . shape )) self . first_time_plotting = False # Example: False color image with interactive level adjustment #self.first_time_plotting = False cm = pg . colormap . get ( 'CET-D1' ) image = pg . ImageItem ( data ) self . win4 . addItem ( image ) # TODO fix color limits self . win4 . addColorBar ( image , colorMap = cm , values = ( 0 , np . max ( data ))) def change_win1 ( self ): self . horizontalLayout_top . removeItem ( self . win1 ) self . horizontalLayout_top . addItem ( self . win1 ) def plot_data ( self , widget , x , y ): widget . plot ( x , y ) \"\"\" ======================= MENU BAR // EDIT... ======================= \"\"\" \"\"\" ======================= MENU BAR // VIEW... ======================= \"\"\" \"\"\" ======================= MENU BAR // WINDOW... ======================= \"\"\" # TODO func - update window with new data def updateWindowWithNewData ( self , window ): pass \"\"\" ======================= MENU BAR // SETTINGS... ======================= \"\"\" \"\"\" ======================= TEST FUNCTIONS ======================= \"\"\" def plot ( self , hour , temperature ): self . traceplot_1 . plot ( hour , temperature ) getDataPath ( self , file_type ) Parameters: Name Type Description Default file_type str required Source code in app/src/gui/gui_base.py def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path loadDataFromFileMat ( self , path , loadingDict ) Parameters: Name Type Description Default path required loadingDict required Source code in app/src/gui/gui_base.py def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = 'modHierlemann' ) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData () onActionLoadMAT ( self ) Source code in app/src/gui/gui_base.py def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) #worker.signals.finished.connect(self.thread_complete) #worker.signals.progress.connect(self.progress_fn) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict ) onActionLoadNPZ ( self ) Source code in app/src/gui/gui_base.py def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData () onLoadRealtimeStream ( self ) Source code in app/src/gui/gui_base.py def onLoadRealtimeStream ( self ): \"\"\" Returns: \"\"\" path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) self . loading_dict = initDataLoading ( path ) # TODO parallelize loading already saved .mat files load_realtime_worker = Worker ( self . realtimeLoading , path , self . loading_dict ) load_realtime_worker . signals . progress . connect ( self . updateStatusBar ) load_realtime_worker . signals . gui_callback . connect ( self . updateGUIWithNewData ) self . threadpool . start ( load_realtime_worker ) realtimeLoading ( self , path , loadingDict , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ) Parameters: Name Type Description Default path required loadingDict required progress_callback required gui_callback required dataIdentifierString 'gmem1' Source code in app/src/gui/gui_base.py def realtimeLoading ( self , path , loadingDict , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] last_file_idx = 0 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'append raw data' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filter data' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculate array stats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit () update ( self ) update(self) update(self, QRect) update(self, QRegion) update(self, int, int, int, int) Source code in app/src/gui/gui_base.py def update ( self ): self . region . setZValue ( 10 ) minX , maxX = self . region . getRegion () self . win1 . setXRange ( - 10 , 40 , padding = 0 ) updateGUIWithNewData ( self ) Source code in app/src/gui/gui_base.py def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession print ( \"GUI Counter: \" , self . window_update_counter ) start = time . time () self . update_win1 () end = time . time () if self . mode_profiling : self . profile_data [ 'array map' ] . append ( end - start ) start = time . time () self . update_win2 () end = time . time () if self . mode_profiling : self . profile_data [ 'spike trace' ] . append ( end - start ) start = time . time () self . update_win3 () end = time . time () if self . mode_profiling : self . profile_data [ 'noise histogram' ] . append ( end - start ) self . update_win4 () if self . mode_profiling : print ( \"Current profiling statistics:\" ) for key in self . profile_data . keys (): avg_time = np . round ( np . mean ( self . profile_data [ key ]), 3 ) print ( key , avg_time ) print ( \"\" ) Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. Source code in app/src/gui/gui_base.py class MainWindow ( QtWidgets . QMainWindow ): \"\"\" Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. \"\"\" # MODES mode_profiling = True mode_multithreading = True first_time_plotting = True # GUI GRAPHS win1 , win2 , win3 , win4 = None , None , None , None # ==== DATA PARAMETERS ==== graph_params = None # ==== DATA CONTAINERS ==== # Raw data stream from chip, only double/triple/etc. counts removed LoadedData = None # TODO reconsolidate into new data containers data = None dataAll , cntAll , times = None , None , None numChan , chMap , chId , startIdx , findCoors = None , None , None , None , None filtered_data = None loading_dict = None p = None window_update_counter = 0 profile_data = None bar1 = None bar2 = None #crosshair region = None vLine , hLine = None , None vb = None proxy = None def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) # ====================== # DEBUGGING (tests + profiling) # ===================== self . graph_params = PyqtGraphParams ({}) if self . mode_profiling : print ( 'GUI is in profiling mode' ) self . profile_data = { 'append raw data' : [], 'filter data' : [], 'calculate array stats' : [], 'array map' : [], 'spike trace' : [], 'noise histogram' : [], 'spike rate' : [] } if self . mode_multithreading : print ( 'GUI is multithreading' ) # ===================== # FRONT END (GUI layout + design) # ===================== # Load layout based on QtDesigner .ui file uic . loadUi ( \"./src/gui/layout.ui\" , self ) # TODO make window system more flexible+modular # top left window = Array Map self . win1 = self . arrayMap self . win1 . setBackground ( 'w' ) self . win1 . showGrid ( x = True , y = True , alpha = 0 ) self . win1 . setXRange ( - 10 , 40 , padding = 0 ) self . win1 . setAspectLocked () self . win1 . setLimits ( xMin =- 10 , xMax = 45 , yMin =- 5 , yMax = 37 ) self . win1 . setLabel ( 'top' , \"Spike Amplitude\" ) self . win1 . setLabel ( 'left' , \"Electrode No. (vertical)\" ) self . win1 . setLabel ( 'bottom' , \"Electrode No. (horizontal)\" ) # top right = Trace Search self . win2 = self . traceplot_verticalLayout self . traceplot_1 . setBackground ( 'w' ) self . traceplot_2 . setBackground ( 'w' ) self . traceplot_3 . setBackground ( 'w' ) self . traceplot_4 . setBackground ( 'w' ) self . traceplot_1 . setLabel ( 'left' , \"# XXX\" ) self . traceplot_2 . setLabel ( 'left' , \"# XXX\" ) self . traceplot_3 . setLabel ( 'left' , \"# XXX\" ) self . traceplot_4 . setLabel ( 'left' , \"# XXX\" ) # bottom left = Spike Rate Plot self . win3 = self . spikeRatePlot self . win3 . setLabel ( 'top' , \"Noise\" ) self . win3 . setLabel ( 'left' , \"Count\" ) self . win3 . setLabel ( 'bottom' , \"Standard Dev\" ) self . win3 . setLimits ( xMin = 0 , yMin = 0 ) self . win3 . setBackground ( 'w' ) # bottom right window = Array Map self . win4 = self . miniMapWidget self . win4 . setBackground ( 'w' ) self . win4 . showGrid ( x = True , y = True , alpha = 0 ) self . win4 . setXRange ( - 10 , 40 , padding = 0 ) self . win4 . setAspectLocked () self . win4 . setLimits ( xMin =- 10 , xMax = 45 , yMin =- 5 , yMax = 37 ) self . win4 . setLabel ( 'top' , \"Spike Cnt\" ) self . win4 . setLabel ( 'left' , \"Electrode No. (vertical)\" ) self . win4 . setLabel ( 'bottom' , \"Electrode No. (horizontal)\" ) # init debug plot ## make interesting distribution of values vals = np . hstack ([ np . random . normal ( size = 500 ), np . random . normal ( size = 260 , loc = 4 )]) ## compute standard histogram y , x = np . histogram ( vals , bins = np . linspace ( - 3 , 8 , 40 )) ## notice that len(x) == len(y)+1 ## We are required to use stepMode=True so that PlotCurveItem will interpret this data correctly. curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . win3 . addItem ( curve ) # bottom right - Spike Rate Plot // MiniMap Widget -> in development # ====================== # BACKEND (multithreading + interactivity) # ===================== self . LoadedData = DC1DataContainer () # class for holding and manipulating data # Set up PyQt multithreading self . threadpool = QThreadPool () print ( \"Multithreading with maximum %d threads\" % self . threadpool . maxThreadCount ()) # >>>> MENU BAR <<<<< # TODO hook up interactivity for all menu bar buttons # >> FILE BUTTON self . action_npz . triggered . connect ( self . onActionLoadNPZ ) self . action_mat . triggered . connect ( self . onActionLoadMAT ) self . actionNew_session . triggered . connect ( self . onLoadRealtimeStream ) self . action_save_npz . triggered . connect ( self . plot ) self . action_save_mat . triggered . connect ( self . plot ) #hack no longer needed - self.windowTitleChanged.connect(self.newOfflineDataSession) # >> EDIT BUTTON # >> VIEW BUTTON # >> WINDOW BUTTON # >> SETTINGS BUTTON # >> HELP BUTTON # plot 1 - hover self . region = pg . LinearRegionItem () self . region . setZValue ( 10 ) # Add the LinearRegionItem to the ViewBox, but tell the ViewBox to exclude this # item when doing auto-range calculations. self . win1 . addItem ( self . region , ignoreBounds = True ) self . win1 . sigRangeChanged . connect ( self . updateRegion ) self . region . setRegion ([ - 10 , 50 ]) self . region . sigRegionChanged . connect ( self . update ) # cross hair self . vLine = pg . InfiniteLine ( angle = 90 , movable = False ) self . hLine = pg . InfiniteLine ( angle = 0 , movable = False ) self . win1 . addItem ( self . vLine , ignoreBounds = True ) self . win1 . addItem ( self . hLine , ignoreBounds = True ) self . vb = self . win1 . plotItem . vb self . proxy = pg . SignalProxy ( self . win1 . scene () . sigMouseMoved , rateLimit = 60 , slot = self . mouseMoved ) self . update_win1 () self . update_win4 () # END __INIT__ FUNCTION # ===================== # for crosshairs def update ( self ): self . region . setZValue ( 10 ) minX , maxX = self . region . getRegion () self . win1 . setXRange ( - 10 , 40 , padding = 0 ) def updateRegion ( self , window , viewRange ): rgn = viewRange [ 0 ] self . region . setRegion ( rgn ) def mouseMoved ( self , evt ): print ( \"mouseMoved\" ) pos = evt [ 0 ] ## using signal proxy turns original arguments into a tuple if self . win1 . sceneBoundingRect () . contains ( pos ): mousePoint = self . vb . mapSceneToView ( pos ) index = int ( mousePoint . x ()) if index > 0 and index < 100 : int_x = int ( mousePoint . x ()) int_y = int ( mousePoint . y ()) self . statusBar () . showMessage ( str ( int_x ) + \", \" + str ( int_y ) + \": \" + str ( self . LoadedData . array_stats [ 'spike_avg' ][ int_x ][ int_y ] ) ) self . vLine . setPos ( mousePoint . x ()) self . hLine . setPos ( mousePoint . y ()) \"\"\" ======================= MULTITHREADING PROGRESS FUNCS ======================= \"\"\" def progress_fn ( self , n ): print ( \" %d%% done\" % n ) def print_output ( self , s ): print ( s ) def thread_complete ( self ): print ( \"THREAD COMPLETE!\" ) \"\"\" ======================= MENU BAR // FILE... ======================= \"\"\" def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path def onLoadRealtimeStream ( self ): \"\"\" Returns: \"\"\" path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) self . loading_dict = initDataLoading ( path ) # TODO parallelize loading already saved .mat files load_realtime_worker = Worker ( self . realtimeLoading , path , self . loading_dict ) load_realtime_worker . signals . progress . connect ( self . updateStatusBar ) load_realtime_worker . signals . gui_callback . connect ( self . updateGUIWithNewData ) self . threadpool . start ( load_realtime_worker ) # callback from progress signal def updateStatusBar ( self , message ): self . statusBar () . showMessage ( message ) # Continuously Check for New Data def realtimeLoading ( self , path , loadingDict , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] last_file_idx = 0 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'append raw data' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filter data' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculate array stats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit () def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData () def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) #worker.signals.finished.connect(self.thread_complete) #worker.signals.progress.connect(self.progress_fn) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict ) def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = 'modHierlemann' ) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData () def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession print ( \"GUI Counter: \" , self . window_update_counter ) start = time . time () self . update_win1 () end = time . time () if self . mode_profiling : self . profile_data [ 'array map' ] . append ( end - start ) start = time . time () self . update_win2 () end = time . time () if self . mode_profiling : self . profile_data [ 'spike trace' ] . append ( end - start ) start = time . time () self . update_win3 () end = time . time () if self . mode_profiling : self . profile_data [ 'noise histogram' ] . append ( end - start ) self . update_win4 () if self . mode_profiling : print ( \"Current profiling statistics:\" ) for key in self . profile_data . keys (): avg_time = np . round ( np . mean ( self . profile_data [ key ]), 3 ) print ( key , avg_time ) print ( \"\" ) def update_win1 ( self ): self . win1 . clear () # prepare demonstration data: if self . first_time_plotting is False : colors = self . LoadedData . array_stats [ 'spike_avg' ] data = colors . T else : data = np . fromfunction ( lambda i , j : ( 1 + 0.3 * np . sin ( i )) * ( i ) ** 2 + ( j ) ** 2 , ( 32 , 32 )) data = data * ( 1 + 0.2 * np . random . random ( data . shape )) # Example: False color image with interactive level adjustment #self.first_time_plotting = False cm = pg . colormap . get ( 'CET-D1' ) image = pg . ImageItem ( data ) self . win1 . clear () self . win1 . addItem ( image ) # bound the LinearRegionItem to the plotted data self . region . setClipItem ( image ) # TODO fix color limits self . win1 . addColorBar ( image , colorMap = cm , values = ( 0 , np . max ( data ))) def update_win2 ( self ): trace_plots = [ self . traceplot_1 , self . traceplot_2 , self . traceplot_3 , self . traceplot_4 ] len_data = len ( self . LoadedData . filtered_data ) # Generate subplots for m , plt in enumerate ( trace_plots ): chan_idx = len_data + ( m - 4 ) x = self . LoadedData . filtered_data [ chan_idx ][ 'times' ] y = self . LoadedData . filtered_data [ chan_idx ][ 'data' ] plt . clear () plt . plot ( x , y , pen = 'b' ) plt . setLabel ( 'left' , '#' + str ( self . LoadedData . filtered_data [ chan_idx ][ 'channel_idx' ])) plt . enableAutoRange ( axis = 'y' ) plt . setAutoVisible ( y = True ) def update_win3 ( self ): self . win3 . clear () vals = self . LoadedData . array_stats [ 'noise_std' ] vals = vals [ np . nonzero ( vals )] # get nonzero vals because zeros have not had noise calculation done yet y , x = np . histogram ( vals , bins = np . linspace ( 0 , 20 , 40 )) curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . win3 . addItem ( curve ) def update_win4 ( self ): self . win4 . clear () # prepare demonstration data: if self . first_time_plotting is False : spike_cnt = self . LoadedData . array_stats [ 'spike_cnt' ] # AX1) Size by Number of Samples scale1 = ( max_dot - 15 ) / ( np . max ( spike_cnt ) - np . min ( spike_cnt [ spike_cnt != 0 ])) b_add = max_dot - ( np . max ( spike_cnt ) * scale1 ) size = np . round ( spike_cnt * scale1 + b_add ) size [ size < 15 ] = 10 data = spike_cnt . T else : data = np . fromfunction ( lambda i , j : ( 1 + 0.3 * np . sin ( i )) * ( i ) ** 2 + ( j ) ** 2 , ( 32 , 32 )) data = data * ( 1 + 0.2 * np . random . random ( data . shape )) self . first_time_plotting = False # Example: False color image with interactive level adjustment #self.first_time_plotting = False cm = pg . colormap . get ( 'CET-D1' ) image = pg . ImageItem ( data ) self . win4 . addItem ( image ) # TODO fix color limits self . win4 . addColorBar ( image , colorMap = cm , values = ( 0 , np . max ( data ))) def change_win1 ( self ): self . horizontalLayout_top . removeItem ( self . win1 ) self . horizontalLayout_top . addItem ( self . win1 ) def plot_data ( self , widget , x , y ): widget . plot ( x , y ) \"\"\" ======================= MENU BAR // EDIT... ======================= \"\"\" \"\"\" ======================= MENU BAR // VIEW... ======================= \"\"\" \"\"\" ======================= MENU BAR // WINDOW... ======================= \"\"\" # TODO func - update window with new data def updateWindowWithNewData ( self , window ): pass \"\"\" ======================= MENU BAR // SETTINGS... ======================= \"\"\" \"\"\" ======================= TEST FUNCTIONS ======================= \"\"\" def plot ( self , hour , temperature ): self . traceplot_1 . plot ( hour , temperature ) getDataPath ( self , file_type ) Parameters: Name Type Description Default file_type str required Source code in app/src/gui/gui_base.py def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path loadDataFromFileMat ( self , path , loadingDict ) Parameters: Name Type Description Default path required loadingDict required Source code in app/src/gui/gui_base.py def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = 'modHierlemann' ) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData () onActionLoadMAT ( self ) Source code in app/src/gui/gui_base.py def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) #worker.signals.finished.connect(self.thread_complete) #worker.signals.progress.connect(self.progress_fn) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict ) onActionLoadNPZ ( self ) Source code in app/src/gui/gui_base.py def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData () onLoadRealtimeStream ( self ) Source code in app/src/gui/gui_base.py def onLoadRealtimeStream ( self ): \"\"\" Returns: \"\"\" path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) self . loading_dict = initDataLoading ( path ) # TODO parallelize loading already saved .mat files load_realtime_worker = Worker ( self . realtimeLoading , path , self . loading_dict ) load_realtime_worker . signals . progress . connect ( self . updateStatusBar ) load_realtime_worker . signals . gui_callback . connect ( self . updateGUIWithNewData ) self . threadpool . start ( load_realtime_worker ) realtimeLoading ( self , path , loadingDict , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ) Parameters: Name Type Description Default path required loadingDict required progress_callback required gui_callback required dataIdentifierString 'gmem1' Source code in app/src/gui/gui_base.py def realtimeLoading ( self , path , loadingDict , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] last_file_idx = 0 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'append raw data' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filter data' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculate array stats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit () update ( self ) update(self) update(self, QRect) update(self, QRegion) update(self, int, int, int, int) Source code in app/src/gui/gui_base.py def update ( self ): self . region . setZValue ( 10 ) minX , maxX = self . region . getRegion () self . win1 . setXRange ( - 10 , 40 , padding = 0 ) updateGUIWithNewData ( self ) Source code in app/src/gui/gui_base.py def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession print ( \"GUI Counter: \" , self . window_update_counter ) start = time . time () self . update_win1 () end = time . time () if self . mode_profiling : self . profile_data [ 'array map' ] . append ( end - start ) start = time . time () self . update_win2 () end = time . time () if self . mode_profiling : self . profile_data [ 'spike trace' ] . append ( end - start ) start = time . time () self . update_win3 () end = time . time () if self . mode_profiling : self . profile_data [ 'noise histogram' ] . append ( end - start ) self . update_win4 () if self . mode_profiling : print ( \"Current profiling statistics:\" ) for key in self . profile_data . keys (): avg_time = np . round ( np . mean ( self . profile_data [ key ]), 3 ) print ( key , avg_time ) print ( \"\" )","title":"Base"},{"location":"gui-base/#gui-base-class","text":"Huy Nguyen (2022) Contains the base app framework for loading up the GUI. Note: To regenerate gui_layout.py, in terminal do pyuic5 layout.ui -o gui_layout.py","title":"GUI Base Class"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow","text":"Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. Source code in app/src/gui/gui_base.py class MainWindow ( QtWidgets . QMainWindow ): \"\"\" Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. \"\"\" # MODES mode_profiling = True mode_multithreading = True first_time_plotting = True # GUI GRAPHS win1 , win2 , win3 , win4 = None , None , None , None # ==== DATA PARAMETERS ==== graph_params = None # ==== DATA CONTAINERS ==== # Raw data stream from chip, only double/triple/etc. counts removed LoadedData = None # TODO reconsolidate into new data containers data = None dataAll , cntAll , times = None , None , None numChan , chMap , chId , startIdx , findCoors = None , None , None , None , None filtered_data = None loading_dict = None p = None window_update_counter = 0 profile_data = None bar1 = None bar2 = None #crosshair region = None vLine , hLine = None , None vb = None proxy = None def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) # ====================== # DEBUGGING (tests + profiling) # ===================== self . graph_params = PyqtGraphParams ({}) if self . mode_profiling : print ( 'GUI is in profiling mode' ) self . profile_data = { 'append raw data' : [], 'filter data' : [], 'calculate array stats' : [], 'array map' : [], 'spike trace' : [], 'noise histogram' : [], 'spike rate' : [] } if self . mode_multithreading : print ( 'GUI is multithreading' ) # ===================== # FRONT END (GUI layout + design) # ===================== # Load layout based on QtDesigner .ui file uic . loadUi ( \"./src/gui/layout.ui\" , self ) # TODO make window system more flexible+modular # top left window = Array Map self . win1 = self . arrayMap self . win1 . setBackground ( 'w' ) self . win1 . showGrid ( x = True , y = True , alpha = 0 ) self . win1 . setXRange ( - 10 , 40 , padding = 0 ) self . win1 . setAspectLocked () self . win1 . setLimits ( xMin =- 10 , xMax = 45 , yMin =- 5 , yMax = 37 ) self . win1 . setLabel ( 'top' , \"Spike Amplitude\" ) self . win1 . setLabel ( 'left' , \"Electrode No. (vertical)\" ) self . win1 . setLabel ( 'bottom' , \"Electrode No. (horizontal)\" ) # top right = Trace Search self . win2 = self . traceplot_verticalLayout self . traceplot_1 . setBackground ( 'w' ) self . traceplot_2 . setBackground ( 'w' ) self . traceplot_3 . setBackground ( 'w' ) self . traceplot_4 . setBackground ( 'w' ) self . traceplot_1 . setLabel ( 'left' , \"# XXX\" ) self . traceplot_2 . setLabel ( 'left' , \"# XXX\" ) self . traceplot_3 . setLabel ( 'left' , \"# XXX\" ) self . traceplot_4 . setLabel ( 'left' , \"# XXX\" ) # bottom left = Spike Rate Plot self . win3 = self . spikeRatePlot self . win3 . setLabel ( 'top' , \"Noise\" ) self . win3 . setLabel ( 'left' , \"Count\" ) self . win3 . setLabel ( 'bottom' , \"Standard Dev\" ) self . win3 . setLimits ( xMin = 0 , yMin = 0 ) self . win3 . setBackground ( 'w' ) # bottom right window = Array Map self . win4 = self . miniMapWidget self . win4 . setBackground ( 'w' ) self . win4 . showGrid ( x = True , y = True , alpha = 0 ) self . win4 . setXRange ( - 10 , 40 , padding = 0 ) self . win4 . setAspectLocked () self . win4 . setLimits ( xMin =- 10 , xMax = 45 , yMin =- 5 , yMax = 37 ) self . win4 . setLabel ( 'top' , \"Spike Cnt\" ) self . win4 . setLabel ( 'left' , \"Electrode No. (vertical)\" ) self . win4 . setLabel ( 'bottom' , \"Electrode No. (horizontal)\" ) # init debug plot ## make interesting distribution of values vals = np . hstack ([ np . random . normal ( size = 500 ), np . random . normal ( size = 260 , loc = 4 )]) ## compute standard histogram y , x = np . histogram ( vals , bins = np . linspace ( - 3 , 8 , 40 )) ## notice that len(x) == len(y)+1 ## We are required to use stepMode=True so that PlotCurveItem will interpret this data correctly. curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . win3 . addItem ( curve ) # bottom right - Spike Rate Plot // MiniMap Widget -> in development # ====================== # BACKEND (multithreading + interactivity) # ===================== self . LoadedData = DC1DataContainer () # class for holding and manipulating data # Set up PyQt multithreading self . threadpool = QThreadPool () print ( \"Multithreading with maximum %d threads\" % self . threadpool . maxThreadCount ()) # >>>> MENU BAR <<<<< # TODO hook up interactivity for all menu bar buttons # >> FILE BUTTON self . action_npz . triggered . connect ( self . onActionLoadNPZ ) self . action_mat . triggered . connect ( self . onActionLoadMAT ) self . actionNew_session . triggered . connect ( self . onLoadRealtimeStream ) self . action_save_npz . triggered . connect ( self . plot ) self . action_save_mat . triggered . connect ( self . plot ) #hack no longer needed - self.windowTitleChanged.connect(self.newOfflineDataSession) # >> EDIT BUTTON # >> VIEW BUTTON # >> WINDOW BUTTON # >> SETTINGS BUTTON # >> HELP BUTTON # plot 1 - hover self . region = pg . LinearRegionItem () self . region . setZValue ( 10 ) # Add the LinearRegionItem to the ViewBox, but tell the ViewBox to exclude this # item when doing auto-range calculations. self . win1 . addItem ( self . region , ignoreBounds = True ) self . win1 . sigRangeChanged . connect ( self . updateRegion ) self . region . setRegion ([ - 10 , 50 ]) self . region . sigRegionChanged . connect ( self . update ) # cross hair self . vLine = pg . InfiniteLine ( angle = 90 , movable = False ) self . hLine = pg . InfiniteLine ( angle = 0 , movable = False ) self . win1 . addItem ( self . vLine , ignoreBounds = True ) self . win1 . addItem ( self . hLine , ignoreBounds = True ) self . vb = self . win1 . plotItem . vb self . proxy = pg . SignalProxy ( self . win1 . scene () . sigMouseMoved , rateLimit = 60 , slot = self . mouseMoved ) self . update_win1 () self . update_win4 () # END __INIT__ FUNCTION # ===================== # for crosshairs def update ( self ): self . region . setZValue ( 10 ) minX , maxX = self . region . getRegion () self . win1 . setXRange ( - 10 , 40 , padding = 0 ) def updateRegion ( self , window , viewRange ): rgn = viewRange [ 0 ] self . region . setRegion ( rgn ) def mouseMoved ( self , evt ): print ( \"mouseMoved\" ) pos = evt [ 0 ] ## using signal proxy turns original arguments into a tuple if self . win1 . sceneBoundingRect () . contains ( pos ): mousePoint = self . vb . mapSceneToView ( pos ) index = int ( mousePoint . x ()) if index > 0 and index < 100 : int_x = int ( mousePoint . x ()) int_y = int ( mousePoint . y ()) self . statusBar () . showMessage ( str ( int_x ) + \", \" + str ( int_y ) + \": \" + str ( self . LoadedData . array_stats [ 'spike_avg' ][ int_x ][ int_y ] ) ) self . vLine . setPos ( mousePoint . x ()) self . hLine . setPos ( mousePoint . y ()) \"\"\" ======================= MULTITHREADING PROGRESS FUNCS ======================= \"\"\" def progress_fn ( self , n ): print ( \" %d%% done\" % n ) def print_output ( self , s ): print ( s ) def thread_complete ( self ): print ( \"THREAD COMPLETE!\" ) \"\"\" ======================= MENU BAR // FILE... ======================= \"\"\" def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path def onLoadRealtimeStream ( self ): \"\"\" Returns: \"\"\" path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) self . loading_dict = initDataLoading ( path ) # TODO parallelize loading already saved .mat files load_realtime_worker = Worker ( self . realtimeLoading , path , self . loading_dict ) load_realtime_worker . signals . progress . connect ( self . updateStatusBar ) load_realtime_worker . signals . gui_callback . connect ( self . updateGUIWithNewData ) self . threadpool . start ( load_realtime_worker ) # callback from progress signal def updateStatusBar ( self , message ): self . statusBar () . showMessage ( message ) # Continuously Check for New Data def realtimeLoading ( self , path , loadingDict , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] last_file_idx = 0 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'append raw data' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filter data' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculate array stats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit () def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData () def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) #worker.signals.finished.connect(self.thread_complete) #worker.signals.progress.connect(self.progress_fn) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict ) def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = 'modHierlemann' ) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData () def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession print ( \"GUI Counter: \" , self . window_update_counter ) start = time . time () self . update_win1 () end = time . time () if self . mode_profiling : self . profile_data [ 'array map' ] . append ( end - start ) start = time . time () self . update_win2 () end = time . time () if self . mode_profiling : self . profile_data [ 'spike trace' ] . append ( end - start ) start = time . time () self . update_win3 () end = time . time () if self . mode_profiling : self . profile_data [ 'noise histogram' ] . append ( end - start ) self . update_win4 () if self . mode_profiling : print ( \"Current profiling statistics:\" ) for key in self . profile_data . keys (): avg_time = np . round ( np . mean ( self . profile_data [ key ]), 3 ) print ( key , avg_time ) print ( \"\" ) def update_win1 ( self ): self . win1 . clear () # prepare demonstration data: if self . first_time_plotting is False : colors = self . LoadedData . array_stats [ 'spike_avg' ] data = colors . T else : data = np . fromfunction ( lambda i , j : ( 1 + 0.3 * np . sin ( i )) * ( i ) ** 2 + ( j ) ** 2 , ( 32 , 32 )) data = data * ( 1 + 0.2 * np . random . random ( data . shape )) # Example: False color image with interactive level adjustment #self.first_time_plotting = False cm = pg . colormap . get ( 'CET-D1' ) image = pg . ImageItem ( data ) self . win1 . clear () self . win1 . addItem ( image ) # bound the LinearRegionItem to the plotted data self . region . setClipItem ( image ) # TODO fix color limits self . win1 . addColorBar ( image , colorMap = cm , values = ( 0 , np . max ( data ))) def update_win2 ( self ): trace_plots = [ self . traceplot_1 , self . traceplot_2 , self . traceplot_3 , self . traceplot_4 ] len_data = len ( self . LoadedData . filtered_data ) # Generate subplots for m , plt in enumerate ( trace_plots ): chan_idx = len_data + ( m - 4 ) x = self . LoadedData . filtered_data [ chan_idx ][ 'times' ] y = self . LoadedData . filtered_data [ chan_idx ][ 'data' ] plt . clear () plt . plot ( x , y , pen = 'b' ) plt . setLabel ( 'left' , '#' + str ( self . LoadedData . filtered_data [ chan_idx ][ 'channel_idx' ])) plt . enableAutoRange ( axis = 'y' ) plt . setAutoVisible ( y = True ) def update_win3 ( self ): self . win3 . clear () vals = self . LoadedData . array_stats [ 'noise_std' ] vals = vals [ np . nonzero ( vals )] # get nonzero vals because zeros have not had noise calculation done yet y , x = np . histogram ( vals , bins = np . linspace ( 0 , 20 , 40 )) curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . win3 . addItem ( curve ) def update_win4 ( self ): self . win4 . clear () # prepare demonstration data: if self . first_time_plotting is False : spike_cnt = self . LoadedData . array_stats [ 'spike_cnt' ] # AX1) Size by Number of Samples scale1 = ( max_dot - 15 ) / ( np . max ( spike_cnt ) - np . min ( spike_cnt [ spike_cnt != 0 ])) b_add = max_dot - ( np . max ( spike_cnt ) * scale1 ) size = np . round ( spike_cnt * scale1 + b_add ) size [ size < 15 ] = 10 data = spike_cnt . T else : data = np . fromfunction ( lambda i , j : ( 1 + 0.3 * np . sin ( i )) * ( i ) ** 2 + ( j ) ** 2 , ( 32 , 32 )) data = data * ( 1 + 0.2 * np . random . random ( data . shape )) self . first_time_plotting = False # Example: False color image with interactive level adjustment #self.first_time_plotting = False cm = pg . colormap . get ( 'CET-D1' ) image = pg . ImageItem ( data ) self . win4 . addItem ( image ) # TODO fix color limits self . win4 . addColorBar ( image , colorMap = cm , values = ( 0 , np . max ( data ))) def change_win1 ( self ): self . horizontalLayout_top . removeItem ( self . win1 ) self . horizontalLayout_top . addItem ( self . win1 ) def plot_data ( self , widget , x , y ): widget . plot ( x , y ) \"\"\" ======================= MENU BAR // EDIT... ======================= \"\"\" \"\"\" ======================= MENU BAR // VIEW... ======================= \"\"\" \"\"\" ======================= MENU BAR // WINDOW... ======================= \"\"\" # TODO func - update window with new data def updateWindowWithNewData ( self , window ): pass \"\"\" ======================= MENU BAR // SETTINGS... ======================= \"\"\" \"\"\" ======================= TEST FUNCTIONS ======================= \"\"\" def plot ( self , hour , temperature ): self . traceplot_1 . plot ( hour , temperature )","title":"MainWindow"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.getDataPath","text":"Parameters: Name Type Description Default file_type str required Source code in app/src/gui/gui_base.py def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path","title":"getDataPath()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.loadDataFromFileMat","text":"Parameters: Name Type Description Default path required loadingDict required Source code in app/src/gui/gui_base.py def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = 'modHierlemann' ) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData ()","title":"loadDataFromFileMat()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.onActionLoadMAT","text":"Source code in app/src/gui/gui_base.py def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) #worker.signals.finished.connect(self.thread_complete) #worker.signals.progress.connect(self.progress_fn) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict )","title":"onActionLoadMAT()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.onActionLoadNPZ","text":"Source code in app/src/gui/gui_base.py def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData ()","title":"onActionLoadNPZ()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.onLoadRealtimeStream","text":"Source code in app/src/gui/gui_base.py def onLoadRealtimeStream ( self ): \"\"\" Returns: \"\"\" path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) self . loading_dict = initDataLoading ( path ) # TODO parallelize loading already saved .mat files load_realtime_worker = Worker ( self . realtimeLoading , path , self . loading_dict ) load_realtime_worker . signals . progress . connect ( self . updateStatusBar ) load_realtime_worker . signals . gui_callback . connect ( self . updateGUIWithNewData ) self . threadpool . start ( load_realtime_worker )","title":"onLoadRealtimeStream()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.realtimeLoading","text":"Parameters: Name Type Description Default path required loadingDict required progress_callback required gui_callback required dataIdentifierString 'gmem1' Source code in app/src/gui/gui_base.py def realtimeLoading ( self , path , loadingDict , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] last_file_idx = 0 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'append raw data' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filter data' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculate array stats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit ()","title":"realtimeLoading()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.update","text":"update(self) update(self, QRect) update(self, QRegion) update(self, int, int, int, int) Source code in app/src/gui/gui_base.py def update ( self ): self . region . setZValue ( 10 ) minX , maxX = self . region . getRegion () self . win1 . setXRange ( - 10 , 40 , padding = 0 )","title":"update()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.updateGUIWithNewData","text":"Source code in app/src/gui/gui_base.py def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession print ( \"GUI Counter: \" , self . window_update_counter ) start = time . time () self . update_win1 () end = time . time () if self . mode_profiling : self . profile_data [ 'array map' ] . append ( end - start ) start = time . time () self . update_win2 () end = time . time () if self . mode_profiling : self . profile_data [ 'spike trace' ] . append ( end - start ) start = time . time () self . update_win3 () end = time . time () if self . mode_profiling : self . profile_data [ 'noise histogram' ] . append ( end - start ) self . update_win4 () if self . mode_profiling : print ( \"Current profiling statistics:\" ) for key in self . profile_data . keys (): avg_time = np . round ( np . mean ( self . profile_data [ key ]), 3 ) print ( key , avg_time ) print ( \"\" ) Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. Source code in app/src/gui/gui_base.py class MainWindow ( QtWidgets . QMainWindow ): \"\"\" Inherited from PyQt main window class. Contains all the functions necessary to start and run GUI elements. \"\"\" # MODES mode_profiling = True mode_multithreading = True first_time_plotting = True # GUI GRAPHS win1 , win2 , win3 , win4 = None , None , None , None # ==== DATA PARAMETERS ==== graph_params = None # ==== DATA CONTAINERS ==== # Raw data stream from chip, only double/triple/etc. counts removed LoadedData = None # TODO reconsolidate into new data containers data = None dataAll , cntAll , times = None , None , None numChan , chMap , chId , startIdx , findCoors = None , None , None , None , None filtered_data = None loading_dict = None p = None window_update_counter = 0 profile_data = None bar1 = None bar2 = None #crosshair region = None vLine , hLine = None , None vb = None proxy = None def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) # ====================== # DEBUGGING (tests + profiling) # ===================== self . graph_params = PyqtGraphParams ({}) if self . mode_profiling : print ( 'GUI is in profiling mode' ) self . profile_data = { 'append raw data' : [], 'filter data' : [], 'calculate array stats' : [], 'array map' : [], 'spike trace' : [], 'noise histogram' : [], 'spike rate' : [] } if self . mode_multithreading : print ( 'GUI is multithreading' ) # ===================== # FRONT END (GUI layout + design) # ===================== # Load layout based on QtDesigner .ui file uic . loadUi ( \"./src/gui/layout.ui\" , self ) # TODO make window system more flexible+modular # top left window = Array Map self . win1 = self . arrayMap self . win1 . setBackground ( 'w' ) self . win1 . showGrid ( x = True , y = True , alpha = 0 ) self . win1 . setXRange ( - 10 , 40 , padding = 0 ) self . win1 . setAspectLocked () self . win1 . setLimits ( xMin =- 10 , xMax = 45 , yMin =- 5 , yMax = 37 ) self . win1 . setLabel ( 'top' , \"Spike Amplitude\" ) self . win1 . setLabel ( 'left' , \"Electrode No. (vertical)\" ) self . win1 . setLabel ( 'bottom' , \"Electrode No. (horizontal)\" ) # top right = Trace Search self . win2 = self . traceplot_verticalLayout self . traceplot_1 . setBackground ( 'w' ) self . traceplot_2 . setBackground ( 'w' ) self . traceplot_3 . setBackground ( 'w' ) self . traceplot_4 . setBackground ( 'w' ) self . traceplot_1 . setLabel ( 'left' , \"# XXX\" ) self . traceplot_2 . setLabel ( 'left' , \"# XXX\" ) self . traceplot_3 . setLabel ( 'left' , \"# XXX\" ) self . traceplot_4 . setLabel ( 'left' , \"# XXX\" ) # bottom left = Spike Rate Plot self . win3 = self . spikeRatePlot self . win3 . setLabel ( 'top' , \"Noise\" ) self . win3 . setLabel ( 'left' , \"Count\" ) self . win3 . setLabel ( 'bottom' , \"Standard Dev\" ) self . win3 . setLimits ( xMin = 0 , yMin = 0 ) self . win3 . setBackground ( 'w' ) # bottom right window = Array Map self . win4 = self . miniMapWidget self . win4 . setBackground ( 'w' ) self . win4 . showGrid ( x = True , y = True , alpha = 0 ) self . win4 . setXRange ( - 10 , 40 , padding = 0 ) self . win4 . setAspectLocked () self . win4 . setLimits ( xMin =- 10 , xMax = 45 , yMin =- 5 , yMax = 37 ) self . win4 . setLabel ( 'top' , \"Spike Cnt\" ) self . win4 . setLabel ( 'left' , \"Electrode No. (vertical)\" ) self . win4 . setLabel ( 'bottom' , \"Electrode No. (horizontal)\" ) # init debug plot ## make interesting distribution of values vals = np . hstack ([ np . random . normal ( size = 500 ), np . random . normal ( size = 260 , loc = 4 )]) ## compute standard histogram y , x = np . histogram ( vals , bins = np . linspace ( - 3 , 8 , 40 )) ## notice that len(x) == len(y)+1 ## We are required to use stepMode=True so that PlotCurveItem will interpret this data correctly. curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . win3 . addItem ( curve ) # bottom right - Spike Rate Plot // MiniMap Widget -> in development # ====================== # BACKEND (multithreading + interactivity) # ===================== self . LoadedData = DC1DataContainer () # class for holding and manipulating data # Set up PyQt multithreading self . threadpool = QThreadPool () print ( \"Multithreading with maximum %d threads\" % self . threadpool . maxThreadCount ()) # >>>> MENU BAR <<<<< # TODO hook up interactivity for all menu bar buttons # >> FILE BUTTON self . action_npz . triggered . connect ( self . onActionLoadNPZ ) self . action_mat . triggered . connect ( self . onActionLoadMAT ) self . actionNew_session . triggered . connect ( self . onLoadRealtimeStream ) self . action_save_npz . triggered . connect ( self . plot ) self . action_save_mat . triggered . connect ( self . plot ) #hack no longer needed - self.windowTitleChanged.connect(self.newOfflineDataSession) # >> EDIT BUTTON # >> VIEW BUTTON # >> WINDOW BUTTON # >> SETTINGS BUTTON # >> HELP BUTTON # plot 1 - hover self . region = pg . LinearRegionItem () self . region . setZValue ( 10 ) # Add the LinearRegionItem to the ViewBox, but tell the ViewBox to exclude this # item when doing auto-range calculations. self . win1 . addItem ( self . region , ignoreBounds = True ) self . win1 . sigRangeChanged . connect ( self . updateRegion ) self . region . setRegion ([ - 10 , 50 ]) self . region . sigRegionChanged . connect ( self . update ) # cross hair self . vLine = pg . InfiniteLine ( angle = 90 , movable = False ) self . hLine = pg . InfiniteLine ( angle = 0 , movable = False ) self . win1 . addItem ( self . vLine , ignoreBounds = True ) self . win1 . addItem ( self . hLine , ignoreBounds = True ) self . vb = self . win1 . plotItem . vb self . proxy = pg . SignalProxy ( self . win1 . scene () . sigMouseMoved , rateLimit = 60 , slot = self . mouseMoved ) self . update_win1 () self . update_win4 () # END __INIT__ FUNCTION # ===================== # for crosshairs def update ( self ): self . region . setZValue ( 10 ) minX , maxX = self . region . getRegion () self . win1 . setXRange ( - 10 , 40 , padding = 0 ) def updateRegion ( self , window , viewRange ): rgn = viewRange [ 0 ] self . region . setRegion ( rgn ) def mouseMoved ( self , evt ): print ( \"mouseMoved\" ) pos = evt [ 0 ] ## using signal proxy turns original arguments into a tuple if self . win1 . sceneBoundingRect () . contains ( pos ): mousePoint = self . vb . mapSceneToView ( pos ) index = int ( mousePoint . x ()) if index > 0 and index < 100 : int_x = int ( mousePoint . x ()) int_y = int ( mousePoint . y ()) self . statusBar () . showMessage ( str ( int_x ) + \", \" + str ( int_y ) + \": \" + str ( self . LoadedData . array_stats [ 'spike_avg' ][ int_x ][ int_y ] ) ) self . vLine . setPos ( mousePoint . x ()) self . hLine . setPos ( mousePoint . y ()) \"\"\" ======================= MULTITHREADING PROGRESS FUNCS ======================= \"\"\" def progress_fn ( self , n ): print ( \" %d%% done\" % n ) def print_output ( self , s ): print ( s ) def thread_complete ( self ): print ( \"THREAD COMPLETE!\" ) \"\"\" ======================= MENU BAR // FILE... ======================= \"\"\" def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path def onLoadRealtimeStream ( self ): \"\"\" Returns: \"\"\" path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) self . loading_dict = initDataLoading ( path ) # TODO parallelize loading already saved .mat files load_realtime_worker = Worker ( self . realtimeLoading , path , self . loading_dict ) load_realtime_worker . signals . progress . connect ( self . updateStatusBar ) load_realtime_worker . signals . gui_callback . connect ( self . updateGUIWithNewData ) self . threadpool . start ( load_realtime_worker ) # callback from progress signal def updateStatusBar ( self , message ): self . statusBar () . showMessage ( message ) # Continuously Check for New Data def realtimeLoading ( self , path , loadingDict , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] last_file_idx = 0 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'append raw data' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filter data' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculate array stats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit () def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData () def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) #worker.signals.finished.connect(self.thread_complete) #worker.signals.progress.connect(self.progress_fn) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict ) def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = 'modHierlemann' ) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData () def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession print ( \"GUI Counter: \" , self . window_update_counter ) start = time . time () self . update_win1 () end = time . time () if self . mode_profiling : self . profile_data [ 'array map' ] . append ( end - start ) start = time . time () self . update_win2 () end = time . time () if self . mode_profiling : self . profile_data [ 'spike trace' ] . append ( end - start ) start = time . time () self . update_win3 () end = time . time () if self . mode_profiling : self . profile_data [ 'noise histogram' ] . append ( end - start ) self . update_win4 () if self . mode_profiling : print ( \"Current profiling statistics:\" ) for key in self . profile_data . keys (): avg_time = np . round ( np . mean ( self . profile_data [ key ]), 3 ) print ( key , avg_time ) print ( \"\" ) def update_win1 ( self ): self . win1 . clear () # prepare demonstration data: if self . first_time_plotting is False : colors = self . LoadedData . array_stats [ 'spike_avg' ] data = colors . T else : data = np . fromfunction ( lambda i , j : ( 1 + 0.3 * np . sin ( i )) * ( i ) ** 2 + ( j ) ** 2 , ( 32 , 32 )) data = data * ( 1 + 0.2 * np . random . random ( data . shape )) # Example: False color image with interactive level adjustment #self.first_time_plotting = False cm = pg . colormap . get ( 'CET-D1' ) image = pg . ImageItem ( data ) self . win1 . clear () self . win1 . addItem ( image ) # bound the LinearRegionItem to the plotted data self . region . setClipItem ( image ) # TODO fix color limits self . win1 . addColorBar ( image , colorMap = cm , values = ( 0 , np . max ( data ))) def update_win2 ( self ): trace_plots = [ self . traceplot_1 , self . traceplot_2 , self . traceplot_3 , self . traceplot_4 ] len_data = len ( self . LoadedData . filtered_data ) # Generate subplots for m , plt in enumerate ( trace_plots ): chan_idx = len_data + ( m - 4 ) x = self . LoadedData . filtered_data [ chan_idx ][ 'times' ] y = self . LoadedData . filtered_data [ chan_idx ][ 'data' ] plt . clear () plt . plot ( x , y , pen = 'b' ) plt . setLabel ( 'left' , '#' + str ( self . LoadedData . filtered_data [ chan_idx ][ 'channel_idx' ])) plt . enableAutoRange ( axis = 'y' ) plt . setAutoVisible ( y = True ) def update_win3 ( self ): self . win3 . clear () vals = self . LoadedData . array_stats [ 'noise_std' ] vals = vals [ np . nonzero ( vals )] # get nonzero vals because zeros have not had noise calculation done yet y , x = np . histogram ( vals , bins = np . linspace ( 0 , 20 , 40 )) curve = pg . PlotCurveItem ( x , y , stepMode = True , fillLevel = 0 , brush = ( 0 , 0 , 255 , 80 )) self . win3 . addItem ( curve ) def update_win4 ( self ): self . win4 . clear () # prepare demonstration data: if self . first_time_plotting is False : spike_cnt = self . LoadedData . array_stats [ 'spike_cnt' ] # AX1) Size by Number of Samples scale1 = ( max_dot - 15 ) / ( np . max ( spike_cnt ) - np . min ( spike_cnt [ spike_cnt != 0 ])) b_add = max_dot - ( np . max ( spike_cnt ) * scale1 ) size = np . round ( spike_cnt * scale1 + b_add ) size [ size < 15 ] = 10 data = spike_cnt . T else : data = np . fromfunction ( lambda i , j : ( 1 + 0.3 * np . sin ( i )) * ( i ) ** 2 + ( j ) ** 2 , ( 32 , 32 )) data = data * ( 1 + 0.2 * np . random . random ( data . shape )) self . first_time_plotting = False # Example: False color image with interactive level adjustment #self.first_time_plotting = False cm = pg . colormap . get ( 'CET-D1' ) image = pg . ImageItem ( data ) self . win4 . addItem ( image ) # TODO fix color limits self . win4 . addColorBar ( image , colorMap = cm , values = ( 0 , np . max ( data ))) def change_win1 ( self ): self . horizontalLayout_top . removeItem ( self . win1 ) self . horizontalLayout_top . addItem ( self . win1 ) def plot_data ( self , widget , x , y ): widget . plot ( x , y ) \"\"\" ======================= MENU BAR // EDIT... ======================= \"\"\" \"\"\" ======================= MENU BAR // VIEW... ======================= \"\"\" \"\"\" ======================= MENU BAR // WINDOW... ======================= \"\"\" # TODO func - update window with new data def updateWindowWithNewData ( self , window ): pass \"\"\" ======================= MENU BAR // SETTINGS... ======================= \"\"\" \"\"\" ======================= TEST FUNCTIONS ======================= \"\"\" def plot ( self , hour , temperature ): self . traceplot_1 . plot ( hour , temperature )","title":"updateGUIWithNewData()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.getDataPath","text":"Parameters: Name Type Description Default file_type str required Source code in app/src/gui/gui_base.py def getDataPath ( self , file_type : str ): \"\"\" Args: file_type: Returns: \"\"\" options = QFileDialog . Options () if file_type is None : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , \"All Files (*)\" , options = options ) else : file_path , _ = QFileDialog . getOpenFileName ( self , \"QFileDialog.getOpenFileName()\" , \"\" , file_type , options = options ) if file_path : print ( file_path ) return file_path","title":"getDataPath()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.loadDataFromFileMat","text":"Parameters: Name Type Description Default path required loadingDict required Source code in app/src/gui/gui_base.py def loadDataFromFileMat ( self , path , loadingDict ): \"\"\" Args: path: loadingDict: Returns: \"\"\" self . dataAll , self . cntAll , self . times = processData ( loadingDict , dataIdentifierString = 'gmem1' , buffer_num = 0 ) # Any other args, kwargs print ( 'identify relevant channels...' ) self . numChan , self . chMap , self . chId , self . startIdx , self . findCoors = identify_relevant_channels ( self . dataAll ) print ( 'applying filter...' ) self . filtered_data = applyFilterToAllData ( self . dataAll , self . numChan , self . chMap , filtType = 'modHierlemann' ) if self . mode_multithreading is False : # if multi-threaded, then this function is already connected on completion of fn self . updateGUIWithNewData ()","title":"loadDataFromFileMat()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.onActionLoadMAT","text":"Source code in app/src/gui/gui_base.py def onActionLoadMAT ( self ): \"\"\" Returns: \"\"\" # path = self.getDataPath(\"MATLAB files (*.mat)\") path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) # init loading dict with path variables loadingDict = initDataLoading ( path ) self . loading_dict = loadingDict # loading data freezes GUI -> multithread if self . mode_multithreading : worker = Worker ( self . loadDataFromFileMat , path , loadingDict ) worker . signals . result . connect ( self . updateGUIWithNewData ) #worker.signals.finished.connect(self.thread_complete) #worker.signals.progress.connect(self.progress_fn) self . threadpool . start ( worker ) else : self . loadDataFromFileMat ( path , loadingDict )","title":"onActionLoadMAT()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.onActionLoadNPZ","text":"Source code in app/src/gui/gui_base.py def onActionLoadNPZ ( self ): \"\"\" Returns: \"\"\" path = self . getDataPath ( \"Numpy files (*.npz)\" ) data = loadDataFromFileNpz ( path ) self . updateGUIWithNewData ()","title":"onActionLoadNPZ()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.onLoadRealtimeStream","text":"Source code in app/src/gui/gui_base.py def onLoadRealtimeStream ( self ): \"\"\" Returns: \"\"\" path = QtWidgets . QFileDialog . getExistingDirectory ( self , 'Select Folder' ) self . loading_dict = initDataLoading ( path ) # TODO parallelize loading already saved .mat files load_realtime_worker = Worker ( self . realtimeLoading , path , self . loading_dict ) load_realtime_worker . signals . progress . connect ( self . updateStatusBar ) load_realtime_worker . signals . gui_callback . connect ( self . updateGUIWithNewData ) self . threadpool . start ( load_realtime_worker )","title":"onLoadRealtimeStream()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.realtimeLoading","text":"Parameters: Name Type Description Default path required loadingDict required progress_callback required gui_callback required dataIdentifierString 'gmem1' Source code in app/src/gui/gui_base.py def realtimeLoading ( self , path , loadingDict , progress_callback , gui_callback , dataIdentifierString = 'gmem1' ): \"\"\" Args: path: loadingDict: progress_callback: gui_callback: dataIdentifierString: Returns: \"\"\" progress_callback . emit ( \"in realtimeloading(): \" + path ) # string parse datarun+datapiece split_path = os . path . split ( path ) data_run = split_path [ 1 ] data_piece = os . path . split ( split_path [ 0 ])[ 1 ] last_file_idx = 0 while True : # In case multiple files coming in at once, hold 100ms (not likely) # time.sleep(0.1) next_file = path + \"/\" + data_run + \"_\" + str ( last_file_idx + 1 ) + \".mat\" # If the next numbered file doesn't exist, just wait if os . path . exists ( next_file ) is False : progress_callback . emit ( \"Waiting for next buffer file to load in: \" + next_file ) continue else : # next file does exist, so process it last_file_idx += 1 # update idx print ( \"NEW FILE: \" , last_file_idx ) progress_callback . emit ( \"Loading latest buffer file idx \" + str ( last_file_idx )) # In the off chance the file has been written, but not saved by the TCP socket yet, pause time . sleep ( 0.5 ) # Load Data from this Loop's Buffer file mat_contents = sio . loadmat ( next_file ) dataRaw = mat_contents [ dataIdentifierString ][ 0 ][:] data_real , cnt_real , N = removeMultipleCounts ( dataRaw ) start = time . time () self . LoadedData . append_raw_data ( data_real , cnt_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'append raw data' ] = end - start start = time . time () self . LoadedData . update_filtered_data () end = time . time () if self . mode_profiling : self . profile_data [ 'filter data' ] = end - start start = time . time () self . LoadedData . update_array_stats ( data_real , N ) end = time . time () if self . mode_profiling : self . profile_data [ 'calculate array stats' ] = end - start # we need to call the main GUI thread to update graphs (can't do with non GUI-thread) gui_callback . emit ()","title":"realtimeLoading()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.update","text":"update(self) update(self, QRect) update(self, QRegion) update(self, int, int, int, int) Source code in app/src/gui/gui_base.py def update ( self ): self . region . setZValue ( 10 ) minX , maxX = self . region . getRegion () self . win1 . setXRange ( - 10 , 40 , padding = 0 )","title":"update()"},{"location":"gui-base/#dc1DataVis.app.src.gui.gui_base.MainWindow.updateGUIWithNewData","text":"Source code in app/src/gui/gui_base.py def updateGUIWithNewData ( self ): \"\"\" Returns: \"\"\" self . setWindowTitle ( 'DC1 Vis - ' + self . loading_dict [ 'path' ]) # -> connects to newOfflineDataSession print ( \"GUI Counter: \" , self . window_update_counter ) start = time . time () self . update_win1 () end = time . time () if self . mode_profiling : self . profile_data [ 'array map' ] . append ( end - start ) start = time . time () self . update_win2 () end = time . time () if self . mode_profiling : self . profile_data [ 'spike trace' ] . append ( end - start ) start = time . time () self . update_win3 () end = time . time () if self . mode_profiling : self . profile_data [ 'noise histogram' ] . append ( end - start ) self . update_win4 () if self . mode_profiling : print ( \"Current profiling statistics:\" ) for key in self . profile_data . keys (): avg_time = np . round ( np . mean ( self . profile_data [ key ]), 3 ) print ( key , avg_time ) print ( \"\" )","title":"updateGUIWithNewData()"},{"location":"gui-interactivity/","text":"","title":"Interactivity"},{"location":"gui-layout/","text":"","title":"Layout"},{"location":"gui/","text":"","title":"Gui"},{"location":"preprocessing/","text":"Data Preprocessing @authors Maddy Hays, Huy Nguyen (2022) identify_relevant_channels ( raw_data ) Only n number of channels can be recorded at a given time due to bandwidth concerns--the rest are shut off. For given data recorded at during a certain window, find which channels were recorded. Parameters: Name Type Description Default raw_data_all unprocessed data in a given time window (num_channels_X x num_channels_Y x time_len) required Returns: Type Description num_channels number of channels that were found to have been recorded for given data channel_map: list of channels that were recorded, i.e. nonzero (x/y_coords, num_channels) channel_id: list of channels that were recorded, but identified by a single numerical ID start_idx: @param raw_data: all the raw data loaded thus far from files Source code in app/src/data/preprocessing.py def identify_relevant_channels ( raw_data : np . array ): \"\"\" Only n number of channels can be recorded at a given time due to bandwidth concerns--the rest are shut off. For given data recorded at during a certain window, find which channels were recorded. Args: raw_data_all: unprocessed data in a given time window (num_channels_X x num_channels_Y x time_len) Returns: num_channels: number of channels that were found to have been recorded for given data channel_map: list of channels that were recorded, i.e. nonzero (x/y_coords, num_channels) channel_id: list of channels that were recorded, but identified by a single numerical ID start_idx: @param raw_data: all the raw data loaded thus far from files \"\"\" # This bit takes the longest. ~ 30 sec for whole array 4 channel recording num_samples = np . count_nonzero ( raw_data , axis = 2 ) num_channels = np . count_nonzero ( num_samples ) # Map and Identify recorded channels find_coords = np . nonzero ( num_samples ) channel_map = np . array ( find_coords ) channel_id = np . zeros ( num_channels ) start_idx = np . zeros ( num_channels ) for k in range ( 0 , num_channels ): channel_id [ k ] = map2idx ( channel_map [ 0 , k ], channel_map [ 1 , k ]) start_idx [ k ] = ( raw_data [ channel_map [ 0 , k ], channel_map [ 1 , k ], :] != 0 ) . argmax ( axis = 0 ) recorded_channels = np . stack (( channel_id , start_idx ), axis = 1 ) . astype ( int ) #return recorded_channels return num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels idx2map ( ch_idx ) Given a channel index, return the channel's row and col Parameters: Name Type Description Default ch_idx int single numerical index for array (up to 1024) required Returns: Type Description channel row and channel index Source code in app/src/data/preprocessing.py def idx2map ( ch_idx : int ): \"\"\" Given a channel index, return the channel's row and col Args: ch_idx: single numerical index for array (up to 1024) Returns: channel row and channel index \"\"\" if ch_idx > 1023 or ch_idx < 0 : print ( 'Chan num out of range' ) else : ch_row = int ( ch_idx / 32 ) ch_col = int ( ch_idx - ch_row * 32 ) return ch_row , ch_col map2idx ( ch_row , ch_col ) Given a channel's row and col, return channel's index Parameters: Name Type Description Default ch_row int row index of channel in array (up to 32) required ch_col int column index of channel in array (up to 32) required Returns: numerical index of array Source code in app/src/data/preprocessing.py def map2idx ( ch_row : int , ch_col : int ): \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx","title":"Preprocessing"},{"location":"preprocessing/#data-preprocessing","text":"@authors Maddy Hays, Huy Nguyen (2022)","title":"Data Preprocessing"},{"location":"preprocessing/#dc1DataVis.app.src.data.preprocessing.identify_relevant_channels","text":"Only n number of channels can be recorded at a given time due to bandwidth concerns--the rest are shut off. For given data recorded at during a certain window, find which channels were recorded. Parameters: Name Type Description Default raw_data_all unprocessed data in a given time window (num_channels_X x num_channels_Y x time_len) required Returns: Type Description num_channels number of channels that were found to have been recorded for given data channel_map: list of channels that were recorded, i.e. nonzero (x/y_coords, num_channels) channel_id: list of channels that were recorded, but identified by a single numerical ID start_idx: @param raw_data: all the raw data loaded thus far from files Source code in app/src/data/preprocessing.py def identify_relevant_channels ( raw_data : np . array ): \"\"\" Only n number of channels can be recorded at a given time due to bandwidth concerns--the rest are shut off. For given data recorded at during a certain window, find which channels were recorded. Args: raw_data_all: unprocessed data in a given time window (num_channels_X x num_channels_Y x time_len) Returns: num_channels: number of channels that were found to have been recorded for given data channel_map: list of channels that were recorded, i.e. nonzero (x/y_coords, num_channels) channel_id: list of channels that were recorded, but identified by a single numerical ID start_idx: @param raw_data: all the raw data loaded thus far from files \"\"\" # This bit takes the longest. ~ 30 sec for whole array 4 channel recording num_samples = np . count_nonzero ( raw_data , axis = 2 ) num_channels = np . count_nonzero ( num_samples ) # Map and Identify recorded channels find_coords = np . nonzero ( num_samples ) channel_map = np . array ( find_coords ) channel_id = np . zeros ( num_channels ) start_idx = np . zeros ( num_channels ) for k in range ( 0 , num_channels ): channel_id [ k ] = map2idx ( channel_map [ 0 , k ], channel_map [ 1 , k ]) start_idx [ k ] = ( raw_data [ channel_map [ 0 , k ], channel_map [ 1 , k ], :] != 0 ) . argmax ( axis = 0 ) recorded_channels = np . stack (( channel_id , start_idx ), axis = 1 ) . astype ( int ) #return recorded_channels return num_channels , channel_map , channel_id , start_idx , find_coords , recorded_channels","title":"identify_relevant_channels()"},{"location":"preprocessing/#dc1DataVis.app.src.data.preprocessing.idx2map","text":"Given a channel index, return the channel's row and col Parameters: Name Type Description Default ch_idx int single numerical index for array (up to 1024) required Returns: Type Description channel row and channel index Source code in app/src/data/preprocessing.py def idx2map ( ch_idx : int ): \"\"\" Given a channel index, return the channel's row and col Args: ch_idx: single numerical index for array (up to 1024) Returns: channel row and channel index \"\"\" if ch_idx > 1023 or ch_idx < 0 : print ( 'Chan num out of range' ) else : ch_row = int ( ch_idx / 32 ) ch_col = int ( ch_idx - ch_row * 32 ) return ch_row , ch_col","title":"idx2map()"},{"location":"preprocessing/#dc1DataVis.app.src.data.preprocessing.map2idx","text":"Given a channel's row and col, return channel's index Parameters: Name Type Description Default ch_row int row index of channel in array (up to 32) required ch_col int column index of channel in array (up to 32) required Returns: numerical index of array Source code in app/src/data/preprocessing.py def map2idx ( ch_row : int , ch_col : int ): \"\"\" Given a channel's row and col, return channel's index Args: ch_row: row index of channel in array (up to 32) ch_col: column index of channel in array (up to 32) Returns: numerical index of array \"\"\" if ch_row > 31 or ch_row < 0 : print ( 'Row out of range' ) elif ch_col > 31 or ch_col < 0 : print ( 'Col out of range' ) else : ch_idx = int ( ch_row * 32 + ch_col ) return ch_idx","title":"map2idx()"},{"location":"todo/","text":"","title":"To Dos"},{"location":"vis_graphs/","text":"","title":"viz_graphs"}]}